Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.504,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,11.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,13.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,15.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,18.72,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,21.311999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,23.711999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,25.823999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,28.735999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,31.167999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,33.696,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.56,36.256,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,4.736,40.992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",18,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,3.328,44.32,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",19,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,46.912,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",20,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.816,49.728,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",21,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.152,54.88,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",22,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14434848.0,34400.0,15.776,70.656,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451089.0,1075.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",23,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.328,73.98400000000001,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",24,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.008,76.992,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",25,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,11.04,88.03200000000001,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",26,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.816,94.84800000000001,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.816,97.66400000000002,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",28,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.104,100.76800000000001,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,103.32800000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",30,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.184,108.51200000000001,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",31,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597248.0,12288.0,16.192,124.70400000000001,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299914.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",32,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.688,127.39200000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",33,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.624,130.01600000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",34,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,132.544,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",35,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.528,135.072,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,137.6,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",37,18251.0,44950.0,768.0,0,0.0,45718.0,45718.0,0.0,48.0,0.0,12288.0,12288.0,2.688,140.28799999999998,3072.0,6144.0,17867.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",38,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.592,142.88,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",39,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.656,145.536,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",40,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584928.0,12288.0,15.68,161.216,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299529.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,3.04,164.256,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",42,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,167.2,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,169.76,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",44,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,174.784,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",45,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14429376.0,34880.0,15.936,190.72,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,450918.0,1090.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",46,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.488,194.208,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",47,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.136,197.344,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",48,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.24,207.584,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",49,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.488,215.072,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",50,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,217.92000000000002,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",51,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,220.73600000000002,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,223.424,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",53,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,228.448,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",54,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597216.0,12288.0,15.68,244.12800000000001,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299913.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",55,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.752,246.88000000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,249.40800000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,252.06400000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,254.65600000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,257.184,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,18230.0,44908.0,768.0,0,0.0,45676.0,45676.0,0.0,48.0,0.0,12288.0,12288.0,2.624,259.80800000000005,3072.0,6144.0,17846.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",61,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,262.33600000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,264.92800000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",63,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584768.0,12288.0,15.872,280.80000000000007,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299524.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",64,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,3.008,283.80800000000005,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",65,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,286.68800000000005,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,289.28000000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.12,294.40000000000003,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14421472.0,34560.0,15.584,309.98400000000004,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,450671.0,1080.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.264,313.24800000000005,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",70,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.04,316.28800000000007,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",71,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.208,326.4960000000001,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",72,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.816,333.31200000000007,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.912,336.22400000000005,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",74,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,339.10400000000004,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,341.696,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",76,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,346.72,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",77,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597312.0,12288.0,15.808,362.528,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299916.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",78,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,365.088,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",79,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.624,367.71200000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,370.30400000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,372.86400000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,375.456,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,18228.0,44904.0,768.0,0,0.0,45672.0,45672.0,0.0,48.0,0.0,12288.0,12288.0,2.624,378.08000000000004,3072.0,6144.0,17844.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.656,380.73600000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",85,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,383.29600000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",86,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584960.0,12288.0,15.232,398.528,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299530.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",87,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,401.408,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",88,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,404.35200000000003,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,407.04,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",90,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.088,412.12800000000004,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",91,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14337248.0,34528.0,15.488,427.61600000000004,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,448039.0,1079.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.552,431.16800000000006,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",93,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.072,434.24000000000007,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",94,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.304,444.54400000000004,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",95,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.752,451.29600000000005,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",96,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,454.17600000000004,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",97,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,457.02400000000006,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,459.58400000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",99,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,464.64000000000004,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597184.0,12288.0,16.064,480.70400000000006,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299912.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",101,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.688,483.39200000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",102,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,485.95200000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,488.51200000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,491.2320000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",105,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,493.7920000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",106,18246.0,44940.0,768.0,0,0.0,45708.0,45708.0,0.0,48.0,0.0,12288.0,12288.0,2.592,496.38400000000007,3072.0,6144.0,17862.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",107,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.496,498.88000000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,501.44000000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",109,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585088.0,12288.0,15.296,516.7360000000001,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299534.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",110,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.944,519.6800000000001,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",111,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,522.528,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,525.088,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.152,530.24,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14388256.0,34752.0,15.584,545.824,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,449633.0,1086.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.232,549.0559999999999,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",116,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.168,552.2239999999999,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",117,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.336,562.56,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",118,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.912,569.472,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.976,572.448,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",120,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,575.36,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,578.048,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",122,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.216,583.264,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",123,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597056.0,12288.0,15.968,599.232,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299908.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,601.824,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",125,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,604.3839999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",126,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,606.9119999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,609.4719999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",128,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,612.0319999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,18237.0,44922.0,768.0,0,0.0,45690.0,45690.0,0.0,48.0,0.0,12288.0,12288.0,2.624,614.6559999999998,3072.0,6144.0,17853.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.496,617.1519999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,619.7119999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",132,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584704.0,12288.0,15.424,635.1359999999997,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299522.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.912,638.0479999999998,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",134,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,640.8959999999997,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",135,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.752,643.6479999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",136,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,4.96,648.6079999999997,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",137,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14439584.0,34944.0,15.712,664.3199999999997,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451237.0,1092.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",138,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.264,667.5839999999997,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",139,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.008,670.5919999999998,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",140,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.304,680.8959999999997,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",141,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.008,687.9039999999998,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,690.7519999999997,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",143,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.04,693.7919999999997,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,696.3519999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,701.4079999999997,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",146,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597280.0,12288.0,15.648,717.0559999999997,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299915.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",147,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,719.5839999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",148,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,722.1119999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",149,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.752,724.8639999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,727.5199999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",151,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,730.0799999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",152,18237.0,44922.0,768.0,0,0.0,45690.0,45690.0,0.0,48.0,0.0,12288.0,12288.0,2.592,732.6719999999996,3072.0,6144.0,17853.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,735.1999999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",154,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,737.7919999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",155,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585120.0,12288.0,15.776,753.5679999999995,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299535.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.976,756.5439999999995,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",157,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,759.3919999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,761.9839999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,767.0079999999995,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14447936.0,34560.0,15.36,782.3679999999995,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451498.0,1080.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.488,785.8559999999995,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",162,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.136,788.9919999999995,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",163,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.336,799.3279999999995,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",164,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.944,806.2719999999995,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.816,809.0879999999995,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",166,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,811.9999999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",167,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,814.5919999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",168,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,819.6159999999995,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597216.0,12288.0,15.936,835.5519999999996,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299913.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",170,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,838.1439999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",171,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,840.7039999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",172,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,843.2959999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",173,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,845.8879999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",174,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,848.4159999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",175,18229.0,44906.0,768.0,0,0.0,45674.0,45674.0,0.0,48.0,0.0,12288.0,12288.0,2.624,851.0399999999995,3072.0,6144.0,17845.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",176,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.496,853.5359999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",177,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,856.1279999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",178,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584896.0,12288.0,15.456,871.5839999999995,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299528.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",179,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,874.4319999999994,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",180,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.04,877.4719999999994,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,880.0639999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",182,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.12,885.1839999999994,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",183,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14448192.0,34432.0,15.552,900.7359999999994,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451506.0,1076.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.2,903.9359999999995,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",185,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.008,906.9439999999995,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",186,24576.0,865536.0,0.0,0,0.0,865536.0,865536.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,10.272,917.2159999999996,666624.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",187,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.656,923.8719999999995,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",188,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,926.7519999999995,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",189,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.784,929.5359999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,932.1279999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",191,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.28,937.4079999999994,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597344.0,12288.0,15.712,953.1199999999994,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299917.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",193,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,955.6479999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",194,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.592,958.2399999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",195,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,960.7679999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,963.3279999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",197,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,965.8879999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",198,18268.0,44984.0,768.0,0,0.0,45752.0,45752.0,0.0,48.0,0.0,12288.0,12288.0,2.592,968.4799999999993,3072.0,6144.0,17884.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,971.0079999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",200,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.624,973.6319999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",201,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585088.0,12288.0,15.808,989.4399999999994,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299534.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",202,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,992.2879999999993,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",203,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,995.1359999999993,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",204,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,997.7279999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",205,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,4.992,1002.7199999999992,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",206,40205600.0,84382175.0,3216448.0,0,0.0,87598623.0,87598623.0,1608277.0,1382113.0,0.5378151344807868,158978048.0,191456.0,175.264,1177.9839999999992,2362079.0,4825344.0,38597376.0,1608224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4968064.0,5983.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",207,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1180.0319999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.496,1182.5279999999993,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1184.9599999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",210,0.0,51200.0,0.0,0,0.0,51200.0,51200.0,0.0,790.0,0.0,201056.0,201056.0,2.784,1187.7439999999995,0.0,51200.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1189.8559999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",212,75601.0,0.0,151202.0,0,0.0,151202.0,151202.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.192,1194.0479999999995,0.0,0.0,0.0,75601.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",213,43200.0,0.0,86400.0,0,0.0,86400.0,86400.0,3300.0,20652.0,0.1377755511022044,1284800.0,0.0,6.112,1200.1599999999996,0.0,0.0,0.0,43200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",214,25428.0,0.0,50856.0,0,0.0,50856.0,50856.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.096,1204.2559999999996,0.0,0.0,0.0,25428.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",215,52800.0,0.0,105600.0,0,0.0,105600.0,105600.0,3300.0,20952.0,0.13607125185551708,1284800.0,0.0,5.76,1210.0159999999996,0.0,0.0,0.0,52800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",216,25347.0,0.0,50694.0,0,0.0,50694.0,50694.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.032,1214.0479999999995,0.0,0.0,0.0,25347.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",217,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,3300.0,20902.0,0.13635236757292785,1284800.0,0.0,5.76,1219.8079999999995,0.0,0.0,0.0,51200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",218,25345.0,0.0,50690.0,0,0.0,50690.0,50690.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.032,1223.8399999999995,0.0,0.0,0.0,25345.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",219,46400.0,0.0,92800.0,0,0.0,92800.0,92800.0,3300.0,20752.0,0.13720272742391484,1284800.0,32.0,5.888,1229.7279999999994,0.0,0.0,0.0,46400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",220,406.0,0.0,812.0,0,0.0,812.0,812.0,0.0,6.0,0.0,1632.0,224.0,3.072,1232.7999999999993,0.0,0.0,0.0,406.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1234.8479999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",222,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,224.0,0.0,4.32,1239.1679999999992,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,1241.1839999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",224,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,224.0,0.0,4.288,1245.4719999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",225,63332.0,0.0,126664.0,0,0.0,126664.0,126664.0,14350.0,3253.0,0.8152019542123502,207360.0,2112.0,5.824,1251.2959999999994,0.0,0.0,0.0,63332.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6480.0,66.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",226,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,1257.3119999999994,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,4713.0,0.0,203744.0,12576.0,4.032,1261.3439999999994,0.0,0.0,0.0,100514.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6367.0,393.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",228,6400.0,0.0,12800.0,0,0.0,12800.0,12800.0,0.0,1185.0,0.0,251328.0,0.0,2.752,1264.0959999999993,0.0,0.0,0.0,6400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",229,201971.0,0.0,403942.0,0,0.0,403942.0,403942.0,0.0,1571.0,0.0,0.0,402080.0,2.528,1266.6239999999993,0.0,0.0,0.0,201971.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",230,387272.0,0.0,774544.0,0,0.0,774544.0,774544.0,64512.0,1571.0,0.9762268662137009,201056.0,0.0,3.968,1270.5919999999994,0.0,0.0,0.0,387272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,1273.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",232,49536.0,0.0,99072.0,0,0.0,99072.0,99072.0,16978.0,6803.0,0.7139312896850427,653312.0,469408.0,14.848,1288.1599999999994,0.0,0.0,0.0,49536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20416.0,14669.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",233,19200.0,0.0,38400.0,0,0.0,38400.0,38400.0,4766.0,6810.0,0.41171389080856946,650752.0,613376.0,12.928,1301.0879999999995,0.0,0.0,0.0,19200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20336.0,19168.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",234,21888.0,0.0,43776.0,0,0.0,43776.0,43776.0,5746.0,6751.0,0.4597903496839241,647552.0,613632.0,13.6,1314.6879999999994,0.0,0.0,0.0,21888.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20236.0,19176.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",235,21888.0,0.0,43776.0,0,0.0,43776.0,43776.0,5746.0,6742.0,0.46012171684817427,647168.0,511264.0,14.016,1328.7039999999995,0.0,0.0,0.0,21888.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20224.0,15977.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",236,819503.0,1663761.0,231810.0,0,0.0,1895571.0,1895571.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,25.248,1353.9519999999995,206308.0,50257.0,703598.0,115905.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18849.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,480.0,2.112,1356.0639999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",238,3457.0,135689.0,6914.0,0,0.0,142603.0,142603.0,6909.0,3226.0,0.6816970892945239,214240.0,202720.0,4.416,1360.4799999999996,135689.0,0.0,0.0,3457.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6695.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",239,209.0,0.0,418.0,0,0.0,418.0,418.0,0.0,790.0,0.0,201056.0,50208.0,2.784,1363.2639999999997,0.0,0.0,0.0,209.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",240,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1365.3119999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,106867.0,0.0,213734.0,0,0.0,213734.0,213734.0,0.0,4713.0,0.0,452352.0,20032.0,9.056,1374.3679999999997,0.0,0.0,0.0,106867.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,14136.0,626.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",242,6400.0,0.0,12800.0,0,0.0,12800.0,12800.0,0.0,1185.0,0.0,251328.0,0.0,2.72,1377.0879999999997,0.0,0.0,0.0,6400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",243,819506.0,1663761.0,231816.0,0,0.0,1895577.0,1895577.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,25.728,1402.8159999999998,206308.0,50257.0,703598.0,115908.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18849.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",244,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.504,1416.3199999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",245,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,1418.7199999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",246,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.536,1432.2559999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",247,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,1434.6879999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",248,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,1437.312,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,1440.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",250,1536.0,54833.0,3072.0,0,0.0,57905.0,57905.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.312,1453.8239999999998,54833.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",251,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,1456.3519999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,1458.848,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,1462.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",254,706048.0,1008290.0,504320.0,0,0.0,1512610.0,1512610.0,0.0,1571.0,0.0,0.0,201056.0,3.136,1465.184,0.0,100514.0,453888.0,252160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,307537.0,512000.0,103074.0,0,0.0,615074.0,615074.0,0.0,1185.0,0.0,402112.0,0.0,4.0,1469.184,0.0,0.0,256000.0,51537.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",256,27176.0,0.0,54352.0,0,0.0,54352.0,54352.0,124.0,395.0,0.23892100192678228,201056.0,32.0,17.984,1487.168,0.0,0.0,0.0,27176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1489.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,1492.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1494.432,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1496.864,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",261,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.464,1499.328,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",262,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.08,1501.408,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1503.456,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,1506.1119999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",265,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1508.1599999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",266,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.4,1510.56,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",267,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,1513.12,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,1515.616,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",269,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.136,1518.752,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",270,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,1521.9199999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",271,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,1524.3839999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",272,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,1526.8159999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",273,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.392,1530.2079999999999,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1532.2559999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",275,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,1535.168,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1537.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",277,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,1540.032,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",278,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.496,1542.528,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",279,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,3.072,1545.6,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",280,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,3.04,1548.6399999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1551.1999999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",282,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,1553.696,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",283,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.36,1557.0559999999998,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",284,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,1562.1119999999999,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",285,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14240416.0,34144.0,15.936,1578.0479999999998,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,445013.0,1067.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",286,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.392,1581.4399999999998,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",287,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.04,1584.4799999999998,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1587.072,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",289,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.528,1589.6,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",290,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.464,1600.0639999999999,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",291,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.976,1607.04,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",292,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.912,1609.952,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",293,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,1612.864,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1615.424,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",295,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.088,1620.512,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9596992.0,12288.0,16.352,1636.864,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299906.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",297,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1639.424,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",298,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.656,1642.08,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.752,1644.8319999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",300,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1647.3919999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",301,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1649.9519999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,18270.0,44988.0,768.0,0,0.0,45756.0,45756.0,0.0,48.0,0.0,12288.0,12288.0,2.72,1652.6719999999998,3072.0,6144.0,17886.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",303,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1655.1999999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",304,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1657.792,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",305,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584864.0,12288.0,15.488,1673.28,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299527.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",306,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.944,1676.224,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",307,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.136,1679.36,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",308,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,1682.0159999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",309,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,4.992,1687.0079999999998,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",310,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14367200.0,34720.0,15.776,1702.7839999999999,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,448975.0,1085.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",311,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.264,1706.0479999999998,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",312,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.072,1709.1199999999997,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",313,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,1711.7759999999996,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1714.3359999999996,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",315,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.432,1724.7679999999996,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",316,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.72,1731.4879999999996,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",317,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.816,1734.3039999999996,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",318,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,1737.2479999999996,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,1739.9039999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",320,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.248,1745.1519999999996,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",321,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597664.0,12288.0,15.808,1760.9599999999996,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299927.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",322,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1763.4879999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",323,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1766.0159999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",324,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,1768.6079999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",325,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.528,1771.1359999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",326,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1773.7599999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",327,18256.0,44960.0,768.0,0,0.0,45728.0,45728.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1776.3839999999998,3072.0,6144.0,17872.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",328,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1778.9439999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",329,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1781.5039999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",330,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585088.0,12288.0,15.776,1797.2799999999997,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299534.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",331,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,1800.1599999999999,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",332,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,1802.9759999999999,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1805.568,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",334,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.088,1810.656,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",335,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14482304.0,35040.0,15.904,1826.56,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,452572.0,1095.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",336,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.392,1829.952,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",337,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.104,1833.056,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",338,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1835.6480000000001,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",339,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1838.208,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",340,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.272,1848.48,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",341,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.328,1855.808,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",342,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,1858.656,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",343,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,1861.6,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",344,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1864.192,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",345,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,1869.216,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",346,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597344.0,12288.0,15.84,1885.0559999999998,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299917.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",347,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1887.6159999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",348,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.496,1890.1119999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1892.7359999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,1895.456,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1898.0159999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,18250.0,44948.0,768.0,0,0.0,45716.0,45716.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1900.6399999999999,3072.0,6144.0,17866.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",353,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,1903.1999999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",354,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1905.792,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",355,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584864.0,12288.0,15.264,1921.0559999999998,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299527.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",356,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,1923.9039999999998,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",357,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.976,1926.8799999999999,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1929.472,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,4.96,1934.432,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",360,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14439488.0,34656.0,15.904,1950.336,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451234.0,1083.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",361,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.36,1953.696,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",362,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,2.976,1956.672,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1959.232,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,1961.824,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",365,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.432,1972.256,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",366,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.656,1978.912,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",367,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,1981.76,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",368,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,1984.64,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",369,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1987.2320000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",370,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,1992.2880000000002,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",371,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597184.0,12288.0,15.904,2008.1920000000002,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299912.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,2010.8480000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",373,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2013.4720000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2016.0320000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2018.6240000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2021.1840000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,18227.0,44902.0,768.0,0,0.0,45670.0,45670.0,0.0,48.0,0.0,12288.0,12288.0,2.592,2023.7760000000003,3072.0,6144.0,17843.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",378,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.592,2026.3680000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2028.9280000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",380,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584896.0,12288.0,15.584,2044.5120000000004,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299528.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",381,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,2047.3920000000005,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",382,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.976,2050.3680000000004,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",383,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2053.0240000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",384,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,2058.0800000000004,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",385,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14402240.0,35072.0,15.488,2073.568,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,450070.0,1096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",386,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.264,2076.8320000000003,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",387,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.072,2079.9040000000005,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.624,2082.5280000000002,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",389,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.688,2085.2160000000003,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",390,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.368,2095.5840000000003,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",391,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,6.816,2102.4,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",392,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.912,2105.312,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",393,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,2108.192,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2110.752,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.056,2115.808,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",396,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597152.0,12288.0,16.064,2131.872,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299911.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2134.4959999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",398,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2137.0239999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",399,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2139.6479999999992,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,2142.367999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2144.895999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",402,18252.0,44952.0,768.0,0,0.0,45720.0,45720.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2147.5199999999986,3072.0,6144.0,17868.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",403,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2150.0479999999984,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",404,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2152.671999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",405,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585024.0,12288.0,15.488,2168.159999999998,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299532.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",406,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,2171.007999999998,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",407,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,2173.887999999998,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2176.543999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",409,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.12,2181.663999999998,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",410,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14348992.0,34624.0,15.712,2197.375999999998,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,448406.0,1082.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",411,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.328,2200.703999999998,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",412,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.104,2203.8079999999977,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.688,2206.495999999998,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",414,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2209.0559999999978,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",415,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.368,2219.4239999999977,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",416,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.168,2226.591999999998,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",417,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.88,2229.471999999998,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",418,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,2232.351999999998,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2234.911999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",420,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.088,2239.999999999998,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597760.0,12288.0,15.52,2255.519999999998,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299930.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2258.079999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",423,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2260.607999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2263.2319999999977,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",425,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2265.7919999999976,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",426,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,2268.4479999999976,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,18235.0,44918.0,768.0,0,0.0,45686.0,45686.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2271.0719999999974,3072.0,6144.0,17851.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",428,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.496,2273.5679999999975,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2276.1599999999976,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585248.0,12288.0,15.68,2291.8399999999974,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299539.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",431,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,3.04,2294.8799999999974,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",432,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,2297.7599999999975,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",433,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2300.3519999999976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",434,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,2305.3759999999975,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",435,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14511360.0,34784.0,15.552,2320.9279999999976,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,453480.0,1087.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",436,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.328,2324.2559999999976,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",437,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.008,2327.2639999999974,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",438,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2329.8239999999973,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2332.3839999999973,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",440,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.368,2342.751999999997,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",441,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.008,2349.759999999997,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",442,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.976,2352.735999999997,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",443,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,2355.679999999997,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2358.239999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.088,2363.3279999999972,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",446,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597280.0,12288.0,15.808,2379.1359999999972,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299915.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",447,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2381.695999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",448,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2384.255999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",449,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.72,2386.975999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.784,2389.759999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2392.287999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,18252.0,44952.0,768.0,0,0.0,45720.0,45720.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2394.9119999999966,3072.0,6144.0,17868.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",453,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2397.4719999999966,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2400.0319999999965,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",455,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9584704.0,12288.0,15.424,2415.4559999999965,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299522.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",456,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,2418.3039999999964,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",457,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,2421.1199999999963,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2423.7119999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",459,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.216,2428.9279999999962,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",460,1926144.0,3621888.0,304128.0,0,0.0,3926016.0,3926016.0,17280.0,111744.0,0.13392857142857142,14455296.0,34528.0,15.648,2444.5759999999964,73728.0,0.0,1774080.0,152064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,451728.0,1079.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",461,2304.0,6912.0,4608.0,0,0.0,11520.0,11520.0,0.0,6912.0,0.0,18432.0,4608.0,3.296,2447.871999999996,4608.0,2304.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,144.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",462,76032.0,2304.0,152064.0,0,0.0,154368.0,154368.0,0.0,2880.0,0.0,18432.0,0.0,3.04,2450.911999999996,2304.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,0.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",463,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2453.5039999999963,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.72,2456.223999999996,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",465,24576.0,866304.0,0.0,0,0.0,866304.0,866304.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,10.272,2466.495999999996,667392.0,149760.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,645120.0,1210368.0,104448.0,0,0.0,1314816.0,1314816.0,2880.0,36960.0,0.07228915662650602,2396160.0,12288.0,7.136,2473.631999999996,24576.0,0.0,592896.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,74880.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",467,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.816,2476.447999999996,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",468,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2479.2959999999957,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",469,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2481.887999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",470,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.024,2486.9119999999957,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",471,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147648.0,0.01913265306122449,9597824.0,12288.0,15.68,2502.5919999999956,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299932.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",472,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.72,2505.3119999999954,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",473,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.784,2508.0959999999955,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",474,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2510.6559999999954,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.784,2513.4399999999955,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",476,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2515.9679999999953,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,18252.0,44952.0,768.0,0,0.0,45720.0,45720.0,0.0,48.0,0.0,12288.0,12288.0,2.752,2518.7199999999953,3072.0,6144.0,17868.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",478,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2521.247999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",479,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2523.807999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",480,2414592.0,4749312.0,104448.0,0,0.0,4853760.0,4853760.0,2880.0,147552.0,0.01914486279514997,9585184.0,12288.0,15.584,2539.391999999995,24576.0,0.0,2362368.0,52224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299537.0,384.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",481,768.0,3840.0,1536.0,0,0.0,5376.0,5376.0,0.0,3840.0,0.0,12288.0,1536.0,2.848,2542.239999999995,3072.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",482,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,2545.119999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2547.711999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",484,6225.0,21693.0,768.0,0,0.0,22461.0,22461.0,17.0,68.0,0.2,9216.0,3136.0,5.248,2552.959999999995,6028.0,3983.0,5841.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,98.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",485,40205600.0,84382175.0,3216448.0,0,0.0,87598623.0,87598623.0,1608277.0,1382113.0,0.5378151344807868,158803200.0,188416.0,174.656,2727.615999999995,2362079.0,4825344.0,38597376.0,1608224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4962600.0,5888.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2729.631999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.592,2732.223999999995,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2734.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",489,0.0,51200.0,0.0,0,0.0,51200.0,51200.0,0.0,790.0,0.0,201056.0,201056.0,2.816,2737.4719999999948,0.0,51200.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2739.5199999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",491,75601.0,0.0,151202.0,0,0.0,151202.0,151202.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.0,2743.5199999999945,0.0,0.0,0.0,75601.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",492,43200.0,0.0,86400.0,0,0.0,86400.0,86400.0,3300.0,20652.0,0.1377755511022044,1284800.0,0.0,5.984,2749.5039999999944,0.0,0.0,0.0,43200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",493,25448.0,0.0,50896.0,0,0.0,50896.0,50896.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.192,2753.6959999999945,0.0,0.0,0.0,25448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",494,52800.0,0.0,105600.0,0,0.0,105600.0,105600.0,3300.0,20952.0,0.13607125185551708,1284800.0,0.0,6.112,2759.8079999999945,0.0,0.0,0.0,52800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",495,25347.0,0.0,50694.0,0,0.0,50694.0,50694.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,3.936,2763.7439999999947,0.0,0.0,0.0,25347.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",496,49600.0,0.0,99200.0,0,0.0,99200.0,99200.0,3300.0,20852.0,0.1366346472341835,1284800.0,0.0,5.856,2769.599999999995,0.0,0.0,0.0,49600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",497,25345.0,0.0,50690.0,0,0.0,50690.0,50690.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,4.224,2773.823999999995,0.0,0.0,0.0,25345.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",498,44800.0,0.0,89600.0,0,0.0,89600.0,89600.0,3300.0,20702.0,0.13748854262144822,1284800.0,32.0,5.984,2779.807999999995,0.0,0.0,0.0,44800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",499,406.0,0.0,812.0,0,0.0,812.0,812.0,0.0,6.0,0.0,1632.0,224.0,3.136,2782.943999999995,0.0,0.0,0.0,406.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2784.9919999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",501,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,224.0,0.0,4.256,2789.2479999999946,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,2791.2639999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",503,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,224.0,0.0,4.544,2795.8079999999945,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",504,63332.0,0.0,126664.0,0,0.0,126664.0,126664.0,9020.0,3249.0,0.7351862417474937,207360.0,2176.0,5.984,2801.7919999999945,0.0,0.0,0.0,63332.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6480.0,68.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",505,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.92,2807.7119999999945,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,4713.0,0.0,203744.0,12576.0,4.096,2811.8079999999945,0.0,0.0,0.0,100514.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6367.0,393.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",507,6400.0,0.0,12800.0,0,0.0,12800.0,12800.0,0.0,1185.0,0.0,251328.0,0.0,2.976,2814.7839999999946,0.0,0.0,0.0,6400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",508,201971.0,0.0,403942.0,0,0.0,403942.0,403942.0,0.0,1571.0,0.0,0.0,402080.0,2.464,2817.2479999999946,0.0,0.0,0.0,201971.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",509,387271.0,0.0,774542.0,0,0.0,774542.0,774542.0,64512.0,1571.0,0.9762268662137009,201056.0,0.0,3.872,2821.1199999999944,0.0,0.0,0.0,387271.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,2823.7439999999942,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",511,49536.0,0.0,99072.0,0,0.0,99072.0,99072.0,16978.0,6804.0,0.7139012698679674,650240.0,461664.0,14.528,2838.271999999994,0.0,0.0,0.0,49536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20320.0,14427.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",512,19200.0,0.0,38400.0,0,0.0,38400.0,38400.0,4766.0,6871.0,0.40955572742115665,650240.0,613632.0,13.056,2851.327999999994,0.0,0.0,0.0,19200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20320.0,19176.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",513,21888.0,0.0,43776.0,0,0.0,43776.0,43776.0,5746.0,6758.0,0.459532949456174,647168.0,613632.0,13.632,2864.959999999994,0.0,0.0,0.0,21888.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20224.0,19176.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",514,21888.0,0.0,43776.0,0,0.0,43776.0,43776.0,5746.0,6778.0,0.4587991057170233,647168.0,508160.0,13.664,2878.6239999999943,0.0,0.0,0.0,21888.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20224.0,15880.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",515,819503.0,1663761.0,231810.0,0,0.0,1895571.0,1895571.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,25.44,2904.0639999999944,206308.0,50257.0,703598.0,115905.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18849.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",516,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,480.0,2.24,2906.303999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",517,3457.0,135689.0,6914.0,0,0.0,142603.0,142603.0,6909.0,3226.0,0.6816970892945239,213696.0,202720.0,4.384,2910.687999999994,135689.0,0.0,0.0,3457.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6678.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,209.0,0.0,418.0,0,0.0,418.0,418.0,0.0,790.0,0.0,201056.0,50208.0,2.688,2913.3759999999943,0.0,0.0,0.0,209.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",519,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,2915.3919999999944,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,106867.0,0.0,213734.0,0,0.0,213734.0,213734.0,0.0,4713.0,0.0,452352.0,19488.0,8.928,2924.3199999999943,0.0,0.0,0.0,106867.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,14136.0,609.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",521,6400.0,0.0,12800.0,0,0.0,12800.0,12800.0,0.0,1185.0,0.0,251328.0,0.0,3.072,2927.3919999999944,0.0,0.0,0.0,6400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",522,819506.0,1663761.0,231816.0,0,0.0,1895577.0,1895577.0,132.0,1676.0,0.07300884955752213,603168.0,201056.0,25.312,2952.7039999999943,206308.0,50257.0,703598.0,115908.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18849.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",523,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.504,2966.207999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,2968.671999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",525,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.344,2982.015999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2984.447999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",527,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,2987.039999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2990.303999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",529,1536.0,54833.0,3072.0,0,0.0,57905.0,57905.0,62.0,395.0,0.13566739606126915,201056.0,32.0,13.504,3003.807999999994,54833.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",530,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,3006.207999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,3008.639999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,3011.839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",533,706048.0,1008290.0,504320.0,0,0.0,1512610.0,1512610.0,0.0,1571.0,0.0,0.0,201056.0,3.136,3014.9759999999937,0.0,100514.0,453888.0,252160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",534,307537.0,512000.0,103074.0,0,0.0,615074.0,615074.0,0.0,1185.0,0.0,402112.0,0.0,3.872,3018.8479999999936,0.0,0.0,256000.0,51537.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",535,27176.0,0.0,54352.0,0,0.0,54352.0,54352.0,124.0,395.0,0.23892100192678228,201056.0,32.0,18.048,3036.8959999999934,0.0,0.0,0.0,27176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",536,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,3039.3599999999933,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",537,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,3041.7599999999934,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,3044.2559999999935,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,3046.7839999999933,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.496,3049.2799999999934,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",541,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,3051.2959999999935,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",542,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3053.3439999999932,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",543,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.464,3055.807999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",544,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.112,3057.9199999999933,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",545,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.4,3060.3199999999933,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",546,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,3062.847999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,3065.279999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",548,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,3068.351999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",549,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,3071.519999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",550,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,3074.047999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
