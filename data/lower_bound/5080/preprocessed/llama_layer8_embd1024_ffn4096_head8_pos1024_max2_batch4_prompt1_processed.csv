Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.76,1.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.3280000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,7.008,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.632,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,12.128,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.096,16.224,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.296,19.52,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,21.951999999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,24.031999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,26.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.208,28.287999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,31.295999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,33.791999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,36.25599999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.912,39.16799999999999,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,41.599999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,43.99999999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.56,46.559999999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,4352.0,16384.0,4.256,50.815999999999995,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.816,53.632,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.424,57.056,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.752,59.808,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.688,62.496,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.528,65.024,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.264,68.288,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.624,70.91199999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.232,74.14399999999999,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.72,76.86399999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.624,79.48799999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,83.45599999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,85.88799999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,88.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.2,91.776,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,94.944,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16384.0,9.952,104.896,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16384.0,9.696,114.592,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16384.0,9.824,124.416,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,127.616,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,130.656,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,134.27200000000002,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,137.40800000000002,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.752,140.16000000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,143.26400000000004,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,146.36800000000005,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.84,150.20800000000006,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,153.40800000000004,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,155.96800000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,176.09600000000006,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570560.0,16384.0,10.048,186.14400000000006,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174080.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,188.67200000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,191.20000000000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,195.13600000000005,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,197.50400000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,200.09600000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,203.26400000000007,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,206.30400000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19229952.0,65984.0,23.04,229.34400000000005,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,600936.0,2062.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,232.35200000000006,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18998656.0,65888.0,23.776,256.12800000000004,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,593708.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.784,258.91200000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22292992.0,16416.0,29.952,288.86400000000003,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696656.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,291.42400000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.624,294.04800000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,297.88800000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,300.32000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,302.91200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,305.95200000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,309.0880000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571328.0,16416.0,9.792,318.88000000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174104.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571840.0,16384.0,9.856,328.73600000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174120.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5576064.0,16384.0,10.24,338.97600000000006,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174252.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,342.1120000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,345.12000000000006,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,348.73600000000005,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,351.9680000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,354.56000000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,357.6960000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,360.7360000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,364.3840000000001,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,367.52000000000015,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,370.08000000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,390.20800000000014,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572736.0,16384.0,10.336,400.54400000000015,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174148.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,403.0720000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,405.6320000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,409.5040000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,412.00000000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,414.59200000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,417.69600000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,420.76800000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19114368.0,65728.0,23.936,444.7040000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,597324.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.944,447.64800000000014,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19196032.0,65792.0,23.296,470.94400000000013,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,599876.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.944,473.88800000000015,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22300160.0,16416.0,30.08,503.96800000000013,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696880.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,506.52800000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,509.08800000000014,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,512.9920000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,515.3920000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,517.9840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,521.1520000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,524.1920000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571328.0,16384.0,9.632,533.8240000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174104.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16416.0,9.568,543.392,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571456.0,16384.0,9.952,553.344,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174108.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,556.6080000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,559.648,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,563.328,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,566.4639999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,569.0239999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,572.2879999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,575.4239999999999,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,579.0399999999998,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,582.2079999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,584.7679999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.224,604.9919999999998,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5574656.0,16384.0,9.952,614.9439999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174208.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,617.5359999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,620.0959999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,624.0639999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,626.4959999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,629.0879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.2,632.2879999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,635.3599999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19198720.0,65760.0,23.008,658.3679999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,599960.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.2,661.5679999999999,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19012608.0,65792.0,23.936,685.5039999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,594144.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.752,688.2559999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22286976.0,16416.0,29.504,717.7599999999999,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696468.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,720.4159999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,722.9439999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,726.8479999999998,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,729.2479999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,731.8399999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,735.0079999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,738.0799999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5583872.0,16384.0,9.92,747.9999999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174496.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571712.0,16416.0,9.632,757.6319999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174116.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573504.0,16384.0,9.952,767.5839999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174172.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,770.8799999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,773.9199999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,777.5359999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,780.7359999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,783.3279999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,786.4959999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,789.5359999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.712,793.2479999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,796.4479999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,799.0719999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.16,819.2319999999997,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573632.0,16384.0,10.016,829.2479999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174176.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.72,831.9679999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,834.5279999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,838.3679999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,840.8319999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,843.4239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,846.4959999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,849.5359999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19086720.0,65856.0,23.936,873.4719999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596460.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.88,876.3519999999997,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19254272.0,65568.0,23.776,900.1279999999997,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,601696.0,2049.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,902.7839999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22296064.0,16384.0,29.568,932.3519999999996,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696752.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,934.9119999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,937.4399999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,941.2799999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,943.6799999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,946.2719999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,949.4399999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.2,952.6399999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571712.0,16384.0,9.76,962.3999999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174116.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570560.0,16384.0,9.792,972.1919999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174080.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571584.0,16384.0,10.08,982.2719999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174112.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,985.5039999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,988.5119999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,992.1279999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,995.2959999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,997.8879999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,1001.0879999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,1004.1279999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.584,1007.7119999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,1010.8799999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.848,1013.7279999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.064,1033.7919999999997,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16384.0,9.696,1043.4879999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1046.0479999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,1048.5439999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1052.4479999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,1054.9439999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1057.5039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1060.5759999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1063.6479999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19562112.0,66080.0,24.192,1087.8399999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611316.0,2065.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.976,1090.8159999999996,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19109504.0,65760.0,23.552,1114.3679999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,597172.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.688,1117.0559999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22303104.0,16384.0,30.368,1147.4239999999995,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696972.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1149.9839999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,1152.5119999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,1156.3519999999994,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1158.7519999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1161.2799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.136,1164.4159999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,1167.5519999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571840.0,16384.0,9.856,1177.4079999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174120.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16384.0,10.08,1187.4879999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16384.0,10.112,1197.5999999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,1200.9279999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,1204.0319999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.712,1207.7439999999995,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,1210.9759999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1213.5359999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,1216.7679999999993,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.168,1219.9359999999992,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,1223.5839999999992,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,1226.7839999999992,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1229.3439999999991,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.448,1249.7919999999992,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16384.0,9.888,1259.6799999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1262.239999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,1264.7679999999991,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,1268.607999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1271.0079999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1273.5999999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,1276.7039999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1279.7759999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18923136.0,65792.0,23.392,1303.1679999999992,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,591348.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.912,1306.0799999999992,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19146240.0,65792.0,23.68,1329.7599999999993,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598320.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1332.4159999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22286848.0,16384.0,30.752,1363.1679999999992,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696464.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,1365.6959999999992,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,1368.2879999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.808,1372.0959999999993,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1374.4959999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1377.0559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1380.1279999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,1383.2639999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573120.0,16416.0,10.048,1393.3119999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174160.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16416.0,9.568,1402.8799999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573376.0,16384.0,9.856,1412.7359999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174168.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,1415.9359999999992,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,1419.0079999999991,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,1422.6239999999991,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.072,1425.695999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1428.319999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,1431.455999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,1434.5279999999989,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,1438.1759999999988,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,1441.3119999999988,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,1443.8399999999988,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.288,1464.1279999999988,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571456.0,16384.0,9.632,1473.7599999999989,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174108.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1476.3199999999988,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,1478.911999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1482.815999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1485.343999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1487.935999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.2,1491.135999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,1494.239999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19220480.0,65632.0,23.648,1517.887999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,600640.0,2051.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,1520.959999999999,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18949888.0,65856.0,22.912,1543.871999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,592184.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1546.5279999999989,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22288512.0,16384.0,30.304,1576.831999999999,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696516.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1579.391999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,1581.887999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1585.759999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1588.223999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1590.847999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,1593.887999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.264,1597.151999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572992.0,16384.0,9.6,1606.7519999999988,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174156.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16384.0,9.792,1616.5439999999987,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.6,1626.1439999999986,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,1629.2799999999986,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,1632.3199999999986,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,1635.9999999999986,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,1639.2639999999985,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,1641.7919999999986,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,1645.0559999999984,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,1648.0639999999985,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.776,1651.8399999999986,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,1654.9439999999986,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,1657.5999999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,1677.7279999999985,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573504.0,16384.0,9.664,1687.3919999999985,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174172.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1690.0159999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.688,1692.7039999999986,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.128,1696.8319999999985,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1699.2319999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1701.8879999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1704.9599999999984,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,1708.1279999999983,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19161984.0,65856.0,23.36,1731.4879999999982,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598812.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,1734.4959999999983,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19109504.0,65696.0,23.04,1757.5359999999982,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,597172.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.816,1760.3519999999983,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22310400.0,16384.0,29.92,1790.2719999999983,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697200.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1792.8319999999983,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,1795.3599999999983,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,1799.1999999999982,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1801.7279999999982,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1804.2879999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1807.359999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1810.431999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,1048896000.0,2102272000.0,640000.0,0,0.0,2102912000.0,2102912000.0,3407000.0,20000.0,0.9941639918295886,135134560.0,2560000.0,174.08,1984.511999999998,0.0,5120000.0,1048576000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4222955.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.496,1995.007999999998,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1997.055999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.528,1999.583999999998,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2002.015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.072,2005.087999999998,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2007.135999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.064,2011.199999999998,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.896,2016.095999999998,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,65272.0,0.0,130544.0,0,0.0,130544.0,130544.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.256,2020.351999999998,0.0,0.0,0.0,65272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,0.0,4.704,2025.055999999998,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,64528.0,0.0,129056.0,0,0.0,129056.0,129056.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,3.936,2028.991999999998,0.0,0.0,0.0,64528.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,106496.0,0.0,212992.0,0,0.0,212992.0,212992.0,8448.0,34312.0,0.19756782039289056,2106624.0,0.0,4.672,2033.663999999998,0.0,0.0,0.0,106496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,3.968,2037.631999999998,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,8448.0,35080.0,0.19408197022606138,2106624.0,128.0,4.672,2042.303999999998,0.0,0.0,0.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.104,2045.407999999998,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2047.487999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.384,2051.871999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2053.919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.416,2058.335999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,23616.0,8432.0,0.7368946580129805,525824.0,6912.0,6.048,2064.3839999999977,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,216.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.24,2070.6239999999975,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.096,2074.7199999999975,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.168,2077.8879999999976,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.136,2081.0239999999976,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387723.0,0.0,775446.0,0,0.0,775446.0,775446.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.224,2085.247999999998,0.0,0.0,0.0,387723.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,2087.839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17697.0,0.7018548781104166,1697152.0,1230720.0,15.616,2103.455999999998,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53036.0,38460.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17719.0,0.34863801786567655,1695488.0,1560832.0,13.088,2116.543999999998,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52984.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17568.0,0.38009880028228654,1689856.0,1560960.0,14.272,2130.815999999998,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52808.0,48780.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17647.0,0.3790421900840987,1687808.0,1193504.0,14.08,2144.895999999998,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52744.0,37297.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.352,2149.247999999998,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,2151.839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9497.0,0.5264758675708018,1161472.0,818272.0,7.808,2159.647999999998,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36296.0,25571.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548160.0,1536000.0,4.544,2164.1919999999977,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48380.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1006336.0,512000.0,18.656,2182.8479999999977,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31448.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.296,2234.1439999999975,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.008,2237.1519999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,2239.295999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,49216.0,8.928,2248.223999999997,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.264,2251.487999999997,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1005312.0,512000.0,18.08,2269.567999999997,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31416.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.64,2298.207999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2300.6399999999967,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.8,2329.439999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2331.8719999999967,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,2334.4639999999968,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,2337.7599999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.728,2347.4879999999966,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,2349.9199999999964,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,2353.1839999999966,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2355.6159999999963,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,2358.7839999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.064,2362.8479999999963,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,4.544,2367.391999999996,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.864,2380.255999999996,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,2382.6559999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2385.087999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,2387.583999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,2390.0799999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.56,2392.6399999999962,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.016,2394.6559999999963,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2396.703999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.592,2399.295999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2401.343999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.496,2403.839999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.632,2409.471999999996,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.464,2411.935999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.496,2414.431999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,2417.535999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.296,2420.831999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2423.231999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2425.6639999999957,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.36,2429.023999999996,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,2431.9679999999958,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.4,2434.367999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.432,2436.7999999999956,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.56,2439.3599999999956,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.496,2441.8559999999957,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,16640.0,16384.0,5.216,2447.0719999999956,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.752,2449.8239999999955,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.36,2453.1839999999956,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.848,2456.0319999999956,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.56,2458.5919999999956,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.592,2461.1839999999956,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.232,2464.4159999999956,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2466.9439999999954,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.264,2470.2079999999955,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.56,2472.7679999999955,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.688,2475.4559999999956,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,2479.2959999999957,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2481.7599999999957,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2484.3519999999958,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,2487.3919999999957,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.232,2490.6239999999957,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570816.0,16384.0,9.632,2500.2559999999958,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174088.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573120.0,16384.0,9.952,2510.207999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174160.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570560.0,16384.0,9.888,2520.095999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174080.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,2523.263999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,2526.399999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,2530.079999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,2533.2799999999957,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2535.8399999999956,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2538.9759999999956,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,2.976,2541.9519999999957,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,2545.599999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2548.735999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2551.2959999999957,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,2553.9199999999955,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,2556.5119999999956,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.48,2576.9919999999956,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16416.0,9.856,2586.847999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2589.407999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,2591.9359999999956,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,2595.9039999999954,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2598.3039999999955,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2600.8959999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,2603.9999999999955,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,2607.0399999999954,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19506048.0,65760.0,23.008,2630.047999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,609564.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,2633.055999999995,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19071872.0,65856.0,23.392,2656.447999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,595996.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.88,2659.327999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22285952.0,16384.0,29.6,2688.927999999995,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696436.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,2691.583999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,2694.1119999999946,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,2697.9839999999945,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,2700.5439999999944,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2703.1039999999944,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,2706.1759999999945,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,2709.2479999999946,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572992.0,16384.0,9.824,2719.0719999999947,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174156.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16416.0,9.664,2728.735999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,513.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5574144.0,16384.0,10.016,2738.751999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174192.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2741.887999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,2744.927999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.584,2748.5119999999947,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,2751.679999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,2754.2079999999946,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,2757.4399999999946,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,2760.5119999999947,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,2764.159999999995,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,2767.3599999999947,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2769.9199999999946,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,2772.5119999999947,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,2775.103999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.32,2795.423999999995,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5574016.0,16416.0,9.792,2805.215999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174188.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,2807.871999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,2810.431999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.808,2814.239999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2816.639999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2819.199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,2822.271999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,2825.3759999999947,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18927872.0,65760.0,24.288,2849.6639999999948,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,591496.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.88,2852.543999999995,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19085056.0,65696.0,23.776,2876.3199999999947,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596408.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.944,2879.2639999999947,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22308864.0,16384.0,30.272,2909.5359999999946,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697152.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,2912.0639999999944,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,2914.591999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,2918.559999999994,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2920.959999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2923.551999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,2926.655999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,2929.823999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572864.0,16384.0,9.696,2939.519999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174152.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572480.0,16384.0,9.824,2949.343999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174140.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16416.0,9.664,2959.0079999999944,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2962.1439999999943,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,2965.1839999999943,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.776,2968.959999999994,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2972.095999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2974.655999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,2977.791999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,2.976,2980.767999999994,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,2984.4159999999943,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,2987.7439999999942,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,2990.303999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.656,2992.959999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,2995.647999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.256,3015.903999999994,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572480.0,16384.0,9.856,3025.7599999999943,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174140.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,3028.287999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3030.815999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.776,3034.5919999999937,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3036.991999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3039.679999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,3042.847999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,3045.951999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19214848.0,65728.0,22.592,3068.543999999994,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,600464.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,3071.5519999999938,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18866944.0,65664.0,23.2,3094.7519999999936,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,589592.0,2052.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.752,3097.5039999999935,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22295296.0,16384.0,29.696,3127.1999999999935,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696728.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3129.7599999999934,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3132.287999999993,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3136.159999999993,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3138.591999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3141.1519999999928,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3144.223999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,3147.263999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5583872.0,16384.0,9.824,3157.087999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174496.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571584.0,16384.0,10.144,3167.2319999999927,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174112.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573504.0,16416.0,9.696,3176.9279999999926,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174172.0,513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3180.0959999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,3183.1359999999927,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.552,3186.687999999993,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,3190.015999999993,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3192.5759999999927,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,3195.8719999999926,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,2.976,3198.8479999999927,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,3202.4639999999927,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,3205.7599999999925,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3208.4159999999924,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,3211.1039999999925,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3213.7279999999923,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.48,3234.2079999999924,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.824,3244.0319999999924,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3246.5919999999924,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,3249.1839999999925,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.776,3252.9599999999923,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3255.4239999999922,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3258.0159999999923,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,3261.119999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,3264.159999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18978048.0,65632.0,23.392,3287.551999999992,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,593064.0,2051.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,3290.5599999999918,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19024384.0,65952.0,23.168,3313.727999999992,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,594512.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3316.383999999992,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22300928.0,16384.0,29.632,3346.015999999992,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696904.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3348.575999999992,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3351.1039999999916,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,3354.943999999992,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3357.343999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3359.903999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3362.975999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.264,3366.239999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5575040.0,16384.0,9.632,3375.871999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174220.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.568,3385.4399999999923,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16384.0,9.92,3395.3599999999924,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,3398.4959999999924,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,3401.5679999999925,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.744,3405.3119999999926,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,3408.5439999999926,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3411.1039999999925,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,3414.3679999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,3417.439999999993,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.808,3421.2479999999928,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,3424.3839999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,3426.9119999999925,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3429.5039999999926,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,3432.0639999999926,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.416,3452.4799999999927,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,10.24,3462.7199999999925,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3465.3119999999926,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,3467.8719999999926,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,3471.8079999999927,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3474.2399999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3476.8639999999923,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.136,3479.9999999999923,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,3483.1679999999924,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19700224.0,65984.0,23.2,3506.367999999992,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615632.0,2062.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,3509.4399999999923,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19230336.0,65984.0,23.424,3532.8639999999923,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,600948.0,2062.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,3535.583999999992,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22292224.0,16384.0,29.376,3564.9599999999923,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696632.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3567.5199999999923,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3570.047999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3573.919999999992,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3576.319999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3578.911999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3581.983999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,3585.1519999999923,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,10.08,3595.2319999999922,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5574016.0,16384.0,9.984,3605.215999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174188.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16384.0,10.016,3615.2319999999922,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,3618.463999999992,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,3621.5359999999923,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,3625.1839999999925,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3628.3519999999926,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3630.9439999999927,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,3634.2719999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,3637.3119999999926,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.84,3641.1519999999928,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,3644.3839999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3646.975999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3649.567999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3652.159999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.256,3672.415999999993,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572224.0,16384.0,10.048,3682.4639999999927,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174132.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3685.0559999999928,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,3687.6159999999927,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,3691.455999999993,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3694.015999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3696.6719999999927,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,3699.7119999999927,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,3702.8159999999925,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19030656.0,65952.0,23.488,3726.3039999999924,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,594708.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.976,3729.2799999999925,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19174144.0,65952.0,23.584,3752.8639999999923,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,599192.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.784,3755.6479999999924,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22302592.0,16416.0,29.664,3785.3119999999926,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696956.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3787.8719999999926,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3790.3999999999924,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,3794.2399999999925,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3796.6719999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3799.2319999999922,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3802.3039999999924,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,3805.4719999999925,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570816.0,16384.0,10.4,3815.8719999999926,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174088.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571456.0,16384.0,9.888,3825.7599999999925,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174108.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16384.0,9.952,3835.7119999999927,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,3838.8479999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,3841.8559999999925,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,3845.5039999999926,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3848.6719999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,3851.2959999999925,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3854.4639999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,3857.5679999999925,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,3861.2159999999926,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3864.3839999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,3867.071999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3869.663999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,3872.255999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.352,3892.607999999993,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.76,3902.367999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,3904.895999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3907.4239999999927,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,3911.4239999999927,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3913.8559999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3916.4799999999923,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3919.5519999999924,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,3922.5919999999924,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19302656.0,65792.0,22.944,3945.5359999999923,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,603208.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.944,3948.4799999999923,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19152640.0,65792.0,22.784,3971.2639999999924,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598520.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3973.9199999999923,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22287232.0,16416.0,29.44,4003.3599999999924,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696476.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4005.9519999999925,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,4008.5439999999926,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,4012.4159999999924,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4014.8799999999924,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,4017.6319999999923,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4020.7039999999924,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,4023.7759999999926,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.6,4033.3759999999925,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572480.0,16384.0,9.952,4043.3279999999927,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174140.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572224.0,16416.0,9.792,4053.1199999999926,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174132.0,513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.36,4056.4799999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,4059.5199999999927,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,4063.1359999999927,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4066.2719999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4068.8319999999926,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4071.9999999999927,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,4075.1039999999925,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,4078.7519999999927,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4081.919999999993,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4084.4799999999927,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,4087.167999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,4089.855999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.288,4110.143999999993,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16416.0,9.92,4120.063999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4122.655999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,4125.247999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.84,4129.0879999999925,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4131.583999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4134.143999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,4137.311999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,4140.383999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18992000.0,65856.0,23.584,4163.967999999993,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,593500.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,4167.039999999993,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19559552.0,66048.0,22.88,4189.919999999993,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611236.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,4192.639999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22314752.0,16384.0,29.312,4221.951999999993,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697336.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4224.511999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,4227.071999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,4230.943999999994,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4233.343999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4235.935999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,4238.975999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,4242.047999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,1048896000.0,2102272000.0,640000.0,0,0.0,2102912000.0,2102912000.0,3407000.0,20000.0,0.9941639918295886,135128832.0,2560000.0,175.104,4417.151999999994,0.0,5120000.0,1048576000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4222776.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.624,4427.7759999999935,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.176,4429.951999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.528,4432.479999999994,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4435.0399999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.072,4438.111999999995,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4440.159999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.096,4444.255999999994,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.736,4448.991999999994,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,65308.0,0.0,130616.0,0,0.0,130616.0,130616.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.064,4453.055999999994,0.0,0.0,0.0,65308.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,0.0,4.864,4457.919999999994,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64525.0,0.0,129050.0,0,0.0,129050.0,129050.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,4462.271999999994,0.0,0.0,0.0,64525.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,4.896,4467.167999999993,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.224,4471.3919999999935,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,8448.0,34632.0,0.19610027855153203,2106624.0,128.0,4.992,4476.383999999994,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.168,4479.551999999993,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,4481.567999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.512,4486.079999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4488.127999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.352,4492.479999999992,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,32431.0,8426.0,0.7937685096801038,525824.0,7072.0,6.304,4498.783999999992,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,221.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.208,4504.991999999992,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.384,4509.375999999992,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.104,4512.479999999992,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.104,4515.583999999993,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387718.0,0.0,775436.0,0,0.0,775436.0,775436.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.256,4519.839999999993,0.0,0.0,0.0,387718.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,4522.4319999999925,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17801.0,0.7006273019289955,1702144.0,1180320.0,15.808,4538.2399999999925,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53192.0,36885.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,48640.0,0.0,97280.0,0,0.0,97280.0,97280.0,12292.0,17770.0,0.40888829751846184,1694208.0,1446976.0,13.376,4551.615999999993,0.0,0.0,0.0,48640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52944.0,45218.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17675.0,0.3786691039476922,1687552.0,1560960.0,14.24,4565.8559999999925,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52736.0,48780.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17660.0,0.3788688801350591,1691648.0,1194528.0,14.432,4580.287999999992,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52864.0,37329.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.192,4584.479999999992,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,4587.103999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9644.0,0.522645151710142,1158144.0,819072.0,7.744,4594.847999999992,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36192.0,25596.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1549120.0,1536000.0,4.416,4599.263999999992,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48410.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1015424.0,512000.0,18.4,4617.663999999992,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31732.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,50.72,4668.383999999992,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.168,4671.5519999999915,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.112,4673.663999999992,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,49888.0,8.992,4682.655999999992,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1559.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.168,4685.823999999991,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1005056.0,512000.0,18.72,4704.543999999992,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31408.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.608,4733.151999999992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,4735.615999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.512,4764.1279999999915,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.496,4766.623999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,4769.151999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,4772.415999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.664,4782.079999999992,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,4784.5119999999915,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,4787.775999999992,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4790.207999999991,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,4793.471999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.064,4797.535999999992,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,4.544,4802.079999999992,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.768,4814.847999999992,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,4817.279999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4819.711999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.592,4822.303999999991,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,4824.767999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.592,4827.359999999991,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4829.40799999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4831.45599999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,4833.95199999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4835.99999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.496,4838.49599999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.696,4844.19199999999,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,4846.68799999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,4849.11999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,4852.22399999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.296,4855.51999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,4857.91999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
