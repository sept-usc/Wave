Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,2.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.984,4.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,6.08,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.432,8.512,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.008,11.52,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.944,14.463999999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.808,18.272,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.68,21.951999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.008,24.959999999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,27.327999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,29.695999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.464,32.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.328,35.488,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,38.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.752,40.992000000000004,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.168,44.160000000000004,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,46.912000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.72,49.632000000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,3.04,52.672000000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,8704.0,32768.0,4.544,57.216,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.36,60.576,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.872,64.44800000000001,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,3.072,67.52000000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.752,70.272,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.008,73.28,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.744,77.024,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,3.008,80.032,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.616,83.648,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.816,86.464,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.944,89.408,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.472,94.88,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,97.6,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,100.60799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.488,104.09599999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,107.45599999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19826944.0,32832.0,24.544,132.0,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619592.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19717504.0,32800.0,24.512,156.512,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616172.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19853952.0,32800.0,24.8,181.312,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,620436.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,184.83200000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.648,188.48000000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.288,192.76800000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,196.22400000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,199.20000000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.392,202.592,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.584,206.17600000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.16,210.336,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.392,213.728,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,216.64000000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.384,237.024,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19788160.0,32800.0,24.864,261.888,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618380.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.104,264.99199999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,267.80799999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.184,272.99199999999996,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,275.74399999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,278.62399999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.328,281.95199999999994,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,285.31199999999995,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83275008.0,136672.0,79.936,365.24799999999993,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2602344.0,4271.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.36,368.60799999999995,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84882048.0,137632.0,79.296,447.90399999999994,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2652564.0,4301.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.072,450.97599999999994,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78465280.0,32832.0,96.256,547.232,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2452040.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,550.208,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,553.024,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.184,558.208,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,560.9599999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,563.8079999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.36,567.1679999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,570.56,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19746304.0,32832.0,25.472,596.0319999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617072.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19994880.0,32832.0,23.904,619.9359999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,624840.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19724160.0,32832.0,25.312,645.2479999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616380.0,1026.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,648.736,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,652.288,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,656.48,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,660.0,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,662.848,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,666.304,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.584,669.8879999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.256,674.1439999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.648,677.7919999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,680.6719999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.48,701.1519999999999,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19681920.0,32800.0,25.28,726.4319999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615060.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,729.3119999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.784,732.0959999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.344,737.4399999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,740.16,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,743.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.488,746.5600000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,749.9200000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84178688.0,138272.0,79.328,829.248,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2630584.0,4321.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,832.5440000000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84129280.0,135776.0,78.816,911.3600000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2629040.0,4243.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,914.4640000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78753920.0,32800.0,94.304,1008.7680000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2461060.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,1011.7440000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.944,1014.6880000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.152,1019.8400000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,1022.5600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,1025.4400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.552,1028.9920000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,1032.352,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19726720.0,32768.0,26.496,1058.8480000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616460.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19858048.0,32768.0,24.16,1083.0080000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,620564.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19670144.0,32768.0,26.816,1109.8240000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614692.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,1113.2800000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,1116.8000000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.384,1121.1840000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,1124.736,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.072,1127.808,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,1131.264,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,1134.8159999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.48,1139.2959999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,1142.8159999999998,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,1145.7279999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.448,1166.176,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19999616.0,32800.0,23.904,1190.08,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,624988.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,1192.96,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.04,1196.0,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.44,1201.44,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,1204.256,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,1207.0720000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.456,1210.528,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,1213.92,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84309888.0,135264.0,78.624,1292.544,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2634684.0,4227.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,1295.8400000000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84549376.0,137536.0,79.968,1375.8080000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2642168.0,4298.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,1378.9120000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78768512.0,32768.0,94.912,1473.8240000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2461516.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,1476.7360000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.008,1479.7440000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.312,1485.0560000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.656,1487.7120000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,1490.5920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.456,1494.0480000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,1497.4400000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19642880.0,32768.0,26.816,1524.2560000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613840.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19999616.0,32832.0,23.232,1547.4880000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,624988.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19644288.0,32768.0,26.592,1574.0800000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613884.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.616,1577.6960000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,1581.2160000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.16,1585.3760000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,1588.8320000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,1591.7440000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.616,1595.3600000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,1598.9120000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,1603.1040000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,1606.5600000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,1609.4080000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.704,1630.112,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19912832.0,32768.0,24.512,1654.624,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,622276.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,1657.664,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,1660.512,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.152,1665.664,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,1668.448,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.04,1671.488,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,1674.88,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.328,1678.208,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84243968.0,136512.0,80.032,1758.24,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2632624.0,4266.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,1761.536,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84759296.0,137504.0,78.848,1840.384,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2648728.0,4297.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.04,1843.424,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78915456.0,32768.0,91.648,1935.072,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2466108.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,1938.048,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.784,1940.832,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.28,1946.112,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,1948.832,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,1951.7120000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.456,1955.1680000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.488,1958.6560000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20010240.0,32928.0,24.736,1983.3920000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,625320.0,1029.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19607168.0,32864.0,26.528,2009.9200000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612724.0,1027.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20043648.0,32800.0,23.648,2033.5680000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,626364.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,2037.0560000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.584,2040.6400000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.32,2044.9600000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2048.416,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,2051.2960000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2054.7520000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,2058.3040000000005,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.352,2062.6560000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2066.1120000000005,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,2069.0240000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.64,2089.664,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19718016.0,32896.0,26.048,2115.712,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616188.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.008,2118.72,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,2121.5359999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.184,2126.72,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,2129.5359999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,2132.4159999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,2135.8079999999995,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,2139.1679999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84419840.0,138848.0,79.584,2218.7519999999995,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2638120.0,4339.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,2222.0479999999993,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83867648.0,137504.0,80.576,2302.6239999999993,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2620864.0,4297.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.2,2305.823999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78594560.0,32800.0,92.064,2397.887999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2456080.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,2400.799999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.976,2403.775999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.312,2409.087999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.912,2411.9999999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,2414.8799999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.36,2418.239999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,2421.6319999999987,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20133760.0,32800.0,23.68,2445.3119999999985,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,629180.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19643392.0,32800.0,26.304,2471.6159999999986,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613856.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20094336.0,32768.0,23.424,2495.0399999999986,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,627948.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2498.4959999999987,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,2502.0159999999987,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,2506.2079999999987,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,2509.6319999999987,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,2512.511999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,2515.935999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,2519.4559999999988,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,2523.647999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.392,2527.0399999999986,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,2530.0799999999986,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.48,2550.5599999999986,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19628288.0,32864.0,26.08,2576.6399999999985,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613384.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,2579.5519999999983,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2582.463999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.28,2587.7439999999983,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,2590.4319999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,2593.2159999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,2596.6079999999984,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,2599.9679999999985,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84661760.0,136768.0,79.264,2679.2319999999986,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2645680.0,4274.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,2682.5279999999984,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84578560.0,135584.0,79.008,2761.5359999999982,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2643080.0,4237.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.136,2764.671999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78493952.0,32768.0,96.288,2860.959999999998,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2452936.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,2863.999999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2866.911999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.152,2872.063999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,2874.815999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,2877.663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.552,2881.215999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.552,2884.767999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19657856.0,32800.0,26.464,2911.231999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614308.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19821056.0,32864.0,24.768,2935.999999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619408.0,1027.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19568128.0,32864.0,27.456,2963.4559999999983,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611504.0,1027.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,2966.8799999999983,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.776,2970.655999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.224,2974.8799999999983,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2978.3359999999984,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.104,2981.4399999999982,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,2984.8959999999984,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.456,2988.3519999999985,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.416,2992.7679999999987,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.392,2996.1599999999985,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,2999.0719999999983,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.768,3019.8399999999983,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20113536.0,32768.0,23.104,3042.943999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,628548.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,3045.855999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,3048.6719999999978,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.28,3053.951999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,3056.703999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,3059.5199999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.36,3062.879999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.424,3066.303999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83983872.0,137504.0,79.104,3145.4079999999976,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2624496.0,4297.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.328,3148.7359999999976,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84406272.0,136576.0,80.128,3228.8639999999978,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2637696.0,4268.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,3232.1599999999976,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78595456.0,32896.0,94.784,3326.9439999999977,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2456108.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,3329.823999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,3332.6399999999976,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.248,3337.8879999999976,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,3340.5759999999977,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,3343.4239999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,3346.8159999999975,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.424,3350.2399999999975,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19619968.0,32768.0,27.2,3377.4399999999973,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613124.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20020608.0,32800.0,23.648,3401.0879999999975,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,625644.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19674112.0,32768.0,26.528,3427.6159999999973,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614816.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,3431.1679999999974,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,3434.7199999999975,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,3438.9119999999975,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,3442.3359999999975,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,3445.2159999999976,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,3448.7679999999978,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,3452.2879999999977,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.288,3456.5759999999977,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,3460.031999999998,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,3462.9439999999977,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,20.576,3483.5199999999977,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19954432.0,32768.0,24.288,3507.8079999999977,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,623576.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,3510.7199999999975,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,3513.5359999999973,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.536,3519.0719999999974,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,3521.8239999999973,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,3524.6719999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,3528.063999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.488,3531.551999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83834880.0,135744.0,79.488,3611.039999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2619840.0,4242.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.328,3614.3679999999968,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84184704.0,136640.0,79.072,3693.439999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2630772.0,4270.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.168,3696.607999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,79502336.0,32864.0,87.104,3783.711999999997,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2484448.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,3786.7519999999968,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,3789.6639999999966,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.248,3794.9119999999966,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,3797.6959999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,3800.5439999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.552,3804.095999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,3807.455999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,2097472000.0,4199424000.0,640000.0,0,0.0,4200064000.0,4200064000.0,6479000.0,20000.0,0.9969226034774581,270305504.0,2560000.0,332.064,4139.519999999997,0.0,5120000.0,2097152000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8447047.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.464,4149.983999999997,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,4152.319999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.88,4155.199999999997,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,4157.919999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.456,4161.3759999999975,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.496,4163.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.448,4168.319999999998,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.376,4173.695999999998,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,69280.0,0.0,138560.0,0,0.0,138560.0,138560.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.512,4178.207999999998,0.0,0.0,0.0,69280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,126976.0,0.0,253952.0,0,0.0,253952.0,253952.0,8448.0,34952.0,0.19465437788018433,2106624.0,0.0,5.216,4183.423999999998,0.0,0.0,0.0,126976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,64520.0,0.0,129040.0,0,0.0,129040.0,129040.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.288,4187.711999999998,0.0,0.0,0.0,64520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,0.0,5.056,4192.767999999997,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.384,4197.151999999997,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,106496.0,0.0,212992.0,0,0.0,212992.0,212992.0,8448.0,34312.0,0.19756782039289056,2106624.0,128.0,5.056,4202.207999999997,0.0,0.0,0.0,106496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.392,4205.599999999997,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,4207.935999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.576,4212.511999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,4214.879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.64,4219.519999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,22960.0,8432.0,0.7313965341488278,525824.0,7488.0,6.368,4225.887999999998,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,234.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.656,4232.543999999998,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.512,4237.055999999998,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.712,4240.767999999998,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.52,4244.287999999999,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387750.0,0.0,775500.0,0,0.0,775500.0,775500.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.704,4248.991999999998,0.0,0.0,0.0,387750.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.04,4252.031999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17816.0,0.700450601923465,1698944.0,1208256.0,15.904,4267.935999999999,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53092.0,37758.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17693.0,0.348971556831144,1692928.0,1560832.0,13.184,4281.119999999999,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52904.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17739.0,0.3778190873697871,1688704.0,925088.0,14.752,4295.871999999999,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52772.0,28909.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17763.0,0.37750131417557387,1687680.0,1127776.0,15.008,4310.879999999999,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52740.0,35243.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.768,4315.647999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.944,4318.592,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9527.0,0.5256895349995021,1159680.0,819680.0,8.224,4326.816,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36240.0,25615.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1549184.0,1536000.0,4.64,4331.456,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48412.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1018240.0,512000.0,18.784,4350.24,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31820.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.424,4401.664,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.328,4404.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.72,4407.712,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,51808.0,9.696,4417.408,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1619.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.616,4421.024,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1004416.0,512000.0,18.72,4439.744000000001,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31388.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.96,4468.704000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.848,4471.552000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.056,4500.608,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.784,4503.392,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.848,4506.24,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.552,4509.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.92,4519.7119999999995,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,3.168,4522.879999999999,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,4.224,4527.103999999999,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.752,4529.856,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.52,4533.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.544,4537.92,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,5.12,4543.04,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.28,4556.32,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,4559.1359999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.944,4562.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,4564.928,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,4567.7119999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.88,4570.592,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,4572.928,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,4575.264,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.88,4578.144,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,4580.4800000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.816,4583.296,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.24,4589.536,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,4592.384,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.688,4595.072,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,4598.144,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.488,4601.6320000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.688,4604.320000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.816,4607.136,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.776,4610.912,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.168,4614.08,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.688,4616.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.784,4619.552,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.784,4622.335999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.944,4625.28,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,33280.0,32768.0,5.568,4630.848,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1040.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.944,4633.792,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.84,4637.6320000000005,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.88,4640.512000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.624,4643.136,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.072,4646.2080000000005,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.68,4649.888000000001,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.88,4652.768000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.776,4656.544000000001,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.848,4659.392000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,4662.304000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.216,4667.520000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,4670.272000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,4673.088000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,4676.480000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,4679.840000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19916800.0,32864.0,23.936,4703.776000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,622400.0,1027.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19797632.0,32800.0,24.832,4728.608000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618676.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19670912.0,32768.0,25.44,4754.048000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614716.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,4757.6,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,4761.152,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.352,4765.504,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,4768.928,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,4771.872,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,4775.424,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.584,4779.008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.544,4783.552,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,4787.04,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,4789.984,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.2,4793.184,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.976,4796.16,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,130848.0,12033462.0,0.0,0,0.0,12033462.0,12033462.0,66575.0,128.0,0.9980810458300227,163840.0,32768.0,20.64,4816.8,10186633.0,1585133.0,130848.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19586176.0,32832.0,27.232,4844.032,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612068.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,4846.944,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,4849.792,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.344,4855.136,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,4857.8240000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,4860.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.488,4864.160000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,4867.52,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84199168.0,137152.0,79.072,4946.592000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2631224.0,4286.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.52,4950.112000000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84736128.0,137984.0,80.256,5030.368000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2648004.0,4312.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.232,5033.600000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78274048.0,32832.0,96.96,5130.560000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446064.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,5133.472000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,5136.288000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.248,5141.536000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,5144.288000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,5147.1680000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,5150.5920000000015,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.552,5154.144000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19819904.0,32800.0,24.704,5178.848000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619372.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19798528.0,32800.0,24.928,5203.776000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618704.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19784320.0,32896.0,25.248,5229.024,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618260.0,1028.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,5232.448,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.648,5236.0960000000005,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.256,5240.352000000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.68,5244.032000000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,5246.944000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,5250.432000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.616,5254.048000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.48,5258.528000000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,5262.016000000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,5264.896000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.04,5267.9360000000015,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.072,5271.008000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,130816.0,12033378.0,0.0,0,0.0,12033378.0,12033378.0,66575.0,128.0,0.9980810458300227,163840.0,32768.0,20.992,5292.000000000002,10186616.0,1585130.0,130816.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19647872.0,32832.0,25.92,5317.920000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613996.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,5320.800000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,5323.616000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.152,5328.768000000002,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,5331.520000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.04,5334.560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,5337.984000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.552,5341.536000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84716800.0,137568.0,79.168,5420.7040000000015,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2647400.0,4299.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,5424.000000000002,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84675456.0,137120.0,78.752,5502.752000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2646108.0,4285.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,5505.8560000000025,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,79193216.0,32896.0,91.2,5597.056000000002,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2474788.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,5600.096000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,5603.264000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.408,5608.672000000002,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,5611.392000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.944,5614.336000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.328,5617.664000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,5621.024000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19644288.0,32768.0,26.4,5647.424000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613884.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19930240.0,32768.0,23.968,5671.392000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,622820.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19644800.0,32768.0,25.856,5697.248000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613900.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,5700.704000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.648,5704.352000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.576,5708.928000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,5712.384000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,5715.296000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,5718.752000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.648,5722.400000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.288,5726.688000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,5730.112000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.008,5733.120000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.104,5736.224000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.944,5739.168000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,130880.0,12033546.0,0.0,0,0.0,12033546.0,12033546.0,66566.0,128.0,0.9980807868773802,163840.0,32768.0,20.672,5759.840000000003,10186650.0,1585136.0,130880.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20027520.0,32768.0,24.032,5783.872000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,625860.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.008,5786.880000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,5789.728000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.216,5794.944000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,5797.632000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,5800.640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,5804.064000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,5807.424000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84621696.0,137184.0,78.4,5885.824000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2644428.0,4287.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.328,5889.152000000003,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84723456.0,136544.0,78.816,5967.968000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2647608.0,4267.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.072,5971.040000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,79163392.0,32864.0,90.368,6061.408000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2473856.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,6064.384000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.008,6067.392000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.408,6072.800000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,6075.520000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.944,6078.464000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.456,6081.920000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,6085.3120000000035,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19644544.0,32768.0,25.792,6111.104000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613892.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19862400.0,32800.0,24.192,6135.296000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,620700.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19588352.0,32800.0,26.784,6162.080000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612136.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,6165.536000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.584,6169.1200000000035,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.224,6173.344000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.584,6176.9280000000035,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.168,6180.096000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,6183.5840000000035,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,6187.104000000004,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,6191.296000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,6194.816000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.136,6197.952000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.944,6200.896000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.976,6203.872000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,130880.0,12033546.0,0.0,0,0.0,12033546.0,12033546.0,66566.0,128.0,0.9980807868773802,163840.0,32768.0,20.544,6224.416000000005,10186650.0,1585136.0,130880.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19994368.0,32800.0,23.616,6248.032000000005,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,624824.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,6250.976000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.784,6253.760000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.184,6258.944000000005,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,6261.664000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,6264.544000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.584,6268.128000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.296,6271.424000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84096512.0,136000.0,78.56,6349.984000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2628016.0,4250.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.392,6353.376000000006,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84054400.0,136992.0,79.232,6432.608000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2626700.0,4281.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,6435.712000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78650496.0,32832.0,92.0,6527.712000000006,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457828.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,6530.624000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,6533.536000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.216,6538.752000000007,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,6541.440000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,6544.352000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,6547.744000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,6551.104000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20105472.0,32800.0,23.2,6574.304000000006,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,628296.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19679872.0,32800.0,26.272,6600.576000000006,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614996.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20216192.0,32768.0,23.2,6623.776000000006,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,631756.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.616,6627.392000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,6630.912000000007,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,6635.104000000007,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,6638.560000000007,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,6641.408000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,6644.960000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.648,6648.6080000000065,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.256,6652.864000000007,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,6656.288000000007,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,6659.168000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.104,6662.272000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.976,6665.248000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,20.512,6685.760000000007,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19700224.0,32768.0,25.696,6711.4560000000065,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615632.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,6714.336000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,6717.184000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.536,6722.720000000007,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,6725.408000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,6728.256000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,6731.680000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.424,6735.104000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84096384.0,138336.0,78.88,6813.984000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2628012.0,4323.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.296,6817.280000000007,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84153344.0,137408.0,79.584,6896.864000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2629792.0,4294.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.168,6900.0320000000065,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78525696.0,32832.0,93.184,6993.216000000007,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2453928.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,6996.160000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.784,6998.944000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.28,7004.2240000000065,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,7006.944000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,7009.824000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,7013.216000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.328,7016.544000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19876992.0,32832.0,24.288,7040.832000000007,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,621156.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19724160.0,32768.0,25.6,7066.432000000007,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616380.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19915392.0,32800.0,24.416,7090.848000000007,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,622356.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,7094.304000000007,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,7097.824000000008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.224,7102.048000000008,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.616,7105.664000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.04,7108.704000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,7112.128000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.616,7115.744000000008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,7119.936000000008,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,7123.456000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,7126.336000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.04,7129.376000000008,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.232,7132.608000000008,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,20.512,7153.120000000008,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19671296.0,32800.0,26.048,7179.168000000008,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614728.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,7182.048000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,7184.864000000008,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.216,7190.080000000008,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,7192.8320000000085,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,7195.712000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.52,7199.232000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.424,7202.656000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83925376.0,137312.0,79.2,7281.856000000009,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2622668.0,4291.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.424,7285.280000000009,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84468992.0,137088.0,79.424,7364.704000000009,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2639656.0,4284.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.392,7368.096000000009,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78592256.0,32832.0,94.24,7462.336000000008,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2456008.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,7465.280000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.912,7468.192000000009,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.408,7473.6000000000095,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,7476.384000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,7479.232000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.392,7482.624000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.456,7486.080000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19611264.0,32800.0,26.56,7512.640000000009,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612852.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19858304.0,32800.0,24.8,7537.44000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,620572.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19667072.0,32864.0,26.112,7563.55200000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614596.0,1027.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.552,7567.104000000009,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.552,7570.656000000009,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.224,7574.880000000009,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.616,7578.496000000009,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,7581.376000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,7584.800000000009,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,7588.32000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.224,7592.54400000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.584,7596.12800000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,7599.00800000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.008,7602.01600000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.008,7605.024000000009,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,20.544,7625.568000000009,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19886464.0,32864.0,24.48,7650.048000000009,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,621452.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,7653.344000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,7656.192000000009,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.152,7661.344000000009,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,7664.128000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,7667.008000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,7670.432000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,7673.792000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84911360.0,138880.0,79.616,7753.4080000000085,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2653480.0,4340.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.264,7756.672000000009,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84816128.0,137024.0,79.808,7836.480000000009,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2650504.0,4282.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.072,7839.552000000009,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,79753088.0,32768.0,85.92,7925.472000000009,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2492284.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,7928.352000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.816,7931.168000000009,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.12,7936.288000000009,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,7939.136000000009,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,7942.048000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.52,7945.568000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.392,7948.960000000009,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19592192.0,32896.0,26.944,7975.90400000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612256.0,1028.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20034176.0,32800.0,23.488,7999.39200000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,626068.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19688576.0,32800.0,25.76,8025.15200000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615268.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.424,8028.57600000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.52,8032.0960000000105,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.48,8036.57600000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.456,8040.03200000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,8042.91200000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.52,8046.432000000011,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,3.744,8050.17600000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,4.192,8054.36800000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,3.488,8057.856000000011,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,8060.736000000011,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,2.976,8063.71200000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,3.136,8066.848000000011,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,20.512,8087.360000000011,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,20000384.0,32800.0,23.712,8111.072000000011,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,625012.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,8114.048000000011,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.784,8116.83200000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.248,8122.08000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,8124.80000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,8127.80800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.424,8131.23200000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.36,8134.59200000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,85031680.0,136800.0,78.784,8213.37600000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2657240.0,4275.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,3.232,8216.60800000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84792448.0,137248.0,78.752,8295.36000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2649764.0,4289.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.04,8298.40000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78557184.0,32768.0,94.112,8392.51200000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2454912.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.104,8395.616000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,2.848,8398.464000000009,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,5.28,8403.74400000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,8406.43200000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,8409.312000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,3.36,8412.67200000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,3.328,8416.00000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,2097472000.0,4199424000.0,640000.0,0,0.0,4200064000.0,4200064000.0,6479000.0,20000.0,0.9969226034774581,270305344.0,2560000.0,333.248,8749.248000000009,0.0,5120000.0,2097152000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8447042.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.656,8759.90400000001,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,8762.240000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.944,8765.184000000008,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,8767.904000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.296,8771.200000000008,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,8773.568000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.64,8778.208000000008,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.216,8783.424000000008,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,69444.0,0.0,138888.0,0,0.0,138888.0,138888.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.544,8787.968000000008,0.0,0.0,0.0,69444.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,126976.0,0.0,253952.0,0,0.0,253952.0,253952.0,8448.0,34952.0,0.19465437788018433,2106624.0,0.0,5.088,8793.056000000008,0.0,0.0,0.0,126976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64523.0,0.0,129046.0,0,0.0,129046.0,129046.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.288,8797.344000000008,0.0,0.0,0.0,64523.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,8448.0,34600.0,0.19624605091990335,2106624.0,0.0,5.184,8802.528000000008,0.0,0.0,0.0,115712.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.64,8807.168000000007,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,121856.0,0.0,243712.0,0,0.0,243712.0,243712.0,8448.0,34792.0,0.19537465309898241,2106624.0,128.0,5.152,8812.320000000007,0.0,0.0,0.0,121856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.36,8815.680000000008,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,8818.048000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.608,8822.656000000008,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,8824.992000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.544,8829.536000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,32964.0,8418.0,0.796578222415543,525824.0,6976.0,6.4,8835.936000000007,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,218.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.656,8842.592000000008,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.416,8847.008000000007,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.488,8850.496000000006,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.36,8853.856000000007,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387754.0,0.0,775508.0,0,0.0,775508.0,775508.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.512,8858.368000000008,0.0,0.0,0.0,387754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.04,8861.408000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17760.0,0.701110737125547,1701376.0,1202016.0,16.0,8877.408000000009,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53168.0,37563.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17676.0,0.3491899852724595,1692800.0,1561088.0,13.28,8890.68800000001,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52900.0,48784.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17800.0,0.377012459750805,1686528.0,953440.0,14.592,8905.28000000001,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52704.0,29795.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17704.0,0.378283466779042,1689600.0,1229664.0,14.912,8920.19200000001,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52800.0,38427.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,5.088,8925.28000000001,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.88,8928.160000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9460.0,0.5274489235226535,1160832.0,817344.0,8.32,8936.480000000009,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36276.0,25542.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548864.0,1536000.0,4.64,8941.120000000008,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48402.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1036800.0,512000.0,18.944,8960.064000000008,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32400.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,50.816,9010.880000000008,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.456,9014.336000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.592,9016.928000000009,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,51200.0,10.112,9027.040000000008,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1600.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.712,9030.752000000008,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1060480.0,512000.0,18.912,9049.664000000008,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,33140.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.832,9078.496000000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,9081.312000000009,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.024,9110.336000000008,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.848,9113.184000000008,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.816,9116.00000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.552,9119.552000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,10.24,9129.792000000009,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.688,9132.480000000009,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.936,9136.416000000008,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.72,9139.136000000008,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,9142.624000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.416,9147.040000000006,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,5.184,9152.224000000006,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.184,9165.408000000005,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,9168.224000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,9170.944000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,9173.792000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.72,9176.512000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.912,9179.424000000005,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.464,9181.888000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,9184.256000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.784,9187.040000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,9189.376000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.848,9192.224000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.24,9198.464000000004,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.944,9201.408000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,9204.160000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.04,9207.200000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.712,9210.912000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.72,9213.632000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
