Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.824,1.824,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.6,3.4240000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,32.0,2.24,5.664000000000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,64.0,3.328,8.992,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.848,11.84,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.048,13.888,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.696,15.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,17.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,19.840000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,22.752000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,25.248,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,27.712,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,96.0,8.0,0.9230769230769231,64.0,32.0,3.008,30.72,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.4,33.12,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.496,35.616,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.752,38.368,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,6912.0,0.0,13824.0,0,0.0,13824.0,13824.0,0.0,576.0,0.0,3456.0,24576.0,5.376,43.744,0.0,0.0,0.0,6912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.88,46.624,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.424,50.048,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,536.0,0.0,1072.0,0,0.0,1072.0,1072.0,0.0,2.0,0.0,64.0,32.0,2.752,52.800000000000004,0.0,0.0,0.0,536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,3.04,55.84,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,2.56,58.400000000000006,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,8448.0,18432.0,512.0,0,0.0,18944.0,18944.0,0.0,16.0,0.0,4096.0,4096.0,3.616,62.016000000000005,0.0,2048.0,8192.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,64.64,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,8320.0,18432.0,256.0,0,0.0,18688.0,18688.0,0.0,16.0,0.0,4096.0,4096.0,3.584,68.224,0.0,2048.0,8192.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,70.848,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.816,73.664,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,77.92,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.88,80.8,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,83.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,86.624,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,89.728,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.68,101.40799999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.264,112.67199999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.072,123.74399999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,126.94399999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,130.048,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,133.728,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,136.928,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,139.52,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,142.752,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,145.792,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,149.472,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,152.608,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,155.168,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,175.296,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424064.0,24576.0,10.944,186.23999999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138252.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,188.832,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,191.35999999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,195.648,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,198.07999999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,200.70399999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,203.83999999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,206.91199999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12007424.0,99072.0,17.088,223.99999999999997,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,375232.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.104,227.10399999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11997056.0,98944.0,17.504,244.60799999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374908.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,247.29599999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695872.0,24576.0,33.568,280.864,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552996.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,283.52,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,286.048,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,290.304,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,292.768,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,295.35999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.36,298.71999999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,301.76,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.424,313.18399999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.264,324.448,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24576.0,10.944,335.392,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,338.528,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,341.6,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,345.24800000000005,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,348.41600000000005,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,351.00800000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,354.17600000000004,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,357.24800000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,360.8960000000001,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.52,364.41600000000005,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,367.00800000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,387.232,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24608.0,11.072,398.30400000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,400.896,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,403.42400000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,407.648,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,410.17600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,412.80000000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,415.8400000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.168,419.0080000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11885952.0,99072.0,17.152,436.1600000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371436.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,439.16800000000006,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12026240.0,99552.0,17.12,456.28800000000007,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,375820.0,3111.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,458.97600000000006,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695232.0,24608.0,34.112,493.0880000000001,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552976.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,495.68000000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.592,498.27200000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,502.49600000000004,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,504.96000000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,507.58400000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,510.65600000000006,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,513.696,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.936,525.6320000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24608.0,11.552,537.1840000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.488,548.672,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,551.808,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.264,555.072,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.904,558.976,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,562.112,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,564.736,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,567.84,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,570.88,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.712,574.592,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,577.824,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,580.4159999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.16,600.5759999999999,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424192.0,24576.0,10.752,611.3279999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138256.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,613.9519999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.688,616.6399999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,620.9279999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,623.3279999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,626.2399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,629.2799999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,632.3519999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11955840.0,99392.0,16.992,649.3439999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373620.0,3106.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,652.3199999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11779712.0,99200.0,17.6,669.9199999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,368116.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,672.6079999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695104.0,24576.0,34.4,707.0079999999998,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552972.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,709.5999999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,712.1279999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,716.4159999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,718.8479999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,721.4719999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,724.5759999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,727.7119999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.392,739.1039999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24576.0,11.296,750.4,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4427008.0,24608.0,11.296,761.696,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138344.0,769.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,764.8000000000001,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,767.8080000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.744,771.5520000000001,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,774.6560000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,777.2800000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.264,780.5440000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,783.5840000000002,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,787.2640000000001,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,790.4640000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,793.0560000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.16,813.2160000000001,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.136,824.3520000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,826.9440000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,829.4720000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,833.6960000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,836.1600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,838.7520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,841.7920000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,844.8960000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12026112.0,99200.0,17.088,861.9840000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,375816.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,864.9600000000002,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11794304.0,99008.0,17.312,882.2720000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,368572.0,3094.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.72,884.9920000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17697408.0,24576.0,34.752,919.7440000000001,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553044.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,922.3680000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.816,925.1840000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.384,929.5680000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,931.9680000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,934.5280000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,937.6320000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,940.7360000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4427008.0,24608.0,11.296,952.0320000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138344.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4427008.0,24576.0,11.296,963.3280000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138344.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.264,974.5920000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,977.7280000000003,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,980.7680000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.712,984.4800000000002,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,987.6480000000003,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,990.2080000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,993.3760000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,996.4160000000002,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.712,1000.1280000000002,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1003.2960000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1005.9200000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.192,1026.112,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,1037.0880000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1039.6800000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1042.2400000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1046.4320000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1048.8640000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1051.4560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,1054.5600000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,1057.6640000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11850240.0,99200.0,17.088,1074.7520000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370320.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,1077.7280000000005,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11824128.0,99136.0,17.312,1095.0400000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,369504.0,3098.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.976,1098.0160000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695232.0,24576.0,34.528,1132.5440000000006,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552976.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,1135.2000000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1137.7600000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.416,1142.1760000000004,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1144.7040000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1147.2960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.2,1150.4960000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,1153.5360000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24608.0,11.392,1164.9280000000006,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.328,1176.2560000000005,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24640.0,11.392,1187.6480000000006,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,770.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1190.8160000000005,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,1193.8560000000004,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,1197.5040000000004,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.264,1200.7680000000003,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1203.3920000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1206.5280000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,1209.6320000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,1213.2800000000002,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1216.448,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.752,1219.2,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.064,1239.2640000000001,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.912,1250.1760000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1252.8000000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1255.3600000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,1259.584,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,1262.0800000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1264.6720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,1267.8080000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,1270.9440000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11896064.0,98976.0,17.248,1288.1920000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371752.0,3093.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.264,1291.4560000000001,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11928448.0,98976.0,17.792,1309.248,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372764.0,3093.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.752,1312.0,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696000.0,24576.0,33.408,1345.408,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553000.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1348.0,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,1350.528,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,1354.784,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1357.248,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1359.8400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,1362.9440000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.168,1366.112,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.712,1377.824,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.072,1388.896,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.232,1400.128,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1403.2959999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.136,1406.4319999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.712,1410.1439999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,1413.2479999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1415.8719999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1419.0079999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,1422.0799999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,1425.7599999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1428.9279999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.688,1431.6159999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,1451.8399999999997,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24608.0,11.104,1462.9439999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1465.5679999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,1468.2239999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1472.4159999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1474.8479999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1477.5039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,1480.5759999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,1483.6799999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11836544.0,99232.0,17.024,1500.7039999999997,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,369892.0,3101.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,1503.7119999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11909632.0,99392.0,17.248,1520.9599999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372176.0,3106.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.752,1523.7119999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696256.0,24576.0,34.848,1558.5599999999997,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553008.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1561.1519999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1563.7759999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.16,1567.936,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1570.336,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1572.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,1576.032,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,1579.136,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.84,1590.9759999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24576.0,11.328,1602.3039999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.36,1613.6639999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1616.7999999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,1619.8079999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,1623.4879999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1626.6239999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1629.2479999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1632.4159999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,1635.5199999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.808,1639.3279999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1642.4959999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1645.0879999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.192,1665.2799999999997,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.816,1676.0959999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1678.7199999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,1681.2479999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,1685.4719999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1687.9999999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1690.6239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.232,1693.8559999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.2,1697.0559999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11890304.0,98848.0,16.96,1714.0159999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371572.0,3089.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,1716.9599999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11853056.0,98912.0,17.984,1734.9439999999997,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370408.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,1737.5999999999997,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17700608.0,24576.0,33.92,1771.5199999999998,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553144.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1774.1119999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1776.6719999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,1780.9279999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1783.3919999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1786.0159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,1789.12,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,1792.1919999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,945649664.0,2061467648.0,24309760.0,0,0.0,2085777408.0,2085777408.0,39807232.0,7900672.0,0.8343949044585988,902896768.0,4959904.0,550.368,2342.56,77791232.0,116686848.0,933494784.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28215524.0,154997.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.016,2344.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,264.0,0.0,528.0,0,0.0,528.0,528.0,0.0,6.0,0.0,128.0,256.0,2.528,2347.104,0.0,0.0,0.0,264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,2349.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,1215488.0,0.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,7.968,2357.4719999999998,0.0,1215488.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,2359.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,1461248.0,0.0,2922496.0,0,0.0,2922496.0,2922496.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.896,2368.48,0.0,0.0,0.0,1461248.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,414720.0,0.0,829440.0,0,0.0,829440.0,829440.0,31680.0,236656.0,0.11806093852483454,14795104.0,0.0,9.44,2377.92,0.0,0.0,0.0,414720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,462347.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,248240.0,0.0,496480.0,0,0.0,496480.0,496480.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.448,2386.368,0.0,0.0,0.0,248240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,506880.0,0.0,1013760.0,0,0.0,1013760.0,1013760.0,31680.0,239536.0,0.11680726800778715,14873504.0,0.0,9.376,2395.744,0.0,0.0,0.0,506880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,464797.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,245824.0,0.0,491648.0,0,0.0,491648.0,491648.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,9.024,2404.768,0.0,0.0,0.0,245824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,491520.0,0.0,983040.0,0,0.0,983040.0,983040.0,31680.0,239056.0,0.11701436085337746,14859168.0,0.0,9.568,2414.3360000000002,0.0,0.0,0.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,464349.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,245768.0,0.0,491536.0,0,0.0,491536.0,491536.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.896,2423.2320000000004,0.0,0.0,0.0,245768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,414720.0,0.0,829440.0,0,0.0,829440.0,829440.0,31680.0,236656.0,0.11806093852483454,14794912.0,224.0,9.696,2432.9280000000003,0.0,0.0,0.0,414720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,462341.0,7.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1248.0,0.0,2496.0,0,0.0,2496.0,2496.0,0.0,45.0,0.0,15392.0,1920.0,3.648,2436.5760000000005,0.0,0.0,0.0,1248.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,481.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2438.6240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.576,2443.2000000000003,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2445.248,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.576,2449.824,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,1340192.0,0.0,2680384.0,0,0.0,2680384.0,2680384.0,297824.0,54016.0,0.8464756707594361,4908928.0,17760.0,13.216,2463.04,0.0,0.0,0.0,1340192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153404.0,555.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,6.272,2469.312,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,4883296.0,303872.0,8.768,2478.08,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152603.0,9496.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,28488.0,0.0,6077440.0,148736.0,9.184,2487.264,0.0,0.0,0.0,151936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,189920.0,4648.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,37984.0,0.0,0.0,9723904.0,10.816,2498.08,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,389942.0,0.0,779884.0,0,0.0,779884.0,779884.0,64512.0,37984.0,0.6294099281923197,4861952.0,0.0,9.152,2507.232,0.0,0.0,0.0,389942.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,2509.9519999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,980928.0,0.0,1961856.0,0,0.0,1961856.0,1961856.0,333423.0,165293.0,0.6685628694487443,16585728.0,11178816.0,41.344,2551.296,0.0,0.0,0.0,980928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,518304.0,349338.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,351936.0,0.0,703872.0,0,0.0,703872.0,703872.0,77895.0,175106.0,0.3078841585606381,16539648.0,14821248.0,34.72,2586.0159999999996,0.0,0.0,0.0,351936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,516864.0,463164.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,355200.0,0.0,710400.0,0,0.0,710400.0,710400.0,78703.0,174260.0,0.31112455181192505,16618752.0,14819968.0,36.352,2622.3679999999995,0.0,0.0,0.0,355200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,519336.0,463124.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,355200.0,0.0,710400.0,0,0.0,710400.0,710400.0,78703.0,174520.0,0.31080510064251665,16611840.0,12432384.0,35.744,2658.1119999999996,0.0,0.0,0.0,355200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,519120.0,388512.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,37984.0,0.19851451721809588,9723904.0,0.0,14.048,2672.1599999999994,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,2674.7519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,194516.0,0.0,389032.0,0,0.0,389032.0,389032.0,78020.0,99940.0,0.4384131265452911,11740800.0,8179104.0,20.544,2695.2959999999994,0.0,0.0,0.0,194516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,366900.0,255597.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,151936.0,0.0,14665632.0,14585856.0,19.552,2714.8479999999995,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,458301.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,19769968.0,40153344.0,5506272.0,0,0.0,45659616.0,45659616.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,66.112,2780.9599999999996,4904192.0,1215488.0,17016832.0,2753136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,1232896.0,6104232.0,2465792.0,0,0.0,8570024.0,8570024.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,228.608,3009.5679999999998,6104232.0,0.0,0.0,1232896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,7.904,3017.4719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,2.176,3019.6479999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,113952.0,0.0,10939392.0,442432.0,19.424,3039.0719999999997,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,341856.0,13826.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,28488.0,0.0,6077440.0,313472.0,9.056,3048.1279999999997,0.0,0.0,0.0,151936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,189920.0,9796.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,19769984.0,40153344.0,5506304.0,0,0.0,45659648.0,45659648.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,66.208,3114.336,4904192.0,1215488.0,17016832.0,2753152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.496,3124.832,0.0,0.0,0.0,230400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,3127.2639999999997,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.592,3137.8559999999998,0.0,0.0,0.0,230400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,3140.256,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,3142.848,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,3146.112,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,401408.0,1971352.0,802816.0,0,0.0,2774168.0,2774168.0,14744.0,9664.0,0.6040642412323828,4862784.0,4960.0,10.784,3156.896,1971352.0,0.0,0.0,401408.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151962.0,155.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,2.0,0.0,32.0,32.0,2.4,3159.2960000000003,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.328,3162.6240000000003,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,3165.056,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.136,3168.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,3612672.0,6817792.0,2838528.0,0,0.0,9656320.0,9656320.0,0.0,37984.0,0.0,0.0,4861952.0,6.336,3174.528,0.0,2430976.0,2193408.0,1419264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,7292544.0,12154880.0,2430208.0,0,0.0,14585088.0,14585088.0,0.0,28488.0,0.0,9723904.0,1577344.0,14.08,3188.6079999999997,0.0,0.0,6077440.0,1215104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303872.0,49292.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,1082880.0,0.0,2165760.0,0,0.0,2165760.0,2165760.0,26904.0,9824.0,0.7325201481158788,4864512.0,5472.0,12.224,3200.832,0.0,0.0,0.0,1082880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152016.0,171.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,264.0,0.0,528.0,0,0.0,528.0,528.0,0.0,6.0,0.0,128.0,256.0,2.464,3203.296,0.0,0.0,0.0,264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.016,3205.312,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,1.984,3207.296,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.592,3209.888,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,2.4,3212.288,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,3.104,3215.392,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.168,3218.56,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,3220.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,3223.424,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,3.0,0.0,160.0,64.0,3.264,3226.688,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,96.0,8.0,0.9230769230769231,128.0,32.0,3.04,3229.728,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.432,3232.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,128.0,32.0,2.464,3234.624,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,0.0,2.432,3237.0559999999996,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,128.0,64.0,2.496,3239.5519999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,6912.0,0.0,13824.0,0,0.0,13824.0,13824.0,0.0,576.0,0.0,24960.0,24576.0,9.6,3249.1519999999996,0.0,0.0,0.0,6912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,780.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,2.816,3251.9679999999994,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.36,3255.3279999999995,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,536.0,0.0,1072.0,0,0.0,1072.0,1072.0,0.0,2.0,0.0,64.0,32.0,2.816,3258.1439999999993,0.0,0.0,0.0,536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.56,3260.7039999999993,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,2.592,3263.2959999999994,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,8448.0,18464.0,512.0,0,0.0,18976.0,18976.0,0.0,16.0,0.0,4096.0,4096.0,3.488,3266.783999999999,32.0,2048.0,8192.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,3269.311999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,8320.0,18432.0,256.0,0,0.0,18688.0,18688.0,0.0,16.0,0.0,4096.0,4096.0,3.584,3272.895999999999,0.0,2048.0,8192.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.496,3275.391999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3277.951999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3282.175999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3284.575999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3287.199999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,3290.335999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,3293.407999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.168,3304.575999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.136,3315.711999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24608.0,11.424,3327.135999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,769.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.296,3330.431999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,3333.503999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.808,3337.311999999999,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,3340.415999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3343.0399999999986,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3346.2079999999987,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,2.976,3349.183999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,3352.8639999999987,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3356.031999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,3358.5919999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3361.183999999999,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3363.8079999999986,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,96576.0,9021000.0,0.0,0,0.0,9021000.0,9021000.0,49940.0,96.0,0.9980813814053882,122880.0,24576.0,20.48,3384.2879999999986,7639146.0,1188702.0,96576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24640.0,11.04,3395.3279999999986,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,770.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.688,3398.0159999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3400.5439999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.448,3404.9919999999984,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3407.3919999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3409.9839999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,3413.0559999999987,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,3416.127999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11896832.0,99200.0,17.664,3433.791999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371776.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,3436.767999999999,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11855104.0,99104.0,17.536,3454.303999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370472.0,3097.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.752,3457.055999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696384.0,24576.0,34.272,3491.327999999999,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553012.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3493.919999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3496.479999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3500.7039999999993,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3503.135999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3505.759999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,3508.831999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,3511.871999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.328,3523.199999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24608.0,10.944,3534.143999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.296,3545.4399999999987,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,3548.6399999999985,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3551.6479999999983,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,3555.2959999999985,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.456,3558.7519999999986,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3561.3759999999984,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3564.5119999999984,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,3567.5519999999983,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.744,3571.2959999999985,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3574.4319999999984,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3577.0239999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3579.6159999999986,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,3582.1759999999986,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,97472.0,9023352.0,0.0,0,0.0,9023352.0,9023352.0,49950.0,96.0,0.9980817647764058,122880.0,24576.0,20.48,3602.6559999999986,7639622.0,1188786.0,97472.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424064.0,24608.0,10.688,3613.3439999999987,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138252.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3615.935999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.784,3618.719999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,3623.007999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3625.4399999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,3628.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,3631.1679999999988,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,3634.2079999999987,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11935232.0,98944.0,17.024,3651.2319999999986,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372976.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.264,3654.4959999999987,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11925504.0,99008.0,16.928,3671.4239999999986,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372672.0,3094.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.816,3674.2399999999984,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695744.0,24608.0,34.112,3708.3519999999985,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552992.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3710.9439999999986,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3713.4719999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.32,3717.7919999999986,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3720.1919999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3722.7839999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,3725.855999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.008,3728.8639999999987,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.328,3740.1919999999986,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24576.0,11.328,3751.5199999999986,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.328,3762.8479999999986,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3766.0159999999987,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3769.0239999999985,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,3772.6719999999987,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,3775.9039999999986,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3778.4959999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3781.663999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,3784.703999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,3788.3839999999987,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3791.5199999999986,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,3794.1759999999986,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3796.7999999999984,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.528,3799.327999999998,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,97664.0,9023856.0,0.0,0,0.0,9023856.0,9023856.0,49944.0,96.0,0.9980815347721822,122880.0,24576.0,20.384,3819.711999999998,7639724.0,1188804.0,97664.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,3830.655999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,3833.215999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3835.743999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,3839.9999999999977,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3842.4319999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3845.0239999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.232,3848.2559999999976,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.008,3851.2639999999974,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11859072.0,99296.0,17.44,3868.7039999999974,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370596.0,3103.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,3871.6479999999974,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11859712.0,99104.0,17.152,3888.7999999999975,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370616.0,3097.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,3891.4879999999976,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696000.0,24608.0,34.24,3925.7279999999973,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553000.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3928.351999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3930.879999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.352,3935.231999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3937.6639999999966,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3940.2559999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,3943.2959999999966,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,3946.3359999999966,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4427520.0,24576.0,11.296,3957.6319999999964,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138360.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.392,3969.0239999999962,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.296,3980.319999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,3983.423999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3986.4319999999957,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,3990.079999999996,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,3993.1839999999956,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3995.7759999999957,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,3998.9759999999956,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,4002.0159999999955,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,4005.6639999999957,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,4008.7679999999955,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,4011.4879999999953,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,4014.047999999995,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,4016.607999999995,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,97920.0,9024528.0,0.0,0,0.0,9024528.0,9024528.0,49938.0,96.0,0.9980813047127953,122880.0,24576.0,20.48,4037.087999999995,7639860.0,1188828.0,97920.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,11.104,4048.191999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,4050.815999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4053.3439999999946,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,4057.5359999999946,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4059.9679999999944,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4062.5279999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,4065.5999999999945,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,4068.6399999999944,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11989248.0,99488.0,17.024,4085.6639999999943,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374664.0,3109.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.232,4088.8959999999943,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12019584.0,99168.0,17.248,4106.143999999994,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,375612.0,3099.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.912,4109.055999999994,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695616.0,24608.0,34.688,4143.743999999994,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552988.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,4146.4639999999945,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4148.991999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,4153.215999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4155.647999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4158.239999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,4161.343999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,4164.447999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.36,4175.8079999999945,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.68,4187.487999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.616,4199.103999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,4202.2719999999945,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,4205.375999999995,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,4209.023999999995,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4212.159999999995,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4214.751999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,4217.919999999995,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,4220.927999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,4224.607999999995,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,4227.711999999995,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4230.303999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,4232.863999999995,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.624,4235.487999999995,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,98112.0,9025032.0,0.0,0,0.0,9025032.0,9025032.0,49932.0,96.0,0.998081074598225,122880.0,24576.0,20.512,4255.9999999999945,7639962.0,1188846.0,98112.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.168,4267.167999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,4269.727999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,4272.287999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,4276.479999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4278.943999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,4281.599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,4284.735999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,4287.807999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11874048.0,99168.0,17.184,4304.991999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371064.0,3099.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.072,4308.063999999996,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11982720.0,99328.0,17.024,4325.087999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374460.0,3104.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.784,4327.871999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695744.0,24576.0,34.432,4362.3039999999955,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552992.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,4364.927999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4367.455999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,4371.647999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4374.1119999999955,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4376.671999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,4379.807999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,4382.8799999999965,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24608.0,11.36,4394.239999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.04,4405.279999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.136,4416.4159999999965,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,4419.6479999999965,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,4422.751999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.808,4426.559999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,4429.727999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.784,4432.511999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4435.6479999999965,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,4438.6879999999965,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.808,4442.4959999999965,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,4445.599999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4448.191999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.528,4450.719999999997,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,4453.279999999997,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,98112.0,9025032.0,0.0,0,0.0,9025032.0,9025032.0,49932.0,96.0,0.998081074598225,122880.0,24576.0,20.48,4473.759999999997,7639962.0,1188846.0,98112.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.136,4484.895999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,4487.519999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4490.047999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.352,4494.399999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4496.831999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4499.391999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,4502.495999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,4505.5679999999975,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11822208.0,99072.0,17.152,4522.7199999999975,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,369444.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,4525.663999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11857792.0,99200.0,17.216,4542.879999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370556.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,4545.567999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695232.0,24576.0,33.888,4579.455999999998,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552976.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4582.047999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4584.575999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,4588.863999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4591.263999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4593.855999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,4596.895999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,4599.967999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24608.0,11.36,4611.327999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.168,4622.4959999999965,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426880.0,24576.0,11.296,4633.791999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138340.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4636.927999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,4639.935999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,4643.615999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4646.751999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4649.343999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4652.479999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,4655.519999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,4659.199999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.264,4662.463999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4665.055999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,4667.647999999997,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.528,4670.175999999998,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.672,4690.847999999997,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.232,4702.079999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4704.671999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4707.199999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,4711.391999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4713.791999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4716.351999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,4719.455999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,4722.495999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11849344.0,99264.0,16.96,4739.455999999997,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370292.0,3102.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,4742.399999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11970304.0,99296.0,17.312,4759.711999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374072.0,3103.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.752,4762.463999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695616.0,24576.0,34.72,4797.183999999998,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552988.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4799.775999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,4802.399999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.352,4806.751999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4809.1839999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,4811.711999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.168,4814.879999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.2,4818.079999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.264,4829.343999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4426752.0,24576.0,11.136,4840.479999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138336.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4427136.0,24576.0,11.168,4851.647999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138348.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.264,4854.9119999999975,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,4857.983999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,4861.631999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4864.767999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,4867.391999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4870.527999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.136,4873.663999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.904,4877.567999999999,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4880.704,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,4883.424,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.528,4885.952,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.528,4888.4800000000005,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.416,4908.896000000001,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.072,4919.968000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4922.56,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4925.088000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,4929.312000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4931.744000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4934.336,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.2,4937.536,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.168,4940.704,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11798400.0,98944.0,17.088,4957.7919999999995,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,368700.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,4960.767999999999,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11789312.0,98944.0,17.376,4978.143999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,368416.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.72,4980.864,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696256.0,24608.0,34.208,5015.071999999999,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553008.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,5017.663999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,5020.191999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,5024.447999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,5026.847999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,5029.567999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,5032.672,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,5035.808,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,945649664.0,2061467648.0,24309760.0,0,0.0,2085777408.0,2085777408.0,39807232.0,7900672.0,0.8343949044585988,902364032.0,4963616.0,550.144,5585.952,77791232.0,116686848.0,933494784.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28198876.0,155113.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.048,5588.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,268.0,0.0,536.0,0,0.0,536.0,536.0,0.0,6.0,0.0,192.0,320.0,2.496,5590.496,0.0,0.0,0.0,268.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,5592.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,1215488.0,0.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,7.616,5600.544,0.0,1215488.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,5602.5599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,1461248.0,0.0,2922496.0,0,0.0,2922496.0,2922496.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.512,5611.071999999999,0.0,0.0,0.0,1461248.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,414720.0,0.0,829440.0,0,0.0,829440.0,829440.0,31680.0,236656.0,0.11806093852483454,14796160.0,0.0,9.28,5620.351999999999,0.0,0.0,0.0,414720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,462380.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,248155.0,0.0,496310.0,0,0.0,496310.0,496310.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,9.056,5629.4079999999985,0.0,0.0,0.0,248155.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,506880.0,0.0,1013760.0,0,0.0,1013760.0,1013760.0,31680.0,239536.0,0.11680726800778715,14878208.0,32.0,9.44,5638.847999999998,0.0,0.0,0.0,506880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,464944.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,245796.0,0.0,491592.0,0,0.0,491592.0,491592.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.96,5647.807999999998,0.0,0.0,0.0,245796.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,449280.0,0.0,898560.0,0,0.0,898560.0,898560.0,31680.0,237736.0,0.11758767111084717,14828992.0,0.0,9.504,5657.311999999998,0.0,0.0,0.0,449280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,463406.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,245769.0,0.0,491538.0,0,0.0,491538.0,491538.0,7680.0,45664.0,0.14397120575884823,4864640.0,122880.0,8.608,5665.919999999998,0.0,0.0,0.0,245769.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152020.0,3840.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,441600.0,0.0,883200.0,0,0.0,883200.0,883200.0,31680.0,237496.0,0.11769251344845008,14816416.0,224.0,9.76,5675.6799999999985,0.0,0.0,0.0,441600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,463013.0,7.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1248.0,0.0,2496.0,0,0.0,2496.0,2496.0,0.0,45.0,0.0,15392.0,1920.0,3.648,5679.327999999999,0.0,0.0,0.0,1248.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,481.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5681.375999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.608,5685.983999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5688.031999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.608,5692.6399999999985,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,1340192.0,0.0,2680384.0,0,0.0,2680384.0,2680384.0,302129.0,54012.0,0.8483409660780421,4908928.0,17568.0,13.216,5705.855999999999,0.0,0.0,0.0,1340192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153404.0,549.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,6.176,5712.031999999999,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,4883264.0,303872.0,9.024,5721.056,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152602.0,9496.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,28488.0,0.0,6077440.0,872320.0,8.928,5729.9839999999995,0.0,0.0,0.0,151936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,189920.0,27260.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,37984.0,0.0,0.0,9723904.0,10.784,5740.767999999999,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,389937.0,0.0,779874.0,0,0.0,779874.0,779874.0,64512.0,37984.0,0.6294099281923197,4861952.0,0.0,9.504,5750.271999999999,0.0,0.0,0.0,389937.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,5752.863999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,998016.0,0.0,1996032.0,0,0.0,1996032.0,1996032.0,339847.0,165526.0,0.672467662498788,16426880.0,11226624.0,41.248,5794.111999999998,0.0,0.0,0.0,998016.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,513340.0,350832.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,351936.0,0.0,703872.0,0,0.0,703872.0,703872.0,77895.0,175860.0,0.3069693208015606,16586496.0,14820736.0,35.168,5829.279999999998,0.0,0.0,0.0,351936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,518328.0,463148.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,355200.0,0.0,710400.0,0,0.0,710400.0,710400.0,78703.0,176683.0,0.3081727267743729,16638720.0,14822016.0,35.648,5864.927999999998,0.0,0.0,0.0,355200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,519960.0,463188.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,355200.0,0.0,710400.0,0,0.0,710400.0,710400.0,78703.0,172904.0,0.3128013131590139,16600960.0,12434048.0,35.392,5900.319999999998,0.0,0.0,0.0,355200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,518780.0,388564.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,37984.0,0.19851451721809588,9723904.0,0.0,13.984,5914.303999999998,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,5916.895999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,194516.0,0.0,389032.0,0,0.0,389032.0,389032.0,78020.0,100018.0,0.4382210539323066,11734912.0,8166336.0,21.408,5938.303999999998,0.0,0.0,0.0,194516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,366716.0,255198.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,151936.0,0.0,14664896.0,14585856.0,19.776,5958.079999999998,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,458278.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,19769968.0,40153344.0,5506272.0,0,0.0,45659616.0,45659616.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,65.728,6023.807999999998,4904192.0,1215488.0,17016832.0,2753136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,1232896.0,6104232.0,2465792.0,0,0.0,8570024.0,8570024.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,228.768,6252.575999999998,6104232.0,0.0,0.0,1232896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,7.936,6260.511999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,2.144,6262.655999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,3646464.0,0.0,7292928.0,0,0.0,7292928.0,7292928.0,0.0,113952.0,0.0,10939392.0,441920.0,19.424,6282.079999999998,0.0,0.0,0.0,3646464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,341856.0,13810.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,28488.0,0.0,6077440.0,122496.0,8.896,6290.975999999998,0.0,0.0,0.0,151936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,189920.0,3828.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,19769989.0,40153344.0,5506314.0,0,0.0,45659658.0,45659658.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,66.144,6357.119999999998,4904192.0,1215488.0,17016832.0,2753157.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.752,6367.8719999999985,0.0,0.0,0.0,230400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,6370.271999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,11.008,6381.279999999998,0.0,0.0,0.0,230400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,6383.711999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,6386.271999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,6389.439999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,401408.0,1971352.0,802816.0,0,0.0,2774168.0,2774168.0,14744.0,9664.0,0.6040642412323828,4862784.0,4960.0,10.848,6400.287999999998,1971352.0,0.0,0.0,401408.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151962.0,155.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,2.0,0.0,32.0,32.0,2.56,6402.847999999998,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.36,6406.207999999998,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.592,6408.799999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,6411.999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,3612672.0,6817792.0,2838528.0,0,0.0,9656320.0,9656320.0,0.0,37984.0,0.0,0.0,4861952.0,6.4,6418.399999999997,0.0,2430976.0,2193408.0,1419264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,7292549.0,12154880.0,2430218.0,0,0.0,14585098.0,14585098.0,0.0,28488.0,0.0,9723904.0,1773184.0,14.144,6432.543999999997,0.0,0.0,6077440.0,1215109.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303872.0,55412.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,1082880.0,0.0,2165760.0,0,0.0,2165760.0,2165760.0,26904.0,9824.0,0.7325201481158788,4864512.0,5248.0,12.16,6444.703999999997,0.0,0.0,0.0,1082880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152016.0,164.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,268.0,0.0,536.0,0,0.0,536.0,536.0,0.0,6.0,0.0,192.0,320.0,2.528,6447.231999999997,0.0,0.0,0.0,268.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.08,6449.311999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.048,6451.359999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.528,6453.887999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,2.464,6456.351999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,3.168,6459.519999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.2,6462.719999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,6465.151999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
