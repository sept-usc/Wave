Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.536,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,32.0,2.464,12.0,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,128.0,3.84,15.84,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.424,19.264,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.944,22.208,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.08,24.287999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,26.303999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,28.447999999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,31.359999999999992,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,33.919999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,36.38399999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,176.0,16.0,0.9166666666666666,128.0,32.0,3.136,39.519999999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.4,41.919999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,128.0,32.0,2.4,44.31999999999999,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,0.0,2.56,46.879999999999995,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,3840.0,49152.0,7.712,54.592,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,120.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,2.848,57.44,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.52,60.96,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,560.0,0.0,1120.0,0,0.0,1120.0,1120.0,0.0,2.0,0.0,128.0,64.0,2.72,63.68,0.0,0.0,0.0,560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.72,66.4,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,2.592,68.992,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,16896.0,36864.0,1024.0,0,0.0,37888.0,37888.0,0.0,32.0,0.0,8192.0,8192.0,3.616,72.608,0.0,4096.0,16384.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,75.2,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,16640.0,36864.0,512.0,0,0.0,37376.0,37376.0,0.0,32.0,0.0,8192.0,8192.0,3.392,78.592,0.0,4096.0,16384.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,81.12,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.72,83.84,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.728,89.568,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,92.0,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.624,94.624,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.168,97.792,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,100.83200000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8677504.0,49216.0,12.224,113.05600000000001,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271172.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8687104.0,49280.0,11.52,124.57600000000001,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271472.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8686336.0,49280.0,11.52,136.096,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271448.0,1540.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,139.168,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.072,142.24,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,145.888,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,148.99200000000002,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,151.64800000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,154.81600000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,157.82400000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,161.44000000000005,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.264,164.70400000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,167.39200000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.984,205.37600000000006,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8674048.0,49440.0,11.648,217.02400000000006,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271064.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,219.74400000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,222.30400000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.6,227.90400000000005,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,230.33600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,232.92800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,236.00000000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,239.07200000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28097920.0,200224.0,29.12,268.19200000000006,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,878060.0,6257.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.104,271.29600000000005,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,29172224.0,198624.0,27.264,298.56000000000006,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,911632.0,6207.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.848,301.4080000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35005568.0,49280.0,35.104,336.51200000000006,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1093924.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.592,339.10400000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,341.6,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.344,346.944,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.56,349.504,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.656,352.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,355.20000000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.008,358.208,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8663936.0,49248.0,11.84,370.048,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270748.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8713984.0,49376.0,11.84,381.888,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272312.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8679936.0,49312.0,11.616,393.50399999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271248.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,396.67199999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,399.67999999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,403.29599999999994,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.04,406.33599999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,409.02399999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,412.09599999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.104,415.19999999999993,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,418.84799999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,421.95199999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,424.57599999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.792,462.36799999999994,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8685056.0,49376.0,11.424,473.7919999999999,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271408.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,476.4799999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.624,479.1039999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.28,484.3839999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,486.8159999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,489.34399999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,492.3519999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.104,495.4559999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,29039232.0,198816.0,26.912,522.3679999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,907476.0,6213.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.04,525.4079999999999,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,27762176.0,199264.0,29.28,554.6879999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,867568.0,6227.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.008,557.6959999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35225216.0,49280.0,34.912,592.608,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1100788.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,595.4879999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,598.0479999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,603.4559999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,605.8559999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,608.4159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,611.4239999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.008,614.4319999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8656896.0,49280.0,11.744,626.1759999999999,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270528.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8673152.0,49280.0,11.52,637.6959999999999,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271036.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8679680.0,49312.0,11.648,649.3439999999999,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271240.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.296,652.64,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,655.648,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,659.296,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.2,662.4960000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,665.152,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,668.5440000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.976,671.5200000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,675.1680000000001,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,678.3040000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,680.96,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.92,718.88,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8662400.0,49312.0,11.456,730.336,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270700.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,733.28,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.592,735.872,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.44,741.312,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,743.744,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,746.336,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,749.344,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,752.384,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28474496.0,199104.0,29.184,781.568,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,889828.0,6222.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.04,784.608,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,29182720.0,198720.0,27.52,812.1279999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,911960.0,6210.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,815.0719999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35284992.0,49408.0,35.552,850.6239999999999,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1102656.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,853.2799999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,855.7759999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.504,861.2799999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,863.6799999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,866.2399999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,869.2799999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.168,872.4479999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8686336.0,49408.0,11.36,883.8079999999998,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271448.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8665856.0,49440.0,11.648,895.4559999999998,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270808.0,1545.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8676992.0,49248.0,11.488,906.9439999999997,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271156.0,1539.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.2,910.1439999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.976,913.1199999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,916.7679999999998,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.232,919.9999999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,922.6559999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,925.7279999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.072,928.7999999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,932.4159999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,935.5839999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,938.2719999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.888,976.1599999999997,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8684160.0,49312.0,11.552,987.7119999999998,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271380.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,990.3359999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,992.8639999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,998.2719999999998,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,1000.7039999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,1003.2639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.168,1006.4319999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,1009.4719999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28790144.0,199296.0,28.64,1038.1119999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,899692.0,6228.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.008,1041.12,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28222208.0,199520.0,29.12,1070.2399999999998,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,881944.0,6235.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,1073.1519999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,34970496.0,49312.0,35.328,1108.4799999999998,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1092828.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,1111.264,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,1113.792,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.344,1119.136,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.464,1121.6,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,1124.1599999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,1127.1999999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.168,1130.3679999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8671872.0,49344.0,11.904,1142.2719999999997,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270996.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8683648.0,49376.0,11.552,1153.8239999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271364.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8718336.0,49408.0,11.456,1165.2799999999995,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272448.0,1544.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,1168.3839999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.072,1171.4559999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.584,1175.0399999999995,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,1178.2079999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,1181.1199999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,1184.2879999999993,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.04,1187.3279999999993,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,1190.9759999999992,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.232,1194.2079999999992,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1196.8639999999991,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.824,1234.6879999999992,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8684288.0,49312.0,11.392,1246.0799999999992,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271384.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1248.7359999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.72,1251.4559999999992,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.632,1257.0879999999993,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.56,1259.6479999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,1262.2079999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,1265.279999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.232,1268.511999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28808320.0,199040.0,28.768,1297.279999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,900260.0,6220.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.04,1300.319999999999,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28142976.0,199296.0,26.912,1327.231999999999,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,879468.0,6228.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.04,1330.271999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35056896.0,49184.0,35.136,1365.407999999999,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1095528.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1368.063999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.656,1370.719999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.504,1376.2239999999988,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,1378.6559999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,1381.2159999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,1384.2879999999986,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.104,1387.3919999999987,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8667648.0,49280.0,11.648,1399.0399999999986,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270864.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8686848.0,49312.0,11.712,1410.7519999999986,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271464.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8671872.0,49440.0,11.744,1422.4959999999985,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270996.0,1545.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,1425.5679999999984,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.232,1428.7999999999984,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.712,1432.5119999999984,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,1435.6159999999984,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1438.2719999999983,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,1441.3759999999984,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.04,1444.4159999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,1448.0639999999983,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,1451.1359999999981,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1453.791999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.984,1491.775999999998,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8700416.0,49344.0,11.424,1503.199999999998,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271888.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,1506.079999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.688,1508.7679999999982,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.376,1514.1439999999982,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,1516.5439999999983,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,1519.1359999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,1522.2079999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,1525.2479999999982,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28766848.0,199520.0,27.264,1552.5119999999981,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,898964.0,6235.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.072,1555.583999999998,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28672768.0,199520.0,27.392,1582.975999999998,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,896024.0,6235.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,1585.887999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35177216.0,49408.0,35.392,1621.2799999999982,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1099288.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1623.935999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,1626.4639999999981,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.344,1631.8079999999982,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,1634.2079999999983,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,1636.7999999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.104,1639.9039999999984,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,1642.9439999999984,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8675712.0,49312.0,11.456,1654.3999999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271116.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8691072.0,49376.0,11.392,1665.7919999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271596.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8677376.0,49344.0,11.328,1677.1199999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271168.0,1542.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,1680.2239999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.976,1683.1999999999985,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,1686.8479999999984,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.296,1690.1439999999984,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1692.7999999999984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.2,1695.9999999999984,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.976,1698.9759999999985,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.712,1702.6879999999985,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.296,1705.9839999999986,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1708.6399999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.792,1746.4319999999984,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8664704.0,49312.0,11.488,1757.9199999999985,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270772.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,1760.8319999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,1763.3279999999986,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.472,1768.7999999999986,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.464,1771.2639999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.688,1773.9519999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,1777.0239999999985,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,1780.0959999999984,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,29080576.0,199136.0,26.848,1806.9439999999984,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,908768.0,6223.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.104,1810.0479999999984,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28305408.0,198752.0,26.912,1836.9599999999984,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,884544.0,6211.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,1840.1279999999983,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35135488.0,49504.0,35.424,1875.5519999999983,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1097984.0,1547.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,1878.2399999999984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.656,1880.8959999999984,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.376,1886.2719999999983,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,1888.7039999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,1891.2639999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,1894.3039999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,1897.3439999999982,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8663168.0,49440.0,11.584,1908.9279999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270724.0,1545.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8660992.0,49248.0,11.424,1920.3519999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270656.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8692736.0,49248.0,11.296,1931.6479999999983,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271648.0,1539.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.264,1934.9119999999982,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.976,1937.8879999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,1941.5359999999982,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,1944.9279999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.752,1947.6799999999982,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,1950.7839999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.2,1953.9839999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.744,1957.7279999999982,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,1961.1199999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1963.7759999999982,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,37.856,2001.6319999999982,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8657408.0,49216.0,11.616,2013.2479999999982,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270544.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,2015.9039999999982,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,2018.4319999999982,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,2023.839999999998,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.496,2026.3359999999982,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,2028.9279999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,2031.9679999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,2035.0079999999982,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28700544.0,199680.0,26.848,2061.8559999999984,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,896892.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.136,2064.9919999999984,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28055424.0,199712.0,27.072,2092.0639999999985,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,876732.0,6241.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,2094.9759999999983,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35135360.0,49344.0,35.072,2130.0479999999984,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1097980.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,2132.7039999999984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,2135.1999999999985,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.44,2140.6399999999985,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.464,2143.1039999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,2145.6639999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,2148.7039999999984,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.104,2151.807999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,790848000.0,1586176000.0,640000.0,0,0.0,1586816000.0,1586816000.0,2639000.0,146826.0,0.947295344361062,118715104.0,4007872.0,172.064,2323.871999999998,0.0,5120000.0,790528000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3709847.0,125246.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.016,2325.887999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,272.0,0.0,544.0,0,0.0,544.0,544.0,0.0,6.0,0.0,256.0,512.0,2.464,2328.351999999998,0.0,0.0,0.0,272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,2330.751999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,512000.0,0.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.704,2335.4559999999983,0.0,512000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.144,2337.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,770048.0,0.0,1540096.0,0,0.0,1540096.0,1540096.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.472,2343.0719999999983,0.0,0.0,0.0,770048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,442368.0,0.0,884736.0,0,0.0,884736.0,884736.0,33792.0,137760.0,0.1969781757134863,8389824.0,160.0,7.04,2350.1119999999983,0.0,0.0,0.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262182.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,259072.0,0.0,518144.0,0,0.0,518144.0,518144.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.376,2355.4879999999985,0.0,0.0,0.0,259072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,540672.0,0.0,1081344.0,0,0.0,1081344.0,1081344.0,33792.0,140832.0,0.19351291918636612,8377344.0,192.0,7.296,2362.7839999999983,0.0,0.0,0.0,540672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261792.0,6.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,258080.0,0.0,516160.0,0,0.0,516160.0,516160.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.536,2368.3199999999983,0.0,0.0,0.0,258080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,458752.0,0.0,917504.0,0,0.0,917504.0,917504.0,33792.0,138272.0,0.19639204017109912,8358368.0,224.0,7.168,2375.4879999999985,0.0,0.0,0.0,458752.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261199.0,7.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,258064.0,0.0,516128.0,0,0.0,516128.0,516128.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.664,2381.1519999999987,0.0,0.0,0.0,258064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,540672.0,0.0,1081344.0,0,0.0,1081344.0,1081344.0,33792.0,140832.0,0.19351291918636612,8411936.0,512.0,7.232,2388.3839999999987,0.0,0.0,0.0,540672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262873.0,16.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,16448.0,2048.0,3.936,2392.319999999999,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,2394.335999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,41.0,0.9394387001477105,2048.0,0.0,4.704,2399.039999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2401.119999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,41.0,0.9394387001477105,2048.0,0.0,4.8,2405.919999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,644672.0,0.0,1289344.0,0,0.0,1289344.0,1289344.0,106272.0,33664.0,0.7594328836039332,2097856.0,29600.0,7.104,2413.023999999999,0.0,0.0,0.0,644672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65558.0,925.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,6.272,2419.295999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,2080256.0,128000.0,4.992,2424.287999999999,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65008.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,12000.0,0.0,2560000.0,512.0,5.248,2429.535999999999,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,16000.0,0.0,0.0,4096000.0,5.6,2435.135999999999,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,389666.0,0.0,779332.0,0,0.0,779332.0,779332.0,64512.0,16000.0,0.8012718600953895,2048000.0,0.0,5.984,2441.119999999999,0.0,0.0,0.0,389666.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.752,2443.871999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,478848.0,0.0,957696.0,0,0.0,957696.0,957696.0,166628.0,74476.0,0.6911042537660097,7194112.0,4763584.0,27.68,2471.5519999999988,0.0,0.0,0.0,478848.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224816.0,148862.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,151040.0,0.0,302080.0,0,0.0,302080.0,302080.0,33748.0,77616.0,0.303042275780324,7172608.0,6243456.0,21.536,2493.087999999999,0.0,0.0,0.0,151040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224144.0,195108.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,153984.0,0.0,307968.0,0,0.0,307968.0,307968.0,34652.0,77959.0,0.3077141664668638,7166336.0,6244096.0,23.296,2516.3839999999987,0.0,0.0,0.0,153984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,223948.0,195128.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,153984.0,0.0,307968.0,0,0.0,307968.0,307968.0,34652.0,74102.0,0.318627360832705,7177472.0,6242944.0,24.032,2540.415999999999,0.0,0.0,0.0,153984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224296.0,195092.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,16000.0,0.3702770780856423,4096000.0,0.0,7.584,2547.9999999999986,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.784,2550.7839999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,124121.0,0.0,248242.0,0,0.0,248242.0,248242.0,42257.0,42435.0,0.49894913333018465,5024640.0,3423200.0,13.728,2564.511999999999,0.0,0.0,0.0,124121.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157020.0,106975.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,64000.0,0.0,6195936.0,6144000.0,10.784,2575.295999999999,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,193623.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,8391904.0,16980480.0,2447808.0,0,0.0,19428288.0,19428288.0,2112.0,20992.0,0.09141274238227147,4103552.0,2048000.0,18.944,2594.239999999999,2132480.0,512000.0,7168000.0,1223904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128236.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,548864.0,2621952.0,1097728.0,0,0.0,3719680.0,3719680.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,51.52,2645.759999999999,2621952.0,0.0,0.0,548864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.704,2650.463999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,2.272,2652.735999999999,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,48000.0,0.0,4608000.0,198016.0,10.432,2663.1679999999988,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144000.0,6188.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,12000.0,0.0,2560000.0,256.0,5.216,2668.3839999999987,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,8.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,8391952.0,16980480.0,2447904.0,0,0.0,19428384.0,19428384.0,2112.0,20992.0,0.09141274238227147,4108160.0,2048000.0,18.624,2687.0079999999984,2132480.0,512000.0,7168000.0,1223952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128380.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.904,2694.9119999999984,0.0,0.0,0.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.368,2697.2799999999984,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.456,2704.7359999999985,0.0,0.0,0.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2707.1359999999986,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,2709.7919999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,2713.1199999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,24576.0,585216.0,49152.0,0,0.0,634368.0,634368.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,9.6,2722.7199999999984,585216.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,2.0,0.0,64.0,32.0,2.368,2725.0879999999984,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.328,2728.4159999999983,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2730.847999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2734.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1935360.0,3346432.0,1548288.0,0,0.0,4894720.0,4894720.0,0.0,16000.0,0.0,0.0,2048000.0,4.288,2738.367999999998,0.0,1024000.0,1161216.0,774144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,3071248.0,5120000.0,1022496.0,0,0.0,6142496.0,6142496.0,0.0,12000.0,0.0,4096000.0,0.0,7.84,2746.2079999999983,0.0,0.0,2560000.0,511248.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,288768.0,0.0,577536.0,0,0.0,577536.0,577536.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,12.544,2758.751999999998,0.0,0.0,0.0,288768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.4,2761.151999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.496,2763.6479999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,2.464,2766.1119999999983,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.432,2768.543999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,272.0,0.0,544.0,0,0.0,544.0,544.0,0.0,6.0,0.0,256.0,512.0,2.528,2771.071999999998,0.0,0.0,0.0,272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,2773.1199999999976,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.016,2775.1359999999977,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.464,2777.5999999999976,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,2779.6479999999974,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,288.0,32.0,2.496,2782.1439999999975,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,20.0,0.0,40.0,0,0.0,40.0,40.0,0.0,5.0,0.0,32.0,32.0,5.888,2788.0319999999974,0.0,0.0,0.0,20.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.496,2790.5279999999975,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,2.496,2793.0239999999976,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,3.072,2796.0959999999977,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.264,2799.359999999998,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2801.759999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,2804.223999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,160.0,0.0,320.0,0,0.0,320.0,320.0,0.0,3.0,0.0,288.0,128.0,3.392,2807.6159999999977,0.0,0.0,0.0,160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,176.0,16.0,0.9166666666666666,256.0,64.0,3.104,2810.7199999999975,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,2.432,2813.1519999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,256.0,32.0,2.336,2815.487999999997,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,288.0,0.0,2.464,2817.951999999997,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,256.0,128.0,2.464,2820.415999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,40704.0,49152.0,11.616,2832.031999999997,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1272.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,64.0,0.0,128.0,0,0.0,128.0,128.0,0.0,2.0,0.0,256.0,32.0,2.784,2834.815999999997,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,96.0,0.0,192.0,0,0.0,192.0,192.0,0.0,2.0,0.0,32.0,32.0,3.328,2838.143999999997,0.0,0.0,0.0,96.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,560.0,0.0,1120.0,0,0.0,1120.0,1120.0,0.0,2.0,0.0,128.0,64.0,2.72,2840.863999999997,0.0,0.0,0.0,560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,2.592,2843.455999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,2.592,2846.047999999997,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,16896.0,36928.0,1024.0,0,0.0,37952.0,37952.0,0.0,32.0,0.0,8192.0,8192.0,3.456,2849.503999999997,64.0,4096.0,16384.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,2852.0959999999973,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,16640.0,36864.0,512.0,0,0.0,37376.0,37376.0,0.0,32.0,0.0,8192.0,8192.0,3.488,2855.583999999997,0.0,4096.0,16384.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,2858.175999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,2860.6719999999973,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.504,2866.175999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,2868.607999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,2871.167999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,2874.207999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,2877.247999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8667648.0,49504.0,11.36,2888.607999999997,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270864.0,1547.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8677120.0,49280.0,11.456,2900.063999999997,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271160.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8664448.0,49312.0,11.584,2911.647999999997,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270764.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,2914.7519999999968,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,2917.7599999999966,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,2921.4079999999967,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,2924.479999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,2927.167999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.296,2930.4639999999968,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.104,2933.5679999999966,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,2937.1839999999966,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.296,2940.4799999999964,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,2943.4239999999963,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.592,2946.0159999999964,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.592,2948.6079999999965,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,38.432,2987.0399999999963,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8687360.0,49376.0,11.648,2998.6879999999965,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271480.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,3001.4079999999963,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.464,3003.871999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,3009.279999999996,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,3011.679999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,3014.207999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.104,3017.311999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.168,3020.479999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28321408.0,199680.0,26.912,3047.3919999999957,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,885044.0,6240.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.072,3050.463999999996,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28565760.0,199136.0,26.784,3077.247999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,892680.0,6223.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.88,3080.127999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35044096.0,49312.0,34.784,3114.911999999996,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1095128.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3117.567999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.688,3120.255999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.632,3125.8879999999963,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3128.319999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,3130.879999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,3133.887999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,3136.959999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8668800.0,49376.0,11.552,3148.511999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270900.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8699520.0,49280.0,11.456,3159.967999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271860.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8685696.0,49280.0,11.616,3171.583999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271428.0,1540.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,3174.719999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.04,3177.759999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.68,3181.439999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,3184.543999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,3187.2639999999956,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,3190.3359999999957,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,3193.3439999999955,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,3196.9919999999956,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,3200.1279999999956,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,3202.8159999999957,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.816,3205.6319999999955,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.592,3208.2239999999956,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,37.952,3246.175999999996,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8691200.0,49312.0,11.456,3257.631999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271600.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3260.287999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,3263.135999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.344,3268.479999999996,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3270.9119999999957,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,3273.503999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.168,3276.671999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.168,3279.839999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28322304.0,199232.0,28.416,3308.255999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,885072.0,6226.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.232,3311.487999999996,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28269568.0,199104.0,26.944,3338.431999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,883424.0,6222.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,3341.375999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35203456.0,49344.0,35.712,3377.087999999996,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1100108.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3379.743999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.784,3382.527999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.472,3387.9999999999964,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3390.431999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,3392.959999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,3396.031999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,3399.071999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8678016.0,49312.0,11.68,3410.751999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271188.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8672384.0,49344.0,11.456,3422.207999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271012.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8702592.0,49408.0,11.488,3433.695999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271956.0,1544.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,3436.7999999999956,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.104,3439.9039999999954,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,3443.5199999999954,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,3446.6239999999952,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3449.279999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.2,3452.479999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,3455.487999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,3459.103999999995,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,3462.175999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.752,3464.927999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.592,3467.519999999995,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.592,3470.111999999995,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,37.888,3507.999999999995,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8668928.0,49312.0,11.616,3519.615999999995,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270904.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,3522.335999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.496,3524.831999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.472,3530.303999999995,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,3532.703999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,3535.263999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.136,3538.399999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.136,3541.535999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28350848.0,198848.0,28.992,3570.5279999999952,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,885964.0,6214.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.072,3573.5999999999954,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28836224.0,199040.0,28.576,3602.1759999999954,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,901132.0,6220.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,3605.1199999999953,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35396992.0,49312.0,35.36,3640.4799999999955,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1106156.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3643.1039999999953,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,3645.631999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.632,3651.263999999995,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3653.695999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,3656.255999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.072,3659.327999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.104,3662.431999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8679424.0,49408.0,11.456,3673.887999999995,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271232.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8668544.0,49344.0,11.392,3685.2799999999947,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270892.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8680832.0,49312.0,11.616,3696.8959999999947,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271276.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.264,3700.159999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.2,3703.3599999999947,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.68,3707.0399999999945,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,3710.1439999999943,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,3712.9279999999944,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.2,3716.1279999999942,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.136,3719.263999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.776,3723.039999999994,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,3726.175999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3728.831999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.72,3731.5519999999938,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.656,3734.2079999999937,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,38.048,3772.255999999994,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8665344.0,49280.0,12.512,3784.767999999994,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270792.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3787.359999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,3789.919999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,3795.327999999994,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3797.759999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.72,3800.4799999999937,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,2.976,3803.4559999999938,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,3806.4959999999937,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28300928.0,198656.0,26.592,3833.087999999994,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,884404.0,6208.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.008,3836.0959999999936,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28785408.0,198720.0,26.816,3862.9119999999934,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,899544.0,6210.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.88,3865.7919999999935,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35062656.0,49184.0,35.136,3900.9279999999935,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1095708.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,3903.7119999999936,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.592,3906.3039999999937,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.536,3911.839999999994,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,3914.2719999999936,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,3916.8319999999935,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.2,3920.0319999999933,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.136,3923.1679999999933,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8673664.0,49312.0,11.744,3934.9119999999934,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271052.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8658432.0,49248.0,11.488,3946.3999999999933,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270576.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8659072.0,49312.0,11.552,3957.9519999999934,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270596.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.328,3961.2799999999934,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.104,3964.383999999993,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.616,3967.999999999993,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,3971.135999999993,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,3973.855999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,3976.9599999999928,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.04,3979.9999999999927,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.744,3983.743999999993,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.136,3986.879999999993,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3989.535999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3992.223999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.688,3994.911999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,37.92,4032.831999999993,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8678016.0,49216.0,12.288,4045.119999999993,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271188.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,4047.775999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,4050.303999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,4055.7119999999927,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,4058.1439999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.56,4060.7039999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,4063.7439999999924,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,4066.8159999999925,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,27801984.0,198848.0,28.928,4095.7439999999924,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,868812.0,6214.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.104,4098.847999999993,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,27998976.0,198432.0,27.008,4125.8559999999925,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,874968.0,6201.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,4128.799999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35025408.0,49408.0,35.584,4164.383999999993,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1094544.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,4167.0079999999925,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,4169.567999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.312,4174.879999999993,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,4177.311999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.688,4179.999999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,4183.0079999999925,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.136,4186.143999999993,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8683520.0,49216.0,11.68,4197.823999999993,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271360.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8668928.0,49408.0,11.392,4209.215999999993,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270904.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8676608.0,49344.0,11.552,4220.767999999993,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271144.0,1542.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4223.871999999993,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.104,4226.975999999993,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.872,4230.847999999994,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4233.951999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,4236.639999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4239.743999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,2.944,4242.687999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,4246.335999999995,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.168,4249.503999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.816,4252.319999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.688,4255.007999999994,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.88,4257.8879999999945,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,37.952,4295.839999999995,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8686720.0,49248.0,11.968,4307.8079999999945,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271460.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.848,4310.6559999999945,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,4313.183999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.504,4318.687999999995,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.368,4321.055999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.656,4323.711999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,4326.751999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.104,4329.855999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,27859328.0,199552.0,29.216,4359.071999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,870604.0,6236.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.04,4362.1119999999955,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28520960.0,198528.0,26.72,4388.831999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,891280.0,6204.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.136,4391.967999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35431680.0,49152.0,36.384,4428.351999999996,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1107240.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.816,4431.167999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.592,4433.759999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.344,4439.103999999996,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.464,4441.567999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,4444.095999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,4447.135999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,4450.175999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8687616.0,49248.0,11.392,4461.567999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271488.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8672000.0,49376.0,11.456,4473.023999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271000.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8667136.0,49376.0,11.552,4484.5759999999955,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270848.0,1543.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.264,4487.839999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.168,4491.007999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.712,4494.719999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4497.823999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,4500.447999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.232,4503.679999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,4506.687999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.712,4510.399999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4513.503999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,4516.159999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.624,4518.783999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.784,4521.567999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,38.048,4559.615999999995,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8676608.0,49248.0,12.448,4572.063999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271144.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,4574.751999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,4577.311999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.376,4582.6879999999965,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.432,4585.119999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,4587.6479999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.168,4590.815999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.008,4593.823999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28986112.0,198080.0,27.072,4620.895999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,905816.0,6190.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.008,4623.903999999996,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,27335168.0,199040.0,29.088,4652.991999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,854224.0,6220.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.88,4655.871999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35188992.0,49280.0,35.488,4691.359999999996,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1099656.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,4694.015999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.528,4696.543999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,4701.951999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,4704.351999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,4706.943999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.136,4710.079999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.04,4713.119999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8684672.0,49312.0,11.424,4724.543999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271396.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8667136.0,49376.0,11.36,4735.903999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,270848.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8674688.0,49248.0,11.552,4747.455999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271084.0,1539.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,4750.527999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.008,4753.5359999999955,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,4757.183999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.072,4760.255999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,4762.943999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.232,4766.175999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.072,4769.247999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,3.648,4772.895999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.104,4775.999999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,4778.975999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.656,4781.631999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.56,4784.191999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,37.856,4822.047999999996,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,9560064.0,20840448.0,245760.0,0,0.0,21086208.0,21086208.0,402432.0,79872.0,0.8343949044585988,8682112.0,49280.0,12.352,4834.399999999996,786432.0,1179648.0,9437184.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271316.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,4837.055999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,4839.615999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.408,4845.023999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,4847.423999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.592,4850.015999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.008,4853.023999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,4856.095999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28319744.0,199776.0,26.816,4882.911999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,884992.0,6243.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.104,4886.015999999996,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,38240256.0,83361792.0,983040.0,0,0.0,84344832.0,84344832.0,1609728.0,319488.0,0.8343949044585988,28425344.0,199424.0,27.296,4913.311999999996,3145728.0,4718592.0,37748736.0,491520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,888292.0,6232.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.976,4916.287999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,38092800.0,82771968.0,688128.0,0,0.0,83460096.0,83460096.0,1508352.0,301056.0,0.833616298811545,35133696.0,49344.0,35.264,4951.551999999996,2555904.0,4718592.0,37748736.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1097928.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,4954.335999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.56,4956.895999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,5.376,4962.271999999996,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,64.0,64.0,2.4,4964.671999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,4967.199999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.04,4970.239999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.072,4973.311999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),690,790848000.0,1586176000.0,640000.0,0,0.0,1586816000.0,1586816000.0,2639000.0,146764.0,0.9473164273786293,118710784.0,4101184.0,171.68,5144.991999999997,0.0,5120000.0,790528000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3709712.0,128162.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.08,5147.0719999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,280.0,0.0,560.0,0,0.0,560.0,560.0,0.0,6.0,0.0,384.0,640.0,2.496,5149.567999999997,0.0,0.0,0.0,280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5152.127999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,512000.0,0.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.768,5156.895999999997,0.0,512000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.048,5158.943999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,770048.0,0.0,1540096.0,0,0.0,1540096.0,1540096.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.632,5164.575999999996,0.0,0.0,0.0,770048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,442368.0,0.0,884736.0,0,0.0,884736.0,884736.0,33792.0,137760.0,0.1969781757134863,8354560.0,160.0,7.04,5171.615999999996,0.0,0.0,0.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261080.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,259086.0,0.0,518172.0,0,0.0,518172.0,518172.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.76,5177.375999999997,0.0,0.0,0.0,259086.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,540672.0,0.0,1081344.0,0,0.0,1081344.0,1081344.0,33792.0,140832.0,0.19351291918636612,8370208.0,224.0,7.104,5184.479999999997,0.0,0.0,0.0,540672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261569.0,7.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,258114.0,0.0,516228.0,0,0.0,516228.0,516228.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.472,5189.951999999997,0.0,0.0,0.0,258114.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,481280.0,0.0,962560.0,0,0.0,962560.0,962560.0,33792.0,138976.0,0.19559177625486202,8361984.0,192.0,7.168,5197.119999999996,0.0,0.0,0.0,481280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261312.0,6.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,258064.0,0.0,516128.0,0,0.0,516128.0,516128.0,8192.0,24192.0,0.25296442687747034,2053376.0,131072.0,5.76,5202.8799999999965,0.0,0.0,0.0,258064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64168.0,4096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,482304.0,0.0,964608.0,0,0.0,964608.0,964608.0,33792.0,139008.0,0.19555555555555557,8397472.0,544.0,7.04,5209.919999999996,0.0,0.0,0.0,482304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262421.0,17.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,48.0,0.0,16448.0,2048.0,3.872,5213.791999999997,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,5215.871999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,41.0,0.9394387001477105,2048.0,0.0,4.768,5220.639999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5222.6879999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,41.0,0.9394387001477105,2048.0,0.0,4.672,5227.359999999996,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,644672.0,0.0,1289344.0,0,0.0,1289344.0,1289344.0,123492.0,33686.0,0.785682474646579,2097856.0,27072.0,7.68,5235.039999999996,0.0,0.0,0.0,644672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65558.0,846.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,6.272,5241.311999999996,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,2080256.0,128000.0,5.056,5246.367999999996,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65008.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,12000.0,0.0,2560000.0,512.0,5.344,5251.711999999996,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,16000.0,0.0,0.0,4096000.0,5.632,5257.3439999999955,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,389632.0,0.0,779264.0,0,0.0,779264.0,779264.0,64512.0,16000.0,0.8012718600953895,2048000.0,0.0,5.92,5263.263999999996,0.0,0.0,0.0,389632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.656,5265.9199999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,478848.0,0.0,957696.0,0,0.0,957696.0,957696.0,166628.0,74874.0,0.6899653004944059,7191424.0,4825984.0,27.232,5293.1519999999955,0.0,0.0,0.0,478848.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224732.0,150812.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,151040.0,0.0,302080.0,0,0.0,302080.0,302080.0,33748.0,77253.0,0.30403329699732434,7179520.0,6242816.0,22.08,5315.231999999995,0.0,0.0,0.0,151040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224360.0,195088.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,153984.0,0.0,307968.0,0,0.0,307968.0,307968.0,34652.0,77523.0,0.3089101849788277,7168384.0,6243072.0,23.36,5338.591999999995,0.0,0.0,0.0,153984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,224012.0,195096.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,153984.0,0.0,307968.0,0,0.0,307968.0,307968.0,34652.0,76015.0,0.3131195387965699,7151872.0,6243328.0,23.68,5362.271999999995,0.0,0.0,0.0,153984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,223496.0,195104.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,16000.0,0.3702770780856423,4096000.0,0.0,7.712,5369.983999999996,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.656,5372.639999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,124121.0,0.0,248242.0,0,0.0,248242.0,248242.0,42257.0,42882.0,0.4963295317069733,5021824.0,3422240.0,14.016,5386.655999999995,0.0,0.0,0.0,124121.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,156932.0,106945.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,64000.0,0.0,6196832.0,6144000.0,10.592,5397.247999999995,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,193651.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,8391904.0,16980480.0,2447808.0,0,0.0,19428288.0,19428288.0,2112.0,20992.0,0.09141274238227147,4099200.0,2048000.0,18.592,5415.839999999995,2132480.0,512000.0,7168000.0,1223904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128100.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,548864.0,2621952.0,1097728.0,0,0.0,3719680.0,3719680.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,51.104,5466.943999999995,2621952.0,0.0,0.0,548864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.704,5471.647999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,2.176,5473.823999999995,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,1536000.0,0.0,3072000.0,0,0.0,3072000.0,3072000.0,0.0,48000.0,0.0,4608000.0,198464.0,10.208,5484.031999999995,0.0,0.0,0.0,1536000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144000.0,6202.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,12000.0,0.0,2560000.0,0.0,5.248,5489.279999999994,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,8391950.0,16980480.0,2447900.0,0,0.0,19428380.0,19428380.0,2112.0,20992.0,0.09141274238227147,4116096.0,2048000.0,18.88,5508.159999999994,2132480.0,512000.0,7168000.0,1223950.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128628.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.488,5515.647999999995,0.0,0.0,0.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,5518.175999999995,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,7.52,5525.695999999995,0.0,0.0,0.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,5528.127999999995,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,5530.687999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,5533.951999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,24576.0,585216.0,49152.0,0,0.0,634368.0,634368.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,9.824,5543.775999999995,585216.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,2.0,0.0,64.0,32.0,2.432,5546.207999999995,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.328,5549.5359999999955,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,5551.999999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,5555.231999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1935360.0,3346432.0,1548288.0,0,0.0,4894720.0,4894720.0,0.0,16000.0,0.0,0.0,2048000.0,4.288,5559.519999999995,0.0,1024000.0,1161216.0,774144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,3071246.0,5120000.0,1022492.0,0,0.0,6142492.0,6142492.0,0.0,12000.0,0.0,4096000.0,192000.0,8.192,5567.711999999995,0.0,0.0,2560000.0,511246.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128000.0,6000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,288768.0,0.0,577536.0,0,0.0,577536.0,577536.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,12.512,5580.223999999995,0.0,0.0,0.0,288768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.4,5582.623999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.464,5585.087999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,2.528,5587.6159999999945,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.464,5590.0799999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,280.0,0.0,560.0,0,0.0,560.0,560.0,0.0,6.0,0.0,384.0,640.0,2.528,5592.607999999995,0.0,0.0,0.0,280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,5594.6559999999945,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.016,5596.671999999994,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.496,5599.167999999994,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.016,5601.183999999994,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,416.0,32.0,2.592,5603.7759999999935,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,20.0,0.0,40.0,0,0.0,40.0,40.0,0.0,5.0,0.0,32.0,32.0,5.632,5609.407999999993,0.0,0.0,0.0,20.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.528,5611.935999999993,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,2.4,5614.335999999993,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,3.136,5617.471999999993,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.2,5620.671999999993,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,5623.135999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
