Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.208,5.472,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.328,8.8,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.912,11.712,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,13.728,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,15.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,17.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.272,19.808,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.944,22.752,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,25.311999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,27.807999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.912,30.719999999999995,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,33.151999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.496,35.647999999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.56,38.208,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,4352.0,16384.0,4.192,42.4,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.848,45.248,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.456,48.704,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.848,51.552,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.592,54.144,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.624,56.768,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.296,60.064,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.624,62.688,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.2,65.888,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.656,68.54400000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.688,71.23200000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,75.20000000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,77.63200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,80.28800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,83.32800000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,86.46400000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575936.0,16384.0,10.624,97.08800000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174248.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576960.0,16384.0,9.952,107.04000000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174280.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576064.0,16384.0,10.208,117.24800000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174252.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,120.41600000000003,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,123.52000000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,127.16800000000002,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,130.30400000000003,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,132.86400000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,136.00000000000003,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.168,139.16800000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,142.81600000000003,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,145.98400000000004,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,148.51200000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.48,168.99200000000002,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572096.0,16384.0,9.76,178.752,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174128.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,181.34400000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,183.872,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,187.74400000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,190.17600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,192.83200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.296,196.12800000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,199.29600000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19267328.0,65728.0,22.88,222.17600000000002,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,602104.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.168,225.34400000000002,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18998784.0,66016.0,24.064,249.40800000000002,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,593712.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,252.06400000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22312448.0,16384.0,29.152,281.216,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697264.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.752,283.968,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.656,286.624,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,290.49600000000004,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,292.92800000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,295.6480000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,298.7200000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,301.8560000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574656.0,16384.0,10.112,311.96800000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174208.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5580032.0,16384.0,10.24,322.20800000000014,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174376.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575552.0,16384.0,9.92,332.12800000000016,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174236.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,335.32800000000015,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,338.43200000000013,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,342.11200000000014,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,345.2160000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,347.84000000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,351.10400000000016,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.232,354.3360000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,357.95200000000017,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,361.0880000000002,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,363.6480000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.224,383.8720000000002,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570816.0,16384.0,9.984,393.85600000000017,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174088.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,396.44800000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,398.94400000000013,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,402.81600000000014,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,405.3120000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,407.96800000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,411.04000000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,414.1440000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18863232.0,65792.0,24.064,438.20800000000014,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,589476.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.944,441.15200000000016,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19467264.0,65920.0,22.784,463.93600000000015,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,608352.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.784,466.72000000000014,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22282624.0,16384.0,31.232,497.9520000000001,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696332.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,500.6080000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.656,503.2640000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,507.2000000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,509.6640000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,512.2880000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,515.3280000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,518.4320000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5579904.0,16384.0,9.856,528.2880000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174372.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575040.0,16384.0,10.08,538.3680000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174220.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574912.0,16384.0,9.952,548.3200000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174216.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,551.4240000000002,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,554.4320000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,558.0800000000003,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,561.2160000000002,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.816,564.0320000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,567.1360000000003,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,570.2720000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,573.9200000000003,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,577.2160000000003,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,579.7760000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.48,600.2560000000003,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571840.0,16384.0,9.6,609.8560000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174120.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,612.4480000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,614.9440000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,618.8480000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,621.2800000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,623.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,626.9440000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.264,630.2080000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19532928.0,65760.0,22.688,652.8960000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,610404.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.976,655.8720000000003,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19347968.0,65760.0,23.04,678.9120000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,604624.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.688,681.6000000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22297344.0,16384.0,29.344,710.9440000000003,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696792.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,713.6000000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,716.1280000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,720.0960000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,722.6560000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,725.2160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.008,728.2240000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,731.3600000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5582080.0,16384.0,9.824,741.1840000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174440.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575680.0,16384.0,10.08,751.2640000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174240.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5578368.0,16384.0,10.112,761.3760000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174324.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,764.5120000000001,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,767.552,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.872,771.424,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,774.528,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,777.216,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,780.48,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,783.616,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,787.264,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,790.4,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,793.0559999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,813.184,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570816.0,16416.0,9.76,822.944,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174088.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,825.5039999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,828.0959999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,831.9999999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,834.4319999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,837.0239999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,840.0639999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,843.1359999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19086720.0,65696.0,23.2,866.3359999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596460.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.944,869.2799999999999,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19078016.0,66048.0,24.0,893.2799999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596188.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,895.9359999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22284032.0,16384.0,29.376,925.3119999999998,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696376.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,927.8719999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,930.4639999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.032,934.4959999999998,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,936.9279999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,939.4879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,942.5599999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,945.6959999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576576.0,16384.0,10.016,955.7119999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174268.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5577344.0,16384.0,10.144,965.8559999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174292.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574656.0,16384.0,9.856,975.7119999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174208.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,978.8159999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,981.9199999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,985.5999999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,988.7999999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.528,991.3279999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,994.5599999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,997.6959999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,1001.3119999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,1004.4479999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1007.0079999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,1027.1359999999995,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571072.0,16384.0,9.824,1036.9599999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1039.5199999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,1042.0159999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1045.9199999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1048.3199999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1050.9119999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,1053.9519999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,1057.1199999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19107968.0,65696.0,23.616,1080.7359999999996,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,597124.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,1083.7439999999997,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19268992.0,65728.0,23.008,1106.7519999999997,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,602156.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,1109.4719999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22292224.0,16384.0,30.464,1139.9359999999997,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696632.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1142.5279999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.464,1144.9919999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,1148.9919999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1151.4559999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1154.0159999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,1157.0559999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,1160.0959999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575168.0,16384.0,9.984,1170.0799999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174224.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5577600.0,16384.0,10.176,1180.2559999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174300.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576832.0,16384.0,9.664,1189.9199999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174276.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,1193.0239999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,1196.0639999999994,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,1199.6799999999994,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,1203.0079999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1205.5679999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,1208.8319999999992,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,1211.8719999999992,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,1215.4879999999991,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,1218.5919999999992,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1221.2159999999992,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.096,1241.3119999999992,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.92,1251.2319999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1253.8239999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,1256.3199999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1260.2239999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1262.6879999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1265.2799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,1268.3199999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,1271.4239999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19243264.0,65728.0,22.912,1294.3359999999996,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,601352.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.944,1297.2799999999995,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19498752.0,66144.0,23.808,1321.0879999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,609336.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1323.7439999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22284672.0,16384.0,29.376,1353.1199999999994,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696396.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1355.6799999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,1358.1759999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1362.0799999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1364.6079999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1367.2639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,1370.3039999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1373.3759999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5578496.0,16384.0,10.048,1383.4239999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174328.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574912.0,16384.0,10.112,1393.5359999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174216.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575296.0,16416.0,10.016,1403.5519999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174228.0,513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.072,1406.6239999999993,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.2,1409.8239999999994,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.936,1413.7599999999993,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,1416.8959999999993,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.816,1419.7119999999993,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,1422.9119999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.2,1426.1119999999994,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.712,1429.8239999999994,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,1432.9279999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1435.5199999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,1455.6479999999995,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573248.0,16384.0,9.92,1465.5679999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174164.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1468.1279999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,1470.6559999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,1474.5599999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1476.9919999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1479.5519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.136,1482.6879999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1485.7599999999993,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18848640.0,65696.0,24.096,1509.8559999999993,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,589020.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,1512.9279999999992,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19088896.0,65632.0,23.392,1536.3199999999993,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596528.0,2051.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1538.9759999999992,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22307072.0,16384.0,30.368,1569.3439999999991,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697096.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1571.9359999999992,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.656,1574.5919999999992,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1578.527999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1580.991999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1583.647999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1586.719999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,1589.7599999999989,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575808.0,16384.0,10.048,1599.8079999999989,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174244.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5579008.0,16384.0,10.08,1609.8879999999988,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174344.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5579008.0,16384.0,10.016,1619.9039999999989,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174344.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,1623.1359999999988,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.168,1626.3039999999987,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,1629.9519999999986,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,1633.1839999999986,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,1635.8719999999987,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,1639.1359999999986,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,2.976,1642.1119999999987,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,1645.7599999999986,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,1648.9919999999986,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1651.5519999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,65536.0,6014976.0,0.0,0,0.0,6014976.0,6014976.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,20.128,1671.6799999999985,5091328.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570816.0,16448.0,9.792,1681.4719999999984,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174088.0,514.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1684.0639999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,1686.5919999999985,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,1690.4639999999986,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1693.0239999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1695.6159999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,1698.7199999999987,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,1701.7919999999986,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19224064.0,65920.0,23.36,1725.1519999999985,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,600752.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.008,1728.1599999999985,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19015168.0,65760.0,23.68,1751.8399999999986,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,594224.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1754.4959999999985,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22286080.0,16416.0,29.12,1783.6159999999984,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696440.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,1786.1759999999983,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,1788.7359999999983,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,1792.6719999999982,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1795.1039999999982,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1797.6959999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,1800.7679999999982,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,1803.935999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,636915712.0,1371070464.0,29171712.0,0,0.0,1400242176.0,1400242176.0,9192128.0,7596800.0,0.5475113122171946,840837632.0,2694112.0,690.816,2494.751999999998,48619520.0,77791232.0,622329856.0,14585856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,26276176.0,84191.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2496.799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.464,2499.263999999998,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,2501.663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.184,2506.847999999998,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2508.863999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.696,2514.559999999998,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20522240.0,0.0,12.896,2527.4559999999983,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,641320.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,247304.0,0.0,494608.0,0,0.0,494608.0,494608.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.92,2533.3759999999984,0.0,0.0,0.0,247304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,487424.0,0.0,974848.0,0,0.0,974848.0,974848.0,31416.0,461728.0,0.0637055302305209,20675392.0,0.0,12.576,2545.9519999999984,0.0,0.0,0.0,487424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646106.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243724.0,0.0,487448.0,0,0.0,487448.0,487448.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,6.016,2551.9679999999985,0.0,0.0,0.0,243724.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,487424.0,0.0,974848.0,0,0.0,974848.0,974848.0,31416.0,461728.0,0.0637055302305209,20623872.0,0.0,12.288,2564.2559999999985,0.0,0.0,0.0,487424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.952,2570.2079999999987,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,441728.0,0.0,883456.0,0,0.0,883456.0,883456.0,31416.0,460300.0,0.06389053844088864,20579328.0,128.0,12.576,2582.7839999999987,0.0,0.0,0.0,441728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,643104.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.616,2586.3999999999987,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2588.4479999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.64,2593.0879999999984,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2595.135999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.704,2599.8399999999983,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,106108.0,34560.0,0.7543151249751188,2473696.0,10912.0,7.584,2607.423999999998,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,341.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.976,2614.3999999999983,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,7.136,2621.5359999999982,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,72320.0,7.2,2628.735999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,2260.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.72,2635.455999999998,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388510.0,0.0,777020.0,0,0.0,777020.0,777020.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.464,2641.919999999998,0.0,0.0,0.0,388510.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.688,2644.607999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,499584.0,0.0,999168.0,0,0.0,999168.0,999168.0,170386.0,83344.0,0.6715248492492019,8316288.0,5626176.0,27.552,2672.159999999998,0.0,0.0,0.0,499584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,259884.0,175818.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,90782.0,0.3048638549419584,8461184.0,7410944.0,23.424,2695.583999999998,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264412.0,231592.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,91708.0,0.30680735914375123,8432640.0,7410816.0,23.264,2718.847999999998,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263520.0,231588.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,89582.0,0.31181820975324953,8431232.0,5637536.0,23.488,2742.335999999998,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263476.0,176173.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.704,2751.039999999998,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.656,2753.695999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,51518.0,0.42854290531546724,5949568.0,3837216.0,14.784,2768.479999999998,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185924.0,119913.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7331296.0,7292928.0,11.648,2780.1279999999983,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229103.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.536,2845.6639999999984,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,230.368,3076.0319999999983,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.184,3081.2159999999985,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,3083.3599999999983,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,212512.0,10.944,3094.3039999999983,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6641.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,1664.0,6.816,3101.119999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,52.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9884996.0,20076672.0,2753160.0,0,0.0,22829832.0,22829832.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.856,3166.975999999998,2452096.0,607744.0,8508416.0,1376580.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.096,3175.071999999998,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,3177.5039999999976,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.32,3185.823999999998,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,3188.223999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,3190.815999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,3194.143999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.744,3201.887999999998,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.816,3204.703999999998,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.808,3208.511999999998,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.88,3211.391999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,3214.623999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.184,3219.807999999998,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649732.0,6082560.0,1216904.0,0,0.0,7299464.0,7299464.0,0.0,14280.0,0.0,4861952.0,183296.0,9.024,3228.831999999998,0.0,0.0,3041280.0,608452.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,5728.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,9.408,3238.239999999998,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,3240.735999999998,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.016,3242.751999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,3244.831999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.592,3247.423999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,3249.855999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.04,3252.895999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.2,3256.0959999999977,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,3258.591999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,3260.991999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.36,3264.351999999998,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,3267.295999999998,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,3269.727999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.592,3272.319999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.464,3274.783999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.496,3277.279999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,16640.0,16384.0,6.528,3283.8079999999977,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.752,3286.5599999999977,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.776,3290.3359999999975,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.752,3293.0879999999975,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.56,3295.6479999999974,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.624,3298.271999999997,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.232,3301.503999999997,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.624,3304.127999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.2,3307.327999999997,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.688,3310.015999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,3312.575999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.352,3316.9279999999967,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3319.3599999999965,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3321.9199999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,3324.9599999999964,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.2,3328.159999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575680.0,16384.0,10.112,3338.2719999999963,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174240.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574784.0,16384.0,10.272,3348.5439999999962,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174212.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575936.0,16384.0,10.176,3358.719999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174248.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,3361.919999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.456,3365.375999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,3369.055999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.2,3372.2559999999958,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.784,3375.039999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3378.207999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.008,3381.215999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.744,3384.959999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3388.127999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3390.687999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3393.311999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,3395.8719999999958,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,65344.0,6016520.0,0.0,0,0.0,6016520.0,6016520.0,33286.0,64.0,0.9980809595202399,81920.0,16384.0,20.608,3416.479999999996,5093274.0,792558.0,65344.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5574528.0,16384.0,9.632,3426.111999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174204.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3428.671999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.752,3431.423999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,3435.359999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3437.759999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3440.319999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,3443.423999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,3446.591999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19184256.0,65856.0,23.296,3469.887999999996,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,599508.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.912,3472.7999999999956,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19075968.0,66016.0,23.712,3496.5119999999956,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,596124.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3499.1679999999956,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22300544.0,16448.0,29.728,3528.8959999999956,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696892.0,514.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3531.4879999999957,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.56,3534.0479999999957,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,3537.9519999999957,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3540.4159999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3543.0079999999957,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.168,3546.175999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,3549.2799999999957,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5579904.0,16384.0,10.144,3559.4239999999954,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174372.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575680.0,16384.0,9.856,3569.2799999999957,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174240.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574912.0,16384.0,10.048,3579.3279999999954,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174216.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,3582.6239999999952,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,3585.727999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,3589.407999999995,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.328,3592.735999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,3595.3599999999947,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,3598.4959999999946,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.232,3601.7279999999946,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,3605.3759999999947,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3608.543999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3611.135999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3613.7599999999948,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,3616.447999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,65472.0,6016856.0,0.0,0,0.0,6016856.0,6016856.0,33286.0,64.0,0.9980809595202399,81920.0,16384.0,20.352,3636.7999999999947,5093342.0,792570.0,65472.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5573760.0,16384.0,9.888,3646.6879999999946,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174180.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3649.3439999999946,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3651.8719999999944,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,3655.8079999999945,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3658.3679999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,3661.0879999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,3664.191999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,3667.327999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19117952.0,65664.0,23.552,3690.879999999994,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,597436.0,2052.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.976,3693.8559999999943,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19149184.0,65792.0,23.136,3716.9919999999943,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598412.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.752,3719.7439999999942,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22290048.0,16384.0,30.752,3750.495999999994,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696564.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3753.0879999999943,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,3755.6799999999944,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,3759.551999999994,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3762.015999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3764.6079999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,3767.647999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,3770.7199999999943,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5577856.0,16384.0,9.856,3780.5759999999946,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174308.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576064.0,16384.0,9.76,3790.335999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174252.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576192.0,16384.0,9.696,3800.0319999999947,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174256.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.36,3803.391999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,3806.431999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,3810.1119999999946,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,3813.2479999999946,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3815.9039999999945,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3819.0719999999947,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,3822.1759999999945,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,3825.8559999999943,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,3829.0239999999944,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3831.6159999999945,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,3834.2399999999943,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,3836.7999999999943,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,65472.0,6016856.0,0.0,0,0.0,6016856.0,6016856.0,33286.0,64.0,0.9980809595202399,81920.0,16384.0,20.288,3857.0879999999943,5093342.0,792570.0,65472.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5572352.0,16384.0,9.568,3866.6559999999945,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174136.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3869.2479999999946,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,3871.7759999999944,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.0,3875.7759999999944,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.592,3878.3679999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3880.9279999999944,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.008,3883.9359999999942,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.04,3886.975999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19465984.0,65952.0,23.104,3910.079999999994,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,608312.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,3913.151999999994,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19315712.0,66080.0,23.616,3936.767999999994,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,603616.0,2065.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.688,3939.455999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22321152.0,16416.0,30.368,3969.823999999994,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697536.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3972.4159999999943,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,3974.9119999999944,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,3978.8159999999943,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3981.2799999999943,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3983.8399999999942,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,3986.9119999999944,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,3990.0479999999943,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5579904.0,16384.0,9.92,3999.9679999999944,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174372.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5577216.0,16384.0,10.08,4010.0479999999943,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174288.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576064.0,16384.0,10.048,4020.095999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174252.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4023.263999999994,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,4026.3359999999943,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.616,4029.9519999999943,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4033.0879999999943,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4035.6799999999944,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4038.8159999999943,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.168,4041.9839999999945,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,4045.6319999999946,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,4048.8959999999947,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4051.487999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,4054.079999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.624,4056.7039999999947,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,65472.0,6016856.0,0.0,0,0.0,6016856.0,6016856.0,33286.0,64.0,0.9980809595202399,81920.0,16384.0,20.416,4077.119999999995,5093342.0,792570.0,65472.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570560.0,16384.0,10.368,4087.487999999995,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174080.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4090.079999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,4092.6079999999947,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.872,4096.479999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.624,4099.103999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,4101.759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4104.831999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,4107.967999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19138944.0,65696.0,23.232,4131.199999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598092.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,2.976,4134.175999999995,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18978432.0,65760.0,23.808,4157.983999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,593076.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.88,4160.863999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22285440.0,16384.0,29.632,4190.495999999995,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696420.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4193.119999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,4195.6159999999945,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,4199.583999999994,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4202.015999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,4204.639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,4207.679999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,4210.847999999994,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576192.0,16384.0,10.368,4221.215999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174256.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575040.0,16384.0,9.92,4231.135999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174220.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574784.0,16384.0,9.984,4241.119999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174212.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4244.255999999995,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,4247.327999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,4251.007999999995,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4254.143999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4256.7679999999955,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4259.903999999996,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.04,4262.943999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,4266.623999999996,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4269.759999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4272.351999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.592,4274.943999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,4277.503999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,65472.0,6016856.0,0.0,0,0.0,6016856.0,6016856.0,33286.0,64.0,0.9980809595202399,81920.0,16384.0,20.384,4297.887999999996,5093342.0,792570.0,65472.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570944.0,16384.0,10.016,4307.903999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174092.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4310.495999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,4313.023999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4316.927999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4319.391999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4321.951999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4325.023999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,4328.095999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19179776.0,65792.0,23.36,4351.4559999999965,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,599368.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.04,4354.4959999999965,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19274112.0,65600.0,22.656,4377.151999999996,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,602316.0,2050.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,4379.807999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22298624.0,16384.0,30.336,4410.143999999997,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696832.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.816,4412.959999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,4415.487999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.904,4419.391999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4421.855999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4424.415999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.296,4427.711999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,4430.783999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574656.0,16384.0,10.016,4440.799999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174208.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576064.0,16384.0,10.016,4450.815999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174252.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574784.0,16384.0,9.728,4460.543999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174212.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,4463.775999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,4466.847999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,4470.495999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.296,4473.791999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4476.415999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4479.583999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,4482.655999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,4486.303999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4489.471999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4492.063999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,4494.623999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,4497.311999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.352,4517.663999999997,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571200.0,16384.0,10.016,4527.679999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174100.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,4530.335999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,4532.831999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.808,4536.639999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4539.103999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4541.663999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4544.735999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,4547.871999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19628928.0,66208.0,23.04,4570.9119999999975,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613404.0,2069.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.104,4574.015999999998,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19394816.0,66080.0,23.744,4597.7599999999975,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,606088.0,2065.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,4600.479999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22285824.0,16384.0,29.856,4630.3359999999975,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696432.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4632.927999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,4635.455999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,4639.391999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4641.855999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4644.447999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.04,4647.487999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.136,4650.623999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5576832.0,16384.0,10.048,4660.671999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174276.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574784.0,16384.0,9.824,4670.4959999999965,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174212.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574656.0,16384.0,10.112,4680.6079999999965,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174208.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4683.743999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.104,4686.847999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,4690.5279999999975,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.104,4693.631999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4696.223999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4699.359999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.168,4702.5279999999975,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.744,4706.271999999997,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.264,4709.535999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4712.095999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.688,4714.783999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,4717.343999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.32,4737.663999999998,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5570688.0,16384.0,9.984,4747.647999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174084.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,4750.239999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.592,4752.831999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.128,4756.959999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,4759.487999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,4762.1439999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.104,4765.247999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,4768.351999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19232128.0,65824.0,23.52,4791.8719999999985,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,601004.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.2,4795.071999999998,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19157760.0,65856.0,23.392,4818.463999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,598680.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,4821.119999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22308864.0,16416.0,30.272,4851.391999999998,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,697152.0,513.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4854.015999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.496,4856.511999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.936,4860.447999999998,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,4862.9119999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,4865.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4868.671999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.168,4871.839999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5575552.0,16384.0,9.984,4881.823999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174236.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5577600.0,16384.0,10.304,4892.127999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174300.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,5574912.0,16384.0,10.048,4902.175999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174216.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4905.343999999997,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.136,4908.479999999998,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.648,4912.127999999998,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.168,4915.295999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,4917.855999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.136,4920.991999999998,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,3.072,4924.0639999999985,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,180224.0,0.0,360448.0,0,0.0,360448.0,360448.0,0.0,256.0,0.0,16384.0,16384.0,3.68,4927.743999999999,0.0,0.0,0.0,180224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,12288.0,4096.0,24576.0,0,0.0,28672.0,28672.0,0.0,384.0,0.0,24576.0,16384.0,3.232,4930.975999999999,0.0,4096.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4933.5999999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.56,4936.159999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,320.0,0.0,32768.0,32768.0,2.72,4938.879999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,65536.0,6017024.0,0.0,0,0.0,6017024.0,6017024.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,20.608,4959.487999999999,5093376.0,792576.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,5571840.0,16384.0,9.568,4969.056,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,174120.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,4971.679999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.528,4974.208,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,4.16,4978.3679999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4980.799999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,4983.455999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,4986.527999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.104,4989.632,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,19045888.0,66208.0,23.552,5013.183999999999,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,595184.0,2069.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,180224.0,344064.0,32768.0,0,0.0,376832.0,376832.0,0.0,256.0,0.0,65536.0,65536.0,3.072,5016.255999999999,16384.0,0.0,163840.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18887808.0,66016.0,24.064,5040.32,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,590244.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.688,5043.008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,22292992.0,16384.0,29.664,5072.672,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,696656.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,5075.263999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,2.656,5077.919999999999,0.0,4096.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,3.968,5081.887999999999,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,5084.351999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,5086.911999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,16896.0,16384.0,3.072,5089.9839999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,32768.0,16384.0,3.072,5093.056,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,636915712.0,1371070464.0,29171712.0,0,0.0,1400242176.0,1400242176.0,9192128.0,7596800.0,0.5475113122171946,868234880.0,2796384.0,691.04,5784.096,48619520.0,77791232.0,622329856.0,14585856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,27132340.0,87387.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,5786.208,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.56,5788.768,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,5791.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.44,5796.736,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,5798.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.92,5804.736,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20760064.0,0.0,12.352,5817.088,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,648752.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,247395.0,0.0,494790.0,0,0.0,494790.0,494790.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.696,5822.784,0.0,0.0,0.0,247395.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,487424.0,0.0,974848.0,0,0.0,974848.0,974848.0,31416.0,461728.0,0.0637055302305209,20820352.0,0.0,12.128,5834.911999999999,0.0,0.0,0.0,487424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,650636.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243735.0,0.0,487470.0,0,0.0,487470.0,487470.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,6.048,5840.959999999999,0.0,0.0,0.0,243735.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,445536.0,0.0,891072.0,0,0.0,891072.0,891072.0,31416.0,460419.0,0.0638750800573363,20799424.0,0.0,12.512,5853.471999999999,0.0,0.0,0.0,445536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,649982.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.536,5859.007999999999,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,468384.0,0.0,936768.0,0,0.0,936768.0,936768.0,31416.0,461133.0,0.06378248661554485,20732352.0,128.0,12.256,5871.263999999999,0.0,0.0,0.0,468384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,647886.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.68,5874.9439999999995,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,5876.991999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.608,5881.599999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,5883.615999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.64,5888.255999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,151700.0,34560.0,0.8144529152797165,2473696.0,10752.0,7.84,5896.096,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,336.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.112,5902.208,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,6.144,5908.352,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,256.0,6.528,5914.88,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,8.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.592,5921.472,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388514.0,0.0,777028.0,0,0.0,777028.0,777028.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.656,5928.128,0.0,0.0,0.0,388514.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,5930.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,516864.0,0.0,1033728.0,0,0.0,1033728.0,1033728.0,177406.0,83989.0,0.6786893398879091,8460032.0,5666464.0,28.032,5958.88,0.0,0.0,0.0,516864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264376.0,177077.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,91219.0,0.3038471224805965,8446336.0,7410688.0,23.2,5982.08,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263948.0,231584.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90066.0,0.3106631153563556,8430208.0,7410944.0,23.744,6005.824,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263444.0,231592.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,91444.0,0.30742081585046277,8442240.0,5635648.0,23.392,6029.215999999999,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263820.0,176114.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.544,6037.759999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,6040.383999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,51100.0,0.43053914904049745,5923456.0,3842624.0,14.464,6054.847999999999,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185108.0,120082.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7332512.0,7292928.0,11.648,6066.495999999999,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229141.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.696,6132.191999999999,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,228.224,6360.415999999999,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.056,6365.471999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.112,6367.583999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,214848.0,11.072,6378.655999999999,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6714.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,5376.0,6.368,6385.023999999999,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,168.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884995.0,20076672.0,2753158.0,0,0.0,22829830.0,22829830.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,66.176,6451.2,2452096.0,607744.0,8508416.0,1376579.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.84,6459.04,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,6461.472,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.712,6469.184,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,6471.584,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,6474.112,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,6477.312,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,8.288,6485.599999999999,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,6488.031999999999,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,6491.3279999999995,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.56,6493.888,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,6497.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.184,6502.272,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649731.0,6082560.0,1216902.0,0,0.0,7299462.0,7299462.0,0.0,14280.0,0.0,4861952.0,72192.0,8.768,6511.04,0.0,0.0,3041280.0,608451.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,2256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,9.536,6520.576,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.496,6523.072,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,6525.152,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,6527.232,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.592,6529.824,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.464,6532.288,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,6535.392,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.232,6538.624,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,6541.056,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
