Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.888,3.904,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.984,5.888,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.336,8.224,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,11.392,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.912,14.303999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.224,18.528,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.648,22.176,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.816,24.991999999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,27.359999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,29.695999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.528,32.224,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.232,35.455999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,38.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,41.056,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.2,44.256,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,46.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.784,49.76,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.912,52.672,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,17408.0,65536.0,4.704,57.376,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.04,60.416,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,4.128,64.544,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.976,67.52,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.04,70.56,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.136,73.696,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.552,77.248,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.976,80.224,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.584,83.808,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.912,86.72000000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.912,89.63200000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,7.104,96.73600000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,99.48800000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.976,102.46400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.392,105.85600000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,109.15200000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79241472.0,65888.0,81.216,190.368,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2476296.0,2059.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80809088.0,65856.0,80.608,270.976,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2525284.0,2058.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79483520.0,65856.0,80.64,351.616,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2483860.0,2058.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,355.072,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.68,358.752,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,363.00800000000004,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,366.49600000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.04,369.53600000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,372.96000000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.712,376.672,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,380.86400000000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,384.22400000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.2,387.42400000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.272,425.696,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78030848.0,65824.0,82.144,507.84000000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2438464.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,510.78400000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,513.6,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,7.072,520.672,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,523.392,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,526.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,529.6,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,532.928,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241748864.0,194048.0,206.976,739.904,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7554652.0,6064.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.456,743.36,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241913216.0,191392.0,206.272,949.6320000000001,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7559788.0,5981.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.072,952.7040000000001,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,223496064.0,65696.0,218.464,1171.1680000000001,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6984252.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,1174.496,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.912,1177.4080000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.944,1184.352,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,1187.104,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,1189.9840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.264,1193.248,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,1196.544,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78942464.0,65888.0,82.048,1278.592,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2466952.0,2059.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79115904.0,65984.0,82.304,1360.8960000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2472372.0,2062.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78589696.0,65888.0,81.6,1442.496,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2455928.0,2059.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,1445.952,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.712,1449.664,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.288,1453.952,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,1457.312,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,1460.192,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,1463.616,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,1467.104,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.16,1471.2640000000001,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,1474.7520000000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,1477.6960000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.272,1515.968,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78349184.0,66016.0,80.896,1596.864,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2448412.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,1599.776,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.944,1602.72,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,1609.6000000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,1612.352,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,1615.2640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,1618.624,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,1621.952,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,243535872.0,193152.0,207.36,1829.312,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7610496.0,6036.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,1832.6399999999999,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,238440704.0,190624.0,206.976,2039.616,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7451272.0,5957.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.232,2042.848,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,226431488.0,65696.0,213.44,2256.288,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7075984.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,2259.232,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,2262.112,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,2268.992,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,2271.6800000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,2274.5280000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.552,2278.0800000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,2281.376,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79299072.0,65888.0,81.024,2362.4,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2478096.0,2059.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78707456.0,65760.0,81.504,2443.904,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2459608.0,2055.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79703936.0,65600.0,81.984,2525.888,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2490748.0,2050.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,2529.2799999999997,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,2532.7999999999997,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,2537.024,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,2540.448,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,2543.392,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,2546.7839999999997,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,2550.3039999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.32,2554.624,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,2557.984,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,2560.864,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.304,2599.168,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78547968.0,65664.0,82.4,2681.568,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2454624.0,2052.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,2684.512,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.072,2687.5840000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,2694.4320000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,2697.184,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,2700.0640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.744,2703.8080000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,2707.1360000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242456192.0,194336.0,204.352,2911.4880000000003,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7576756.0,6073.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,2914.8160000000003,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,239529600.0,190560.0,206.72,3121.536,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7485300.0,5955.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.424,3124.96,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,222220928.0,65824.0,215.616,3340.576,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6944404.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,3343.488,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,3346.368,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,3353.216,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,3355.9359999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,3358.7839999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.424,3362.2079999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.424,3365.6319999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80333824.0,66080.0,81.792,3447.4239999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2510432.0,2065.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78378112.0,65792.0,82.112,3529.5359999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2449316.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79718400.0,65888.0,80.928,3610.4639999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2491200.0,2059.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,3613.8879999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,3617.3759999999993,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,3621.5679999999993,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,3624.9279999999994,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.168,3628.0959999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.584,3631.6799999999994,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,3635.1999999999994,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.448,3639.6479999999992,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.584,3643.231999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.072,3646.303999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.208,3684.5119999999993,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78574592.0,65888.0,82.048,3766.5599999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2455456.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,3769.5679999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.976,3772.5439999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.976,3779.5199999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,3782.2079999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.944,3785.1519999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.488,3788.6399999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,3791.9999999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242898816.0,191840.0,205.952,3997.9519999999993,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7590588.0,5995.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.296,4001.247999999999,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241210240.0,192672.0,205.088,4206.335999999999,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7537820.0,6021.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.168,4209.503999999999,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,224294656.0,65856.0,213.536,4423.039999999999,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7009208.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,4425.9839999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.848,4428.831999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,4435.7119999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.88,4438.592,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,4441.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.392,4444.864,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.648,4448.512,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78859264.0,65952.0,80.32,4528.831999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464352.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79081088.0,66112.0,80.736,4609.567999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2471284.0,2066.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79652352.0,65824.0,80.192,4689.759999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2489136.0,2057.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,4693.183999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.68,4696.864,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.416,4701.28,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,4704.704,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,4707.679999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.552,4711.231999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.648,4714.879999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,4719.103999999999,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,4722.592,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,4725.536,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.24,4763.776,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78132480.0,65920.0,81.728,4845.504,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2441640.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,4848.416,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,4851.232,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.944,4858.176,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.656,4860.832,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,4863.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.296,4867.136,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,4870.464000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241493888.0,192704.0,206.08,5076.544000000001,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7546684.0,6022.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,5079.872000000001,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242037632.0,193440.0,205.408,5285.280000000002,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7563676.0,6045.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.136,5288.416000000002,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,224746880.0,65728.0,214.272,5502.688000000002,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7023340.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.104,5505.792000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.912,5508.704000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.784,5515.488000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,5518.2400000000025,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,5521.120000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,5524.448000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,5527.744000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78955392.0,65984.0,84.896,5612.640000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467356.0,2062.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78431872.0,65952.0,80.448,5693.088000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450996.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79741312.0,65856.0,80.384,5773.472000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2491916.0,2058.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,5776.896000000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.552,5780.448000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.352,5784.800000000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.68,5788.480000000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,5791.3920000000035,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.648,5795.040000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.552,5798.592000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,5802.784000000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,5806.208000000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.168,5809.376000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.208,5847.584000000003,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78858624.0,65856.0,80.224,5927.808000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464332.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,5930.688000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.008,5933.696000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.944,5940.640000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,5943.456000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,5946.336000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.52,5949.856000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,5953.152000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,236216704.0,190848.0,205.28,6158.432000000003,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7381772.0,5964.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.296,6161.728000000004,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242534272.0,191904.0,205.856,6367.5840000000035,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7579196.0,5997.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.104,6370.688000000004,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,226477568.0,65824.0,213.888,6584.576000000004,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7077424.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,6587.488000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.136,6590.624000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.784,6597.408000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,6600.128000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,6603.008000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,6606.368000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,6609.728000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80084096.0,65984.0,81.664,6691.3920000000035,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2502628.0,2062.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79930368.0,66112.0,80.192,6771.5840000000035,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2497824.0,2066.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79889536.0,66272.0,83.68,6855.264000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2496548.0,2071.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.616,6858.880000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.648,6862.528000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.16,6866.688000000004,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,6870.112000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.848,6872.960000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,6876.3520000000035,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.68,6880.032000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,6884.256000000004,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.84,6888.096000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.2,6891.296000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.24,6929.536000000004,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78649472.0,66208.0,81.76,7011.296000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457796.0,2069.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,7014.240000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,7017.120000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,7024.000000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,7026.752000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,7029.632000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,7032.992000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.392,7036.384000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,240444160.0,191552.0,206.208,7242.592000000004,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7513880.0,5986.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,7245.920000000005,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242387328.0,192544.0,206.336,7452.256000000005,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7574604.0,6017.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.456,7455.712000000005,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,225896960.0,65696.0,213.184,7668.896000000005,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7059280.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,7671.808000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.944,7674.752000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,7681.632000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,7684.352000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,7687.200000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,7690.528000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.552,7694.080000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80167808.0,65984.0,79.872,7773.952000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2505244.0,2062.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79091200.0,65792.0,82.048,7856.000000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2471600.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78866688.0,65952.0,80.064,7936.064000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464584.0,2061.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.552,7939.616000000006,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.648,7943.2640000000065,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,7947.488000000007,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,7950.8800000000065,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,7953.792000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,7957.280000000007,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,7960.768000000007,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.128,7964.896000000007,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,7968.320000000007,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,7971.200000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,38.4,8009.600000000007,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78391040.0,65952.0,83.2,8092.800000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2449720.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,8095.744000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,8098.624000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,8105.504000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,8108.320000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,8111.200000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.52,8114.7200000000075,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.296,8118.016000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242443520.0,192640.0,207.2,8325.216000000008,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7576360.0,6020.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,8328.544000000007,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241763328.0,191136.0,204.8,8533.344000000006,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7555104.0,5973.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.136,8536.480000000007,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,229955200.0,65920.0,214.72,8751.200000000006,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7186100.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,8754.208000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.976,8757.184000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.912,8764.096000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,8766.944000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.072,8770.016000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.424,8773.440000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,8776.800000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,533504000.0,1148928000.0,18432000.0,0,0.0,1167360000.0,1167360000.0,6928000.0,6208000.0,0.5274056029232643,755914368.0,594464.0,580.96,9357.76000000001,34816000.0,65536000.0,524288000.0,9216000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23622324.0,18577.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,9360.096000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,9363.008000000009,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,9365.728000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.392,9369.120000000008,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.464,9371.584000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.32,9375.904000000008,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.12,9381.024000000009,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,77676.0,0.0,155352.0,0,0.0,155352.0,155352.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.704,9385.728000000008,0.0,0.0,0.0,77676.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,5.056,9390.784000000009,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,64536.0,0.0,129072.0,0,0.0,129072.0,129072.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.576,9395.360000000008,0.0,0.0,0.0,64536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,122880.0,0.0,245760.0,0,0.0,245760.0,245760.0,8448.0,34824.0,0.19523017193566278,2106624.0,0.0,5.152,9400.512000000008,0.0,0.0,0.0,122880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.288,9404.800000000008,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,114688.0,0.0,229376.0,0,0.0,229376.0,229376.0,8448.0,34568.0,0.19639204017109912,2106624.0,128.0,5.024,9409.824000000008,0.0,0.0,0.0,114688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.392,9413.216000000008,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,9415.552000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.544,9420.096000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,9422.432000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.512,9426.944000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,29192.0,8424.0,0.7760527435133986,525824.0,7168.0,6.56,9433.504000000006,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,224.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.688,9440.192000000006,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.704,9444.896000000006,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.424,9448.320000000007,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.456,9451.776000000007,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,387898.0,0.0,775796.0,0,0.0,775796.0,775796.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.832,9456.608000000007,0.0,0.0,0.0,387898.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.008,9459.616000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17858.0,0.6999563157364159,1693696.0,1210208.0,15.808,9475.424000000008,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52928.0,37819.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17785.0,0.34779419854046717,1696000.0,1560576.0,13.184,9488.608000000007,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53000.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17686.0,0.3785227352589781,1688448.0,1194240.0,14.4,9503.008000000007,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52764.0,37320.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,9368.0,17677.0,0.34638565354039563,1691136.0,1560576.0,15.04,9518.048000000008,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52848.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.64,9522.688000000007,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.88,9525.568000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9416.0,0.5286107634543179,1158144.0,823808.0,7.936,9533.504000000006,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36192.0,25744.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1549504.0,1536000.0,4.96,9538.464000000005,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48422.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,996480.0,512000.0,19.104,9557.568000000005,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31140.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.072,9608.640000000005,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.296,9611.936000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.656,9614.592000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,52672.0,9.6,9624.192000000006,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1646.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.52,9627.712000000007,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,2097992.0,4245120.0,611984.0,0,0.0,4857104.0,4857104.0,528.0,5248.0,0.09141274238227147,1000448.0,512000.0,18.88,9646.592000000006,533120.0,128000.0,1792000.0,305992.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31264.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.088,9675.680000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.912,9678.592000000006,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.768,9707.360000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,9710.176000000007,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.88,9713.056000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.552,9716.608000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,10.24,9726.848000000005,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.848,9729.696000000005,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.712,9733.408000000005,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.688,9736.096000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,9739.584000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.416,9744.000000000004,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,767816.0,1280000.0,255632.0,0,0.0,1535632.0,1535632.0,0.0,3000.0,0.0,1024000.0,0.0,4.864,9748.864000000003,0.0,0.0,640000.0,127816.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.408,9762.272000000003,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.72,9764.992000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,9767.776000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,9770.624000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.88,9773.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.976,9776.480000000001,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.4,9778.880000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,9781.216,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,9784.064,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,9786.4,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.848,9789.248,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.272,9795.52,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,9798.368,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.784,9801.152,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,9804.256,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.488,9807.743999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.688,9810.431999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,9813.215999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.744,9816.96,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.264,9820.223999999998,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.848,9823.071999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.688,9825.759999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.72,9828.479999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.008,9831.487999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,66560.0,65536.0,6.624,9838.111999999997,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2080.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.944,9841.055999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.776,9844.831999999997,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,3.136,9847.967999999997,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.752,9850.719999999998,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.944,9853.663999999997,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.52,9857.183999999997,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.912,9860.095999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.584,9863.679999999998,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.912,9866.591999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,9869.471999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,9876.319999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,9879.007999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,9881.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.392,9885.247999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.424,9888.671999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78549376.0,66016.0,81.056,9969.728,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2454668.0,2063.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80568320.0,66112.0,81.44,10051.168,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2517760.0,2066.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79046400.0,65760.0,80.864,10132.032,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2470200.0,2055.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.68,10135.712,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.552,10139.264,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,10143.455999999998,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,10146.943999999998,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,10149.887999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.52,10153.407999999998,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,10156.927999999998,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,10161.151999999998,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.648,10164.799999999997,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,10167.807999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,10170.847999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.168,10174.015999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,260608.0,24064064.0,0.0,0,0.0,24064064.0,24064064.0,133195.0,256.0,0.9980816929060105,327680.0,65536.0,38.528,10212.543999999998,20372688.0,3170160.0,260608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78508160.0,65920.0,80.64,10293.183999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2453380.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,10296.127999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,10299.007999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.912,10305.919999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,10308.607999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,10311.455999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,10314.783999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,10318.111999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241710336.0,192896.0,205.696,10523.807999999995,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7553448.0,6028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.328,10527.135999999995,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241651968.0,193024.0,206.272,10733.407999999996,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7551624.0,6032.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.136,10736.543999999996,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,228228224.0,66080.0,210.304,10946.847999999996,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7132132.0,2065.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,10949.727999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.168,10952.895999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,7.008,10959.903999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,10962.623999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,10965.535999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.296,10968.831999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.424,10972.255999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78907520.0,66144.0,81.12,11053.375999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2465860.0,2067.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78623488.0,65952.0,80.576,11133.951999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2456984.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78752896.0,65760.0,80.128,11214.079999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2461028.0,2055.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.584,11217.663999999997,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,11221.151999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,11225.407999999996,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,11228.863999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,11231.839999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,11235.231999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,11238.719999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,11242.943999999996,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.552,11246.495999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,11249.503999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.104,11252.607999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,11255.647999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,261568.0,24066584.0,0.0,0,0.0,24066584.0,24066584.0,133147.0,256.0,0.9980810026761018,327680.0,65536.0,38.656,11294.303999999996,20373198.0,3170250.0,261568.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78650368.0,65792.0,81.92,11376.223999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457824.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,11379.135999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,11381.951999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.976,11388.927999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,11391.647999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,11394.527999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,11397.855999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,11401.183999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,243269504.0,192896.0,205.408,11606.591999999995,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7602172.0,6028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.52,11610.111999999996,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,239505024.0,191680.0,207.136,11817.247999999996,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7484532.0,5990.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.168,11820.415999999996,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,225564928.0,65856.0,212.0,12032.415999999996,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7048904.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.04,12035.455999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.848,12038.303999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,12045.183999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,12047.903999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,12050.751999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,12054.079999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,12057.439999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79455616.0,65952.0,81.024,12138.463999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2482988.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80190720.0,65824.0,80.992,12219.455999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2505960.0,2057.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79705984.0,65632.0,81.088,12300.543999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2490812.0,2051.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.776,12304.319999999994,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,12307.839999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.16,12311.999999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.424,12315.423999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,12318.431999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.552,12321.983999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.552,12325.535999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,12329.727999999994,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,12333.183999999994,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,12336.127999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.104,12339.231999999993,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.072,12342.303999999993,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,261696.0,24066920.0,0.0,0,0.0,24066920.0,24066920.0,133135.0,256.0,0.9980808300410072,327680.0,65536.0,38.272,12380.575999999994,20373266.0,3170262.0,261696.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79274112.0,65792.0,80.96,12461.535999999993,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2477316.0,2056.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,12464.447999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.848,12467.295999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.88,12474.175999999992,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,12476.895999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,12479.77599999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.552,12483.32799999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,12486.687999999991,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242850944.0,191936.0,205.504,12692.191999999992,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7589092.0,5998.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.296,12695.487999999992,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,244237184.0,190720.0,205.056,12900.543999999993,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7632412.0,5960.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.2,12903.743999999993,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,233688960.0,65728.0,212.704,13116.447999999993,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7302780.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,13119.455999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,13122.271999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.816,13129.087999999994,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,13131.839999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,13134.687999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.296,13137.983999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.392,13141.375999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80126336.0,65696.0,79.584,13220.959999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2503948.0,2053.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78566912.0,66048.0,80.672,13301.631999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2455216.0,2064.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79133952.0,65600.0,79.52,13381.151999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2472936.0,2050.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,13384.543999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,13388.031999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,13392.255999999996,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.648,13395.903999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.264,13399.167999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,13402.527999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.584,13406.111999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.16,13410.271999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,13413.631999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,13416.639999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,13419.679999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.104,13422.783999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,261696.0,24066920.0,0.0,0,0.0,24066920.0,24066920.0,133135.0,256.0,0.9980808300410072,327680.0,65536.0,38.464,13461.247999999996,20373266.0,3170262.0,261696.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78960640.0,65856.0,80.256,13541.503999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467520.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,13544.415999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,13547.295999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.944,13554.239999999994,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,13557.087999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,13559.935999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.488,13563.423999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,13566.783999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241457920.0,191552.0,205.312,13772.095999999994,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7545560.0,5986.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.264,13775.359999999993,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,240382848.0,190464.0,204.16,13979.519999999993,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7511964.0,5952.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.424,13982.943999999994,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,231371392.0,65856.0,212.864,14195.807999999994,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7230356.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,14198.783999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.008,14201.791999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.784,14208.575999999994,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,14211.359999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,14214.175999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,14217.535999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.328,14220.863999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79590016.0,65760.0,80.672,14301.535999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2487188.0,2055.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79018240.0,65792.0,79.584,14381.119999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2469320.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79920512.0,65984.0,80.192,14461.311999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2497516.0,2062.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.52,14464.831999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,14468.351999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,14472.607999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.584,14476.191999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,14479.135999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,14482.623999999994,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,14486.143999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,14490.367999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,14493.823999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,14496.799999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.104,14499.903999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,14502.943999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,261792.0,24067172.0,0.0,0,0.0,24067172.0,24067172.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,38.336,14541.279999999995,20373317.0,3170271.0,261792.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78958208.0,65856.0,80.8,14622.079999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467444.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,14625.055999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,14627.935999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.752,14634.687999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,14637.439999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.976,14640.415999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,14643.775999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.552,14647.327999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,243040512.0,194272.0,205.44,14852.767999999996,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7595016.0,6071.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.488,14856.255999999996,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,240962816.0,192384.0,204.224,15060.479999999996,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7530088.0,6012.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.456,15063.935999999996,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,228382336.0,65664.0,212.096,15276.031999999996,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7136948.0,2052.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,15278.943999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.848,15281.791999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,15288.639999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,15291.327999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,15294.207999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.488,15297.695999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.552,15301.247999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80091776.0,65824.0,79.328,15380.575999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2502868.0,2057.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78866944.0,65728.0,80.288,15460.863999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464592.0,2054.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80651520.0,65824.0,80.512,15541.375999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2520360.0,2057.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,15544.767999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.68,15548.447999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,15552.671999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.712,15556.383999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.976,15559.359999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.36,15562.719999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,15566.239999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,15570.431999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.52,15573.951999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.04,15576.991999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,15580.031999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.072,15583.103999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,38.72,15621.823999999997,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78493952.0,65888.0,80.096,15701.919999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2452936.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.008,15704.927999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.944,15707.871999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,15714.719999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,15717.439999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,15720.319999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.456,15723.775999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,15727.135999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241492608.0,192096.0,203.552,15930.687999999995,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7546644.0,6003.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.488,15934.175999999994,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,240122368.0,190944.0,207.424,16141.599999999995,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7503824.0,5967.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.104,16144.703999999994,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,226063488.0,66048.0,214.496,16359.199999999993,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7064484.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.072,16362.271999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.136,16365.407999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.976,16372.383999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,16375.103999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,16377.951999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,16381.279999999993,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.392,16384.671999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78710016.0,65664.0,81.6,16466.271999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2459688.0,2052.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79481344.0,65952.0,81.824,16548.095999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2483792.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80537472.0,65792.0,80.16,16628.255999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2516796.0,2056.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,16631.711999999992,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,16635.231999999993,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.128,16639.359999999993,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.584,16642.943999999992,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.88,16645.823999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,16649.215999999993,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.52,16652.735999999994,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,16656.991999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.456,16660.447999999993,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.168,16663.615999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.072,16666.687999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.04,16669.727999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,38.304,16708.031999999996,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78680576.0,65728.0,81.12,16789.151999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2458768.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,16792.095999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.104,16795.199999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,7.136,16802.335999999992,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,16805.055999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,16808.063999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.36,16811.423999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.488,16814.911999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241217536.0,191904.0,204.128,17019.039999999997,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7538048.0,5997.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.296,17022.335999999996,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241505664.0,190976.0,204.768,17227.103999999996,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7547052.0,5968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.424,17230.527999999995,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,223715072.0,65728.0,215.104,17445.631999999994,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6991096.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.04,17448.671999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.88,17451.551999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,17458.399999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,17461.215999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,17464.095999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.488,17467.584,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,17470.944,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79907456.0,65952.0,80.352,17551.296,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2497108.0,2061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78949376.0,65824.0,81.248,17632.543999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467168.0,2057.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80710656.0,65920.0,79.648,17712.192,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2522208.0,2060.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,17715.584,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,17719.072,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,17723.264,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.488,17726.752,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.168,17729.920000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.52,17733.440000000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,3.488,17736.928000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.352,17741.280000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,3.392,17744.672000000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,17747.616,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.072,17750.688000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,3.072,17753.760000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,38.368,17792.128,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78810240.0,65888.0,81.184,17873.312,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2462820.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,17876.224000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,17879.04,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.912,17885.952,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,17888.672000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,17891.552000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,17894.880000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.392,17898.272000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,241083392.0,191648.0,209.184,18107.456000000006,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7533856.0,5989.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,484352.0,924672.0,88064.0,0,0.0,1012736.0,1012736.0,0.0,688.0,0.0,176128.0,176128.0,3.296,18110.752000000004,44032.0,0.0,440320.0,44032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5504.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,183525376.0,395231232.0,6340608.0,0,0.0,401571840.0,401571840.0,2383232.0,2135552.0,0.5274056029232643,242381312.0,192896.0,204.352,18315.104000000003,11976704.0,22544384.0,180355072.0,3170304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7574416.0,6028.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,44032.0,0.0,0,0.0,44032.0,44032.0,0.0,1032.0,0.0,352256.0,176128.0,3.168,18318.272000000004,0.0,44032.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,5504.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,183304192.0,394788864.0,5898240.0,0,0.0,400687104.0,400687104.0,2324480.0,2121728.0,0.5228005527406725,224314880.0,65824.0,214.24,18532.512000000006,11534336.0,22544384.0,180355072.0,2949120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7009840.0,2057.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.944,18535.456000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.912,18538.368000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,6.848,18545.216000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,18548.000000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,18550.84800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,3.328,18554.17600000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,3.36,18557.53600000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,533504000.0,1148928000.0,18432000.0,0,0.0,1167360000.0,1167360000.0,6928000.0,6208000.0,0.5274056029232643,757278976.0,596032.0,582.08,19139.616000000013,34816000.0,65536000.0,524288000.0,9216000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23664968.0,18626.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,19141.98400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,3.04,19145.024000000012,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,19147.776000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.296,19151.07200000001,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,19153.40800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,19157.76000000001,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.12,19162.88000000001,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,78060.0,0.0,156120.0,0,0.0,156120.0,156120.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,19167.232000000007,0.0,0.0,0.0,78060.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,5.248,19172.480000000007,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,64525.0,0.0,129050.0,0,0.0,129050.0,129050.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,19176.832000000006,0.0,0.0,0.0,64525.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,123904.0,0.0,247808.0,0,0.0,247808.0,247808.0,8448.0,34856.0,0.19508590430445225,2106624.0,0.0,5.024,19181.856000000007,0.0,0.0,0.0,123904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.608,19186.464000000007,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,109568.0,0.0,219136.0,0,0.0,219136.0,219136.0,8448.0,34408.0,0.1971252566735113,2106624.0,128.0,5.088,19191.552000000007,0.0,0.0,0.0,109568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.456,19195.008000000005,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,19197.376000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.544,19201.920000000006,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,19204.288000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.576,19208.864000000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,30709.0,8422.0,0.7847742199279344,525824.0,7008.0,6.304,19215.168000000005,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,219.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.592,19221.760000000006,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.416,19226.176000000007,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.84,19230.016000000007,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.392,19233.408000000007,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,387911.0,0.0,775822.0,0,0.0,775822.0,775822.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.448,19237.856000000007,0.0,0.0,0.0,387911.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.912,19240.768000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17876.0,0.6997446922870196,1699584.0,1233216.0,15.904,19256.672000000006,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53112.0,38538.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17836.0,0.34714494875549046,1694080.0,1560704.0,13.024,19269.696000000007,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52940.0,48772.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17651.0,0.3789888470604792,1687680.0,1193248.0,14.944,19284.640000000007,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52740.0,37289.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,9368.0,17720.0,0.34583579444772594,1687552.0,1560704.0,14.912,19299.552000000007,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52736.0,48772.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.544,19304.09600000001,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.848,19306.94400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9548.0,0.5251404983339135,1158784.0,820512.0,8.224,19315.16800000001,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36212.0,25641.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548576.0,1536000.0,4.928,19320.09600000001,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48393.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1001984.0,512000.0,18.72,19338.81600000001,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31312.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.168,19389.98400000001,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.296,19393.28000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.624,19395.90400000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,49888.0,9.824,19405.72800000001,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1559.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.552,19409.28000000001,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,2097991.0,4245120.0,611982.0,0,0.0,4857102.0,4857102.0,528.0,5248.0,0.09141274238227147,1022592.0,512000.0,19.136,19428.41600000001,533120.0,128000.0,1792000.0,305991.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31956.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.44,19457.856000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.784,19460.640000000007,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.088,19489.728000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,19492.544000000005,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.816,19495.360000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,19498.848000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,10.208,19509.056000000004,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.752,19511.808000000005,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.712,19515.520000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.784,19518.304000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,19521.792000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.352,19526.144000000004,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,767815.0,1280000.0,255630.0,0,0.0,1535630.0,1535630.0,0.0,3000.0,0.0,1024000.0,0.0,5.12,19531.264000000003,0.0,0.0,640000.0,127815.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.376,19544.640000000003,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.88,19547.520000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,19550.304000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,19553.120000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,19555.904000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.912,19558.816000000003,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,19561.152000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,19563.52,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,19566.336,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.496,19568.832,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.912,19571.744,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.144,19577.888,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.88,19580.768,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,19583.52,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.168,19586.688000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.584,19590.272,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.72,19592.992000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
