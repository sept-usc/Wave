Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.792,5.024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,6.5920000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.6,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",6,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.496,10.688,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.016,12.704,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",8,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,15.232000000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,17.28,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.944,20.224,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,22.624,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,25.119999999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",13,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.592,27.711999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",14,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,4.896,32.608,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",15,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.88,35.488,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",16,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.784,38.272,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",17,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,3.136,41.408,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",18,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.528,43.936,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",19,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,3.008,46.944,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",20,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.496,49.440000000000005,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",21,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.944,52.38400000000001,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",22,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,54.848000000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.624,57.47200000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",24,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,4.0,61.47200000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",25,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,64.32000000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,66.97600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.104,70.08000000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",28,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,72.64000000000001,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",29,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12192.0,8.416,81.05600000000001,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,381.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",30,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,84.32000000000001,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",31,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,87.23200000000001,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2621472.0,12032.0,7.616,94.84800000000001,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81921.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.392,98.24000000000001,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",34,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,101.05600000000001,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",35,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11968.0,7.68,108.73600000000002,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.296,112.03200000000002,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",37,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,114.88000000000002,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,118.01600000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.168,121.18400000000003,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",40,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.584,124.76800000000003,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,127.84000000000003,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",42,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,130.49600000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,133.60000000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,136.60800000000006,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",45,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,140.06400000000005,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",46,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,143.13600000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,145.76000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",48,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.16,165.92000000000004,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",49,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.296,173.21600000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,175.84000000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,178.43200000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",52,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,182.01600000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",53,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,184.44800000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",54,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,187.04000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",55,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,190.11200000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",56,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,192.70400000000006,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",57,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700864.0,12288.0,13.92,206.62400000000005,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303152.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",58,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.976,209.60000000000005,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",59,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700864.0,12288.0,14.56,224.16000000000005,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303152.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",60,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,226.75200000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",61,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10473472.0,6144.0,16.192,242.94400000000007,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327296.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,245.63200000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,248.19200000000006,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",64,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,251.87200000000007,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,254.30400000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,256.96000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,259.93600000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,262.528,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",69,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617984.0,12128.0,7.968,270.49600000000004,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81812.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",70,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,273.696,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,276.54400000000004,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",72,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12032.0,7.584,284.12800000000004,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",73,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,287.32800000000003,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",74,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,290.17600000000004,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",75,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618720.0,12128.0,7.904,298.08000000000004,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81835.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,301.31200000000007,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",77,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,304.1600000000001,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,307.2000000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,310.2400000000001,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,313.7280000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,316.76800000000014,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,319.42400000000015,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,322.43200000000013,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,325.4400000000001,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,328.8640000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,331.9680000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,334.5920000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",88,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.224,354.8160000000001,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",89,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,361.82400000000007,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,364.4480000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,367.0400000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",92,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,370.7200000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,373.1520000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,375.6800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,378.6560000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",96,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,381.28000000000014,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",97,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700480.0,12288.0,15.232,396.51200000000017,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303140.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,399.42400000000015,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",99,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705216.0,12288.0,14.304,413.7280000000001,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303288.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",100,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,416.2880000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.36,431.64800000000014,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,434.2400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,436.8000000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",104,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.808,440.6080000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",105,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,443.0080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",106,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,445.5680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,448.5120000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.656,451.1680000000001,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",109,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618368.0,12128.0,8.16,459.32800000000015,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81824.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",110,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,462.5600000000002,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",111,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,465.4080000000002,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",112,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618048.0,11936.0,7.584,472.9920000000002,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81814.0,373.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",113,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.328,476.32000000000016,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",114,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.072,479.39200000000017,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",115,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11968.0,7.584,486.97600000000017,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,490.17600000000016,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",117,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,493.1200000000002,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,496.1600000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",119,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,499.2000000000002,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",120,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,502.65600000000023,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,505.6640000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,508.3200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,511.36000000000024,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,514.4960000000002,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",125,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,517.9520000000002,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,520.9600000000003,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,523.5520000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",128,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.096,543.6480000000003,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",129,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,550.6240000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,553.2160000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,555.7760000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",132,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.712,559.4880000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",133,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,561.9200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,564.4800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,567.4240000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",136,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,570.0480000000001,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",137,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9710336.0,12288.0,13.856,583.9040000000001,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303448.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,586.8160000000001,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",139,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699456.0,12288.0,14.592,601.4080000000001,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303108.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,603.9680000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",141,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.36,619.3280000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,621.9520000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",143,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,624.4800000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",144,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.808,628.2880000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",145,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,630.6880000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,633.248,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.104,636.3520000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",148,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,638.912,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",149,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12096.0,7.68,646.592,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,378.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",150,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,649.824,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",151,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,652.6719999999999,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",152,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618912.0,11936.0,7.744,660.4159999999999,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81841.0,373.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,663.616,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",154,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,666.432,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",155,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618208.0,12032.0,7.52,673.952,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81819.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.168,677.12,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",157,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,680.0,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,683.04,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,2.976,686.016,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",160,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,689.536,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,692.544,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,695.168,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,698.368,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,701.3760000000001,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",165,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,704.8640000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,707.9040000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",167,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,710.5280000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",168,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.032,730.5600000000002,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.688,737.2480000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",170,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,739.8720000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",171,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,742.4320000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",172,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,746.0480000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",173,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,748.4800000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",174,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,751.1680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,754.1120000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",176,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.752,756.864,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",177,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705216.0,12288.0,14.496,771.36,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303288.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",178,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.88,774.24,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",179,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9698560.0,12288.0,14.592,788.832,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303080.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",180,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,791.424,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",181,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.232,806.656,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",182,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,809.28,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",183,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,811.8399999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",184,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.744,815.584,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",185,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,817.9839999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,820.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,823.4559999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.656,826.1119999999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",189,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12000.0,7.424,833.5359999999998,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,375.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",190,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.456,836.9919999999998,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,839.8399999999998,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",192,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2619232.0,11872.0,7.712,847.5519999999998,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81851.0,371.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,850.7519999999998,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",194,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,853.5679999999999,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",195,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11968.0,7.968,861.5359999999998,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",196,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,864.7359999999999,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",197,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,867.5839999999998,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,870.5919999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.104,873.6959999999999,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.584,877.2799999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,880.4799999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,883.1039999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,886.112,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,889.12,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,892.5120000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,895.6160000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,898.2080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.16,918.368,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",209,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.52,925.888,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,928.544,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",211,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,931.136,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",212,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,934.752,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",213,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,937.1519999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,939.7119999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,942.6559999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",216,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.784,945.4399999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",217,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705728.0,12288.0,13.984,959.4239999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303304.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.944,962.3679999999998,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",219,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705600.0,12288.0,13.856,976.2239999999998,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303300.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",220,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,978.7839999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",221,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.4,993.1839999999997,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",222,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,995.8079999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,998.3359999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",224,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,1002.0159999999997,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",225,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1004.4479999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1006.9759999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,1009.9199999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1012.5439999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",229,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618464.0,11968.0,7.808,1020.3519999999997,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81827.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",230,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.392,1023.7439999999998,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",231,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,1026.5599999999997,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",232,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2619072.0,11968.0,7.552,1034.1119999999996,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81846.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",233,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.456,1037.5679999999995,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",234,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,1040.4159999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",235,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617568.0,12032.0,8.064,1048.4799999999996,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81799.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,1051.6799999999996,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",237,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,1054.5919999999996,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,1057.6959999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,1060.7359999999996,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",240,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,1064.2559999999996,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1067.3279999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",242,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1069.9199999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,1073.0239999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.168,1076.1919999999996,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1079.6479999999995,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,1082.6559999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1085.2479999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",248,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.128,1105.3759999999995,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",249,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,1112.3519999999996,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1114.9759999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,1117.5359999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,1121.1519999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1123.5839999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1126.1439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,1129.1199999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.688,1131.8079999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",257,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9697920.0,12288.0,15.2,1147.0079999999998,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303060.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.976,1149.984,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",259,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699584.0,12288.0,15.296,1165.28,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303112.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1167.84,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",261,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.816,1182.656,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",262,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1185.28,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1187.808,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",264,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.776,1191.584,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",265,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1193.9840000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1196.544,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,1199.616,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.72,1202.336,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",269,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12064.0,7.936,1210.272,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,377.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",270,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,1213.504,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",271,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,1216.3519999999999,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11968.0,8.0,1224.3519999999999,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.392,1227.744,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",274,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.784,1230.528,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",275,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618816.0,12224.0,7.424,1237.952,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81838.0,382.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",276,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,1241.152,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",277,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,1244.0,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,1247.168,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,2.976,1250.144,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1253.6,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,2.976,1256.576,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1259.2,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1262.272,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,1265.28,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",285,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1268.7359999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1271.7759999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",287,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1274.368,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",288,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.128,1294.4959999999999,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",289,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.104,1301.6,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1304.224,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",291,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,1306.816,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",292,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,1310.432,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1312.864,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1315.4560000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.912,1318.3680000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1320.9600000000003,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",297,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9710592.0,12288.0,13.952,1334.9120000000003,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303456.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,3.072,1337.9840000000002,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",299,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701760.0,12288.0,14.752,1352.736,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303180.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",300,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1355.3280000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",301,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6112.0,15.584,1370.9120000000003,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,191.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,1373.5680000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1376.0960000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.776,1379.8720000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1382.3040000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1384.8640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,1387.8400000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",308,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1390.4640000000004,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",309,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11872.0,7.968,1398.4320000000005,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,371.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.488,1401.9200000000005,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",311,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,1404.7360000000006,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",312,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617696.0,12000.0,7.712,1412.4480000000005,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81803.0,375.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",313,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,1415.6800000000005,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",314,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,1418.5280000000005,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",315,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618720.0,11968.0,7.872,1426.4000000000005,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81835.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",316,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,1429.6640000000004,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",317,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,1432.6080000000004,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,1435.7120000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,1438.7200000000005,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",320,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,1442.1120000000005,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,1445.2800000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",322,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1447.8720000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1450.9120000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,1454.0480000000005,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",325,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1457.5040000000004,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1460.5440000000003,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",327,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1463.1680000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",328,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.096,1483.2640000000004,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",329,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.848,1490.1120000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1492.7360000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",331,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,1495.3280000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",332,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,1498.9120000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",333,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1501.3440000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1504.0000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",335,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.04,1507.0400000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1509.6640000000004,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",337,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702272.0,12288.0,14.4,1524.0640000000005,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303196.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",338,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.88,1526.9440000000006,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",339,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699072.0,12288.0,14.752,1541.6960000000006,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303096.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",340,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.848,1544.5440000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",341,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.848,1559.3920000000005,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,1562.0480000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1564.5760000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.776,1568.3520000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1570.7520000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,1573.2480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.912,1576.1600000000008,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1578.7200000000007,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",349,121548800.0,255100544.0,9723904.0,0,0.0,264824448.0,264824448.0,4861952.0,4178240.0,0.5378151260504201,481864064.0,570880.0,520.448,2099.1680000000006,7140992.0,14585856.0,116686848.0,4861952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15058252.0,17840.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,2101.2480000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.496,2103.7440000000006,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2106.1760000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,152576.0,0.0,0,0.0,152576.0,152576.0,0.0,2392.0,0.0,607744.0,607744.0,3.328,2109.5040000000004,0.0,152576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2111.5200000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",355,227968.0,0.0,455936.0,0,0.0,455936.0,455936.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.416,2115.9360000000006,0.0,0.0,0.0,227968.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",356,128736.0,0.0,257472.0,0,0.0,257472.0,257472.0,9834.0,179547.0,0.05192706765726234,6418336.0,0.0,9.216,2125.1520000000005,0.0,0.0,0.0,128736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",357,76342.0,0.0,152684.0,0,0.0,152684.0,152684.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.032,2129.1840000000007,0.0,0.0,0.0,76342.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",358,157344.0,0.0,314688.0,0,0.0,314688.0,314688.0,9834.0,180441.0,0.051683090264091444,6418336.0,0.0,9.088,2138.272000000001,0.0,0.0,0.0,157344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",359,76040.0,0.0,152080.0,0,0.0,152080.0,152080.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.032,2142.304000000001,0.0,0.0,0.0,76040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",360,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,9834.0,180292.0,0.051723593827251405,6418336.0,0.0,9.184,2151.488000000001,0.0,0.0,0.0,152576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",361,76033.0,0.0,152066.0,0,0.0,152066.0,152066.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.032,2155.5200000000013,0.0,0.0,0.0,76033.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",362,128736.0,0.0,257472.0,0,0.0,257472.0,257472.0,9834.0,179547.0,0.05192706765726234,6418336.0,32.0,8.768,2164.2880000000014,0.0,0.0,0.0,128736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",363,703.0,0.0,1406.0,0,0.0,1406.0,1406.0,0.0,15.0,0.0,4800.0,608.0,3.168,2167.4560000000015,0.0,0.0,0.0,703.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2169.5360000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",365,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,19.0,0.9709923664122138,608.0,0.0,4.352,2173.8880000000013,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2175.968000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",367,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,19.0,0.9709923664122138,608.0,0.0,4.32,2180.2880000000014,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",368,190308.0,0.0,380616.0,0,0.0,380616.0,380616.0,37228.0,9600.0,0.7949944477662937,622464.0,2528.0,6.016,2186.3040000000015,0.0,0.0,0.0,190308.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19452.0,79.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",369,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.984,2192.2880000000014,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",370,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,14244.0,0.0,610432.0,37984.0,4.224,2196.5120000000015,0.0,0.0,0.0,303872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1187.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",371,19072.0,0.0,38144.0,0,0.0,38144.0,38144.0,0.0,3588.0,0.0,759680.0,0.0,3.616,2200.1280000000015,0.0,0.0,0.0,19072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",372,608384.0,0.0,1216768.0,0,0.0,1216768.0,1216768.0,0.0,4748.0,0.0,0.0,1215488.0,3.104,2203.2320000000013,0.0,0.0,0.0,608384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",373,387434.0,0.0,774868.0,0,0.0,774868.0,774868.0,64512.0,4748.0,0.9314467224949465,607744.0,0.0,4.256,2207.488000000001,0.0,0.0,0.0,387434.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,2210.0800000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,130560.0,0.0,261120.0,0,0.0,261120.0,261120.0,44381.0,20848.0,0.6803875576813994,2028416.0,1374880.0,15.2,2225.280000000001,0.0,0.0,0.0,130560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63388.0,42965.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,48192.0,0.0,96384.0,0,0.0,96384.0,96384.0,11169.0,21314.0,0.3438413939599175,2030464.0,1852928.0,13.216,2238.496000000001,0.0,0.0,0.0,48192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63452.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,51072.0,0.0,102144.0,0,0.0,102144.0,102144.0,12089.0,21302.0,0.36204366446048336,2024832.0,1854080.0,13.696,2252.192000000001,0.0,0.0,0.0,51072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63276.0,57940.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",378,51072.0,0.0,102144.0,0,0.0,102144.0,102144.0,12089.0,21180.0,0.36337130662178,2029568.0,1520096.0,13.92,2266.112000000001,0.0,0.0,0.0,51072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63424.0,47503.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",379,2471246.0,5019168.0,688284.0,0,0.0,5707452.0,5707452.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,66.112,2332.224000000001,613024.0,151936.0,2127104.0,344142.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,4.0,0.0,0.0,896.0,2.208,2334.432000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",381,10241.0,408386.0,20482.0,0,0.0,428868.0,428868.0,20477.0,10073.0,0.670278232405892,664608.0,612704.0,5.792,2340.224000000001,408386.0,0.0,0.0,10241.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20769.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",382,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,2392.0,0.0,607744.0,151648.0,3.296,2343.520000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,4739.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",383,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,2345.536000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",384,322944.0,0.0,645888.0,0,0.0,645888.0,645888.0,0.0,14244.0,0.0,1367424.0,55936.0,9.024,2354.560000000001,0.0,0.0,0.0,322944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,42732.0,1748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,19072.0,0.0,38144.0,0,0.0,38144.0,38144.0,0.0,3588.0,0.0,759680.0,0.0,3.712,2358.272000000001,0.0,0.0,0.0,19072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",386,2471248.0,5019168.0,688288.0,0,0.0,5707456.0,5707456.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,65.92,2424.192000000001,613024.0,151936.0,2127104.0,344144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",387,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.656,2430.848000000001,0.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2433.248000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.656,2439.904000000001,0.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.496,2442.400000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",391,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2445.024000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.392,2448.4160000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",393,30720.0,241939.0,61440.0,0,0.0,303379.0,303379.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.56,2454.9760000000006,241939.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.368,2457.3440000000005,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2459.7760000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",396,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2463.0400000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",397,1806336.0,2626304.0,1290240.0,0,0.0,3916544.0,3916544.0,0.0,4748.0,0.0,0.0,607744.0,4.16,2467.2000000000003,0.0,303872.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",398,915792.0,1525760.0,305824.0,0,0.0,1831584.0,1831584.0,0.0,3588.0,0.0,1215488.0,0.0,4.768,2471.9680000000003,0.0,0.0,762880.0,152912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",399,125632.0,0.0,251264.0,0,0.0,251264.0,251264.0,2803.0,1228.0,0.6953609526172165,608064.0,704.0,8.224,2480.1920000000005,0.0,0.0,0.0,125632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19002.0,22.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.528,2482.7200000000003,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,2484.7360000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",402,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,2486.784,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",403,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2489.408,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2491.8399999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",405,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.04,2494.8799999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",406,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,2498.1119999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",407,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2500.5119999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2502.9439999999995,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",409,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.424,2506.3679999999995,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2508.4159999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",411,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.848,2511.263999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2513.695999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",413,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,2516.095999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",414,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.56,2518.655999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",415,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,3.456,2522.111999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.816,2524.927999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",417,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.296,2528.223999999999,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",418,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.72,2530.9439999999986,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",419,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.752,2533.6959999999985,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.56,2536.2559999999985,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.88,2539.1359999999986,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",422,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,2541.5999999999985,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.88,2544.4799999999987,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",424,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,2546.9439999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,2549.4719999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",426,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2553.151999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",427,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2555.5519999999983,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2558.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,2561.023999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.784,2563.807999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617664.0,12096.0,7.392,2571.199999999998,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81802.0,378.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",432,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,2574.399999999998,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",433,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,2577.343999999998,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",434,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618048.0,11904.0,7.616,2584.9599999999978,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81814.0,372.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",435,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.296,2588.2559999999976,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",436,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.008,2591.2639999999974,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",437,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618048.0,12096.0,7.904,2599.1679999999974,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81814.0,378.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",438,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,2602.3999999999974,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",439,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2605.2479999999973,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2608.4159999999974,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,2611.4559999999974,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,2614.8799999999974,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2617.9519999999975,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2620.6079999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,2623.6159999999973,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,2626.623999999997,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2630.079999999997,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,2633.087999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",449,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2635.711999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,2638.3679999999968,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,2641.0239999999967,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",452,11808.0,1126958.0,0.0,0,0.0,1126958.0,1126958.0,6261.0,12.0,0.9980870396939263,15360.0,3072.0,20.32,2661.343999999997,954753.0,148589.0,11808.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",453,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.688,2668.031999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.752,2670.783999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,2673.3119999999967,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",456,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.904,2677.2159999999967,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",457,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2679.615999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",458,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2682.1439999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,2685.1519999999964,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",460,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2687.775999999996,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",461,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703552.0,12288.0,14.304,2702.0799999999963,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303236.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,2704.991999999996,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",463,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9698304.0,12288.0,14.4,2719.391999999996,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2722.047999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.712,2737.759999999996,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.752,2740.511999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,2743.039999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2746.7199999999957,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2749.1839999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2751.7439999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,2754.7519999999954,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",472,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2757.3439999999955,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",473,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12064.0,7.712,2765.0559999999955,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,377.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",474,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,2768.3199999999956,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",475,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2771.1679999999956,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",476,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2619040.0,12096.0,8.16,2779.3279999999954,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81845.0,378.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,2782.5279999999952,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",478,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2785.375999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",479,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12032.0,8.128,2793.5039999999954,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",480,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.328,2796.8319999999953,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",481,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,2799.647999999995,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2802.687999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,2805.823999999995,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2809.311999999995,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2812.479999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.72,2815.199999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,2818.2079999999946,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,2821.2479999999946,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,2824.7679999999946,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,2827.7759999999944,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.88,2830.6559999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",492,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,2833.3119999999944,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",493,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2835.9039999999945,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",494,12256.0,1128110.0,0.0,0,0.0,1128110.0,1128110.0,6243.0,12.0,0.9980815347721822,15360.0,3072.0,20.352,2856.2559999999944,954991.0,148607.0,12256.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",495,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.264,2863.5199999999945,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",496,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2866.1759999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2868.7679999999946,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",498,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.744,2872.5119999999947,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",499,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,2875.0719999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2877.6319999999946,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,2880.6079999999947,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2883.199999999995,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",503,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9704448.0,12288.0,13.792,2896.9919999999947,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303264.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,2899.9039999999945,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",505,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9706624.0,12288.0,13.824,2913.7279999999946,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303332.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",506,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2916.3519999999944,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",507,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.944,2931.2959999999944,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,2933.9839999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,2936.5439999999944,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",510,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.712,2940.2559999999944,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",511,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2942.687999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2945.2799999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,2948.2239999999942,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2950.847999999994,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",515,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2622208.0,12128.0,7.904,2958.751999999994,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81944.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,2961.951999999994,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",517,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2964.799999999994,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",518,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618240.0,12160.0,7.456,2972.255999999994,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81820.0,380.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",519,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,2975.487999999994,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",520,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,2978.335999999994,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",521,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12096.0,7.584,2985.9199999999937,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,378.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",522,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,2989.1199999999935,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",523,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,2992.0319999999933,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2995.0719999999933,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,2998.1119999999933,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3001.5679999999934,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3004.6079999999934,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3007.2639999999933,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",529,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3010.3039999999933,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.104,3013.407999999993,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3016.863999999993,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,3019.999999999993,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",533,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3022.623999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.624,3025.2479999999928,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",535,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.752,3027.9999999999927,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",536,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.16,3048.1599999999926,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.104,3055.2639999999924,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",538,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3057.887999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3060.447999999992,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",540,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3064.127999999992,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",541,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3066.527999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3069.183999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,3072.255999999992,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.688,3074.9439999999922,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",545,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9709440.0,12288.0,14.112,3089.0559999999923,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303420.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,3091.967999999992,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",547,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9704704.0,12288.0,13.856,3105.8239999999923,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303272.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",548,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3108.4159999999924,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",549,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.616,3124.0319999999924,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",550,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3126.655999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.624,3129.279999999992,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",552,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3132.959999999992,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",553,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3135.3919999999916,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3137.9519999999916,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,3140.9279999999917,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.752,3143.6799999999917,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",557,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12192.0,7.424,3151.1039999999916,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,381.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",558,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.296,3154.3999999999915,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",559,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,3157.3439999999914,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",560,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618048.0,12160.0,7.456,3164.7999999999915,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81814.0,380.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",561,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.36,3168.1599999999917,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",562,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.912,3171.0719999999915,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",563,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618112.0,12032.0,7.648,3178.7199999999916,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81816.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.392,3182.1119999999914,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",565,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3184.9599999999914,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3187.9999999999914,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,3191.007999999991,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",568,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,3194.495999999991,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3197.535999999991,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",570,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3200.127999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3203.167999999991,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,3206.303999999991,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3209.759999999991,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,3212.767999999991,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3215.3919999999907,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,3218.0479999999907,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",577,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.688,3220.735999999991,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",578,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.064,3240.7999999999906,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",579,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,3247.7759999999907,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3250.3999999999905,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3252.9599999999905,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3256.6399999999903,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3259.0399999999904,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3261.56799999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,3264.57599999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",586,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3267.23199999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",587,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700096.0,12288.0,14.624,3281.8559999999898,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303128.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,3284.7679999999896,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",589,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703296.0,12288.0,13.792,3298.5599999999895,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303228.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.752,3301.3119999999894,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",591,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.752,3316.0639999999894,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",592,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3318.6559999999895,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",593,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.656,3321.3119999999894,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",594,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.712,3325.0239999999894,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",595,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3327.5199999999895,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3330.1119999999896,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",597,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.104,3333.2159999999894,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3335.8399999999892,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",599,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12064.0,7.776,3343.615999999989,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,377.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",600,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,3346.879999999989,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",601,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3349.727999999989,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",602,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2620320.0,11936.0,8.032,3357.7599999999893,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81885.0,373.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",603,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,3361.0239999999894,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",604,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3363.8719999999894,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",605,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11936.0,7.552,3371.4239999999895,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,373.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",606,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.296,3374.7199999999893,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",607,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3377.5679999999893,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.232,3380.7999999999893,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,3383.807999999989,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",610,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,3387.327999999989,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.232,3390.559999999989,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3393.215999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3396.255999999989,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.104,3399.3599999999888,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",615,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3402.815999999989,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3405.855999999989,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",617,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3408.511999999989,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",618,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.72,3411.2319999999886,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.72,3413.9519999999884,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",620,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.096,3434.0479999999884,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",621,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.752,3440.7999999999884,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",622,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3443.423999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",623,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,3445.951999999988,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",624,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3449.631999999988,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",625,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3452.0959999999877,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,3454.591999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,3457.567999999988,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",628,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3460.159999999988,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",629,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703168.0,12288.0,14.016,3474.175999999988,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303224.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,3.104,3477.279999999988,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",631,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699584.0,12288.0,14.976,3492.255999999988,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303112.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3494.847999999988,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",633,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.88,3509.7279999999882,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",634,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3512.351999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3514.911999999988,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",636,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3518.591999999988,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",637,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3521.0239999999876,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",638,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3523.6479999999874,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,3526.5919999999874,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",640,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.688,3529.2799999999875,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",641,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2624576.0,12000.0,7.872,3537.1519999999873,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,82018.0,375.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",642,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,3540.3839999999873,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",643,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,3543.199999999987,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",644,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2620000.0,12192.0,7.648,3550.847999999987,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81875.0,381.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",645,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,3554.079999999987,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",646,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.976,3557.0559999999873,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2623456.0,12128.0,7.456,3564.5119999999874,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81983.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,3567.7119999999873,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",649,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,3.008,3570.719999999987,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",650,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3573.759999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,3576.799999999987,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,3580.319999999987,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,3583.391999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",654,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3586.047999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",655,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,3589.119999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,2.944,3592.063999999987,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3595.5199999999872,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,3598.5919999999874,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",659,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3601.2479999999873,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.624,3603.871999999987,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",661,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,3606.463999999987,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",662,12288.0,1128194.0,0.0,0,0.0,1128194.0,1128194.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.256,3626.719999999987,955008.0,148610.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",663,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.656,3633.375999999987,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",664,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3635.967999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,3638.559999999987,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",666,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,3642.175999999987,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",667,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3644.5759999999873,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3647.1359999999872,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.912,3650.047999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3652.671999999987,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",671,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700352.0,12288.0,13.92,3666.591999999987,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303136.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.88,3669.471999999987,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",673,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700864.0,12288.0,14.336,3683.807999999987,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303152.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",674,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3686.3679999999868,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",675,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.072,3701.439999999987,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",676,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3704.095999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",677,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,3706.687999999987,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",678,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3710.3679999999868,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",679,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3712.863999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3715.423999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,3718.495999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3721.087999999987,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",683,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12000.0,7.424,3728.511999999987,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,375.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",684,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.264,3731.775999999987,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",685,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.816,3734.591999999987,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",686,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617984.0,11936.0,7.68,3742.2719999999867,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81812.0,373.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",687,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.296,3745.5679999999866,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",688,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3748.4159999999865,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",689,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,11968.0,7.584,3755.9999999999864,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,374.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",690,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.168,3759.1679999999865,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",691,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.88,3762.0479999999866,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",692,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3765.0879999999866,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",693,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,3768.1279999999865,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,3771.6479999999865,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,3774.6559999999863,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",696,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,3777.3439999999864,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,3780.4159999999865,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",698,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,3783.4559999999865,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",699,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.552,3787.0079999999866,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,3790.0479999999866,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",701,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3792.7039999999865,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",702,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.72,3795.4239999999863,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",703,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.784,3798.2079999999864,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",704,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.032,3818.2399999999866,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",705,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.848,3825.0879999999866,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",706,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3827.7439999999865,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",707,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3830.3039999999864,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",708,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3833.9839999999863,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",709,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3836.3839999999864,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3839.0399999999863,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.104,3842.143999999986,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",712,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3844.767999999986,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",713,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9711744.0,12288.0,13.984,3858.751999999986,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303492.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,3.008,3861.7599999999857,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",715,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9698688.0,12288.0,14.624,3876.3839999999855,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303084.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",716,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3878.9759999999856,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",717,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.616,3894.5919999999855,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",718,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3897.2159999999853,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",719,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3899.7759999999853,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",720,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,3903.3919999999853,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",721,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3905.823999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3908.383999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,3911.327999999985,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3913.919999999985,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",725,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12128.0,7.456,3921.375999999985,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",726,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.36,3924.7359999999853,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",727,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,3927.6799999999853,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",728,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618240.0,12032.0,7.456,3935.1359999999854,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81820.0,376.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",729,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2,3938.3359999999852,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",730,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.848,3941.183999999985,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",731,617472.0,1207296.0,52224.0,0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2617344.0,12128.0,7.616,3948.799999999985,24576.0,0.0,591360.0,26112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,81792.0,379.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,768.0,2304.0,1536.0,0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.232,3952.031999999985,1536.0,768.0,0.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,48.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",733,25344.0,768.0,50688.0,0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.944,3954.975999999985,768.0,0.0,0.0,25344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",734,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,3957.983999999985,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,3961.023999999985,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,3964.5119999999847,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",737,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,3967.5199999999845,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",738,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3970.1439999999843,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",739,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,3973.151999999984,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,2.976,3976.1279999999842,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",741,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,3979.5839999999844,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,3982.687999999984,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",743,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3985.311999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",744,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,3987.903999999984,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.624,3990.527999999984,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",746,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.096,4010.623999999984,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",747,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,4017.503999999984,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",748,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,4020.159999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",749,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,4022.719999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",750,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.776,4026.4959999999837,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",751,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4028.895999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4031.4559999999838,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",753,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,4034.3999999999837,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",754,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.528,4036.9279999999835,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",755,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9714944.0,12288.0,14.048,4050.9759999999833,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303592.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.976,4053.9519999999834,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",757,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701376.0,12288.0,14.048,4067.999999999983,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",758,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,4070.5919999999833,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",759,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.88,4085.4719999999834,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",760,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.752,4088.2239999999833,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",761,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,4090.7839999999833,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",762,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.744,4094.5279999999834,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",763,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4096.959999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,4099.647999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",765,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,4102.591999999984,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",766,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,4105.183999999984,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",767,121548800.0,255100544.0,9723904.0,0,0.0,264824448.0,264824448.0,4861952.0,4178240.0,0.5378151260504201,481613824.0,574432.0,519.392,4624.575999999984,7140992.0,14585856.0,116686848.0,4861952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15050432.0,17951.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",768,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4626.623999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",769,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.528,4629.151999999984,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",770,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4631.5839999999835,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",771,0.0,152576.0,0.0,0,0.0,152576.0,152576.0,0.0,2392.0,0.0,607744.0,607744.0,3.424,4635.007999999983,0.0,152576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",772,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,4637.023999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",773,227968.0,0.0,455936.0,0,0.0,455936.0,455936.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.032,4641.055999999983,0.0,0.0,0.0,227968.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",774,128736.0,0.0,257472.0,0,0.0,257472.0,257472.0,9834.0,179547.0,0.05192706765726234,6418336.0,0.0,9.184,4650.239999999983,0.0,0.0,0.0,128736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",775,76335.0,0.0,152670.0,0,0.0,152670.0,152670.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.128,4654.367999999983,0.0,0.0,0.0,76335.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",776,157344.0,0.0,314688.0,0,0.0,314688.0,314688.0,9834.0,180441.0,0.051683090264091444,6418336.0,0.0,9.856,4664.223999999983,0.0,0.0,0.0,157344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",777,76034.0,0.0,152068.0,0,0.0,152068.0,152068.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,4.032,4668.255999999983,0.0,0.0,0.0,76034.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",778,147808.0,0.0,295616.0,0,0.0,295616.0,295616.0,9834.0,180143.0,0.05176416092474352,6418336.0,0.0,9.536,4677.791999999983,0.0,0.0,0.0,147808.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",779,76033.0,0.0,152066.0,0,0.0,152066.0,152066.0,2384.0,7132.0,0.2505254308532997,610432.0,38144.0,3.936,4681.727999999983,0.0,0.0,0.0,76033.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",780,147808.0,0.0,295616.0,0,0.0,295616.0,295616.0,9834.0,180143.0,0.05176416092474352,6418336.0,32.0,9.472,4691.1999999999825,0.0,0.0,0.0,147808.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,200573.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",781,703.0,0.0,1406.0,0,0.0,1406.0,1406.0,0.0,15.0,0.0,4800.0,608.0,3.104,4694.303999999983,0.0,0.0,0.0,703.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",782,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4696.351999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",783,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,19.0,0.9709923664122138,608.0,0.0,4.352,4700.703999999982,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",784,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4702.751999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",785,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,19.0,0.9709923664122138,608.0,0.0,4.544,4707.295999999982,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",786,190308.0,0.0,380616.0,0,0.0,380616.0,380616.0,27675.0,9600.0,0.7424547283702213,622464.0,2752.0,6.304,4713.599999999982,0.0,0.0,0.0,190308.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19452.0,86.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",787,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.888,4719.487999999982,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",788,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,14244.0,0.0,610432.0,37984.0,4.224,4723.711999999982,0.0,0.0,0.0,303872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19076.0,1187.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",789,19072.0,0.0,38144.0,0,0.0,38144.0,38144.0,0.0,3588.0,0.0,759680.0,0.0,3.872,4727.583999999983,0.0,0.0,0.0,19072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",790,608384.0,0.0,1216768.0,0,0.0,1216768.0,1216768.0,0.0,4748.0,0.0,0.0,1215488.0,3.104,4730.687999999983,0.0,0.0,0.0,608384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",791,387436.0,0.0,774872.0,0,0.0,774872.0,774872.0,64512.0,4748.0,0.9314467224949465,607744.0,0.0,4.32,4735.0079999999825,0.0,0.0,0.0,387436.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",792,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,4737.631999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",793,120768.0,0.0,241536.0,0,0.0,241536.0,241536.0,40653.0,20609.0,0.6635924390323529,1999360.0,1435648.0,15.424,4753.055999999982,0.0,0.0,0.0,120768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,62480.0,44864.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",794,48192.0,0.0,96384.0,0,0.0,96384.0,96384.0,11169.0,21304.0,0.34394727927816954,2033536.0,1852928.0,13.024,4766.079999999983,0.0,0.0,0.0,48192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63548.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",795,51072.0,0.0,102144.0,0,0.0,102144.0,102144.0,12089.0,21170.0,0.36348056165248505,2025472.0,1853312.0,13.664,4779.743999999982,0.0,0.0,0.0,51072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63296.0,57916.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,51072.0,0.0,102144.0,0,0.0,102144.0,102144.0,12089.0,21199.0,0.3631639029079548,2022400.0,1520160.0,13.696,4793.439999999982,0.0,0.0,0.0,51072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63200.0,47505.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",797,2471246.0,5019168.0,688284.0,0,0.0,5707452.0,5707452.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,66.112,4859.551999999982,613024.0,151936.0,2127104.0,344142.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",798,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,4.0,0.0,0.0,896.0,2.144,4861.695999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",799,10241.0,408538.0,20482.0,0,0.0,429020.0,429020.0,20477.0,10037.0,0.6710690175001639,663776.0,612704.0,5.888,4867.583999999983,408538.0,0.0,0.0,10241.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20743.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",800,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,2392.0,0.0,607744.0,151648.0,3.232,4870.8159999999825,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18992.0,4739.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",801,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,4872.863999999982,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",802,322944.0,0.0,645888.0,0,0.0,645888.0,645888.0,0.0,14244.0,0.0,1367424.0,54656.0,8.832,4881.695999999983,0.0,0.0,0.0,322944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,42732.0,1708.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",803,19072.0,0.0,38144.0,0,0.0,38144.0,38144.0,0.0,3588.0,0.0,759680.0,0.0,3.84,4885.535999999983,0.0,0.0,0.0,19072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,2471249.0,5019168.0,688290.0,0,0.0,5707458.0,5707458.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,66.272,4951.807999999983,613024.0,151936.0,2127104.0,344145.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",805,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.56,4958.367999999983,0.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,4960.767999999983,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",807,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.592,4967.359999999982,0.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",808,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,4969.823999999982,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",809,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,4972.351999999983,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",810,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,4975.583999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",811,30720.0,241939.0,61440.0,0,0.0,303379.0,303379.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,6.432,4982.015999999982,241939.0,0.0,0.0,30720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",812,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,4984.415999999982,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",813,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4986.847999999982,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",814,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.36,4990.207999999981,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",815,1806336.0,2626304.0,1290240.0,0,0.0,3916544.0,3916544.0,0.0,4748.0,0.0,0.0,607744.0,4.192,4994.399999999981,0.0,303872.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",816,915793.0,1525760.0,305826.0,0,0.0,1831586.0,1831586.0,0.0,3588.0,0.0,1215488.0,0.0,4.768,4999.1679999999815,0.0,0.0,762880.0,152913.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",817,125632.0,0.0,251264.0,0,0.0,251264.0,251264.0,2803.0,1228.0,0.6953609526172165,608064.0,800.0,8.16,5007.327999999981,0.0,0.0,0.0,125632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,19002.0,25.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",818,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.528,5009.855999999982,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",819,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,5011.903999999981,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",820,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,5013.919999999981,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",821,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,5016.447999999981,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",822,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,5018.943999999981,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",823,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,5022.015999999981,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",824,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.264,5025.279999999982,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",825,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,5027.679999999981,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
