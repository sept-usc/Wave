Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002016,0.002016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001856,0.003872,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.00272,0.006592000000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003744,0.010336000000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003168,0.013504000000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002496,0.016,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002048,0.018048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.0024,0.020448,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002464,0.022912000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003264,0.026176,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002816,0.028992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002816,0.031808,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.0032,0.035008000000000004,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002752,0.03776,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.002976,0.040736,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,0.002848,0.043584,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,13056.0,49152.0,0.004512,0.048096,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,408.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.051008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003904,0.054911999999999996,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.05782399999999999,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.002784,0.060607999999999995,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.00304,0.063648,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,0.003648,0.067296,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.00304,0.070336,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.003456,0.073792,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002848,0.07664,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,0.07952,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006016,0.08553599999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,0.08835199999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,0.09135999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,0.09471999999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,0.09811199999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45060480.0,49184.0,0.049728,0.14784,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1408140.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43460992.0,49280.0,0.051616,0.199456,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1358156.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45444224.0,49152.0,0.049856,0.24931199999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1420132.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003744,0.253056,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003648,0.256704,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,0.26095999999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,0.26448,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,0.26745599999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,0.270912,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003552,0.274464,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,0.278688,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,0.282112,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,0.28512,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038208,0.323328,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45187328.0,49312.0,0.048608,0.371936,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1412104.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003232,0.375168,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,0.377984,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00608,0.38406399999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,0.38678399999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.389696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003424,0.39311999999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,0.396512,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205111552.0,218144.0,0.174624,0.571136,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6409736.0,6817.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.00336,0.574496,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203685888.0,214880.0,0.175808,0.750304,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6365184.0,6715.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003168,0.7534719999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,180177536.0,49344.0,0.185024,0.9384959999999999,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5630548.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,0.9415359999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002848,0.9443839999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006112,0.9504959999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,0.9532159999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,0.9560959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,0.9594559999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,0.9629119999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43297408.0,49248.0,0.052384,1.015296,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1353044.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43415552.0,49152.0,0.051968,1.067264,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1356736.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44244224.0,49152.0,0.051648,1.118912,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1382632.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,1.1224319999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,1.1259199999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.00416,1.1300799999999998,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,1.1335359999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,1.1364479999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,1.1399679999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,1.1434559999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,1.1477119999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,1.1512319999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,1.1542079999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038144,1.1923519999999996,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43930368.0,49280.0,0.049344,1.2416959999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1372824.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,1.2446079999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002784,1.2473919999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,1.2533439999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,1.2560959999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,1.2589759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003456,1.2624319999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,1.2658879999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205719296.0,217024.0,0.175232,1.4411199999999995,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6428728.0,6782.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.00352,1.4446399999999995,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205217280.0,217088.0,0.176768,1.6214079999999995,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6413040.0,6784.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003264,1.6246719999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,187271168.0,49408.0,0.18176,1.8064319999999994,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5852224.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003072,1.8095039999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002944,1.8124479999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005984,1.8184319999999994,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,1.8211519999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,1.8240319999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003488,1.8275199999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003328,1.8308479999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45454080.0,49152.0,0.051104,1.8819519999999994,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1420440.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43788800.0,49216.0,0.051008,1.9329599999999993,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1368400.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43798400.0,49152.0,0.052128,1.9850879999999993,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1368700.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,1.9885119999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,1.9920319999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004128,1.9961599999999993,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003392,1.9995519999999993,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003104,2.0026559999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,2.0061439999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,2.0096639999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,2.0139199999999993,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,2.017343999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00288,2.0202239999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038272,2.0584959999999994,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43610112.0,49440.0,0.05024,2.1087359999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1362816.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,2.1116479999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,2.1144639999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006112,2.1205759999999994,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,2.1232959999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,2.126207999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003392,2.129599999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,2.132991999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204684928.0,216608.0,0.175552,2.308543999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6396404.0,6769.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003424,2.311967999999999,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202968704.0,215840.0,0.175328,2.487295999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6342772.0,6745.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003232,2.490527999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175676800.0,49376.0,0.192736,2.683263999999999,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5489900.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00288,2.686143999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,2.6889599999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006048,2.695007999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,2.6978239999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,2.7007039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,2.7040639999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003488,2.7075519999999993,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,42942464.0,49152.0,0.05488,2.762431999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1341952.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43957632.0,49248.0,0.049792,2.812223999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1373676.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44536448.0,49152.0,0.04976,2.861983999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1391764.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003552,2.865535999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,2.869023999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004288,2.873311999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,2.876831999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,2.8797439999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,2.8832639999999987,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,2.8867519999999987,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,2.890943999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003648,2.894591999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,2.897599999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038304,2.935903999999999,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43339392.0,49344.0,0.051264,2.987167999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1354356.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,2.990207999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002848,2.9930559999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006208,2.9992639999999993,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,3.0019839999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,3.004895999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00368,3.0085759999999993,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.00336,3.011935999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205392128.0,218176.0,0.176608,3.188543999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6418504.0,6818.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003392,3.1919359999999988,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204877056.0,219552.0,0.1744,3.3663359999999987,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6402408.0,6861.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.0032,3.3695359999999988,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,181714944.0,49440.0,0.184224,3.5537599999999987,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5678592.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,3.5566719999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,3.5594879999999987,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00592,3.565407999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,3.568191999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,3.571071999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003456,3.574527999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.00336,3.577887999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44730496.0,49216.0,0.049408,3.627295999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1397828.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45093248.0,49312.0,0.049248,3.676543999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1409164.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44389248.0,49152.0,0.051072,3.727615999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1387164.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,3.731039999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,3.7345599999999988,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,3.7387839999999986,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,3.7422719999999985,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,3.7451839999999983,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003552,3.7487359999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,3.7522559999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,3.756479999999998,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,3.759999999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,3.763039999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038112,3.801151999999998,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43593088.0,49408.0,0.050592,3.851743999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1362284.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,3.8546559999999976,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002976,3.8576319999999975,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006048,3.8636799999999973,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,3.8663999999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,3.869311999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003392,3.872703999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003424,3.876127999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204285440.0,218560.0,0.176576,4.052703999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6383920.0,6830.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.00352,4.056223999999997,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203622016.0,219872.0,0.176864,4.233087999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6363188.0,6871.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003296,4.236383999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175434240.0,49408.0,0.187552,4.423935999999997,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5482320.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,4.426943999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002912,4.429855999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00624,4.436095999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,4.438815999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00304,4.441855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003552,4.445407999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,4.448799999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44155520.0,49184.0,0.051136,4.499935999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1379860.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45389568.0,49184.0,0.048352,4.548287999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1418424.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44948480.0,49152.0,0.0504,4.5986879999999974,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1404640.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,4.602175999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,4.605663999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,4.609887999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,4.613375999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,4.616287999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003392,4.619679999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003584,4.623263999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,4.627455999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,4.630943999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,4.633855999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038304,4.672159999999997,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43526144.0,49184.0,0.05008,4.7222399999999976,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1360192.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00288,4.725119999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,4.727935999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005888,4.733823999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,4.736543999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,4.739455999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,4.742815999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.00336,4.7461759999999975,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206683008.0,219168.0,0.17488,4.921055999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6458844.0,6849.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003392,4.924447999999997,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203738880.0,215904.0,0.176352,5.100799999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6366840.0,6747.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003168,5.1039679999999965,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177367552.0,49312.0,0.187904,5.291871999999996,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5542736.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,5.294815999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,5.297631999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,5.303583999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,5.306271999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,5.3091199999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00352,5.3126399999999965,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003424,5.316063999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44079104.0,49248.0,0.05088,5.366943999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1377472.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44625024.0,49152.0,0.049184,5.416127999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1394532.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45106304.0,49184.0,0.050528,5.466655999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1409572.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,5.470175999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,5.473663999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,5.4778559999999965,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003808,5.481663999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,5.484607999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,5.488095999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00368,5.491775999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,5.495967999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,5.499487999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,5.502399999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038176,5.540575999999997,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43565568.0,49280.0,0.050592,5.591167999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1361424.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,5.594079999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002848,5.5969279999999975,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,5.602879999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,5.605599999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00304,5.608639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003616,5.612255999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,5.615711999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206797312.0,214528.0,0.175584,5.791295999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6462416.0,6704.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003456,5.794751999999997,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203437824.0,218304.0,0.174688,5.969439999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6357432.0,6822.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.0032,5.972639999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,186430464.0,49504.0,0.18208,6.154719999999997,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5825952.0,1547.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,6.157695999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,6.160575999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006016,6.166591999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,6.169343999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,6.172255999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003424,6.175679999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003424,6.179103999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45490688.0,49184.0,0.05008,6.229183999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1421584.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44866176.0,49152.0,0.048768,6.277951999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1402068.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45216128.0,49184.0,0.050944,6.328895999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1413004.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003616,6.332511999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003584,6.336095999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,6.3403519999999975,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003552,6.3439039999999975,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003328,6.347231999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,6.350751999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,6.354239999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,6.358431999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,6.361919999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,6.364831999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,0.038176,6.403007999999997,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,42868864.0,49376.0,0.05312,6.456127999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1339652.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,6.459103999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002944,6.462047999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006016,6.468063999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,6.4708479999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,6.473823999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003328,6.477151999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,6.480543999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202252800.0,216832.0,0.176672,6.657215999999997,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6320400.0,6776.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003392,6.660607999999997,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204813312.0,214944.0,0.174432,6.835039999999998,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6400416.0,6717.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003168,6.838207999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175972864.0,49408.0,0.193248,7.031455999999997,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5499152.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003168,7.034623999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,7.037503999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006272,7.043775999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002912,7.046687999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003072,7.049759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003616,7.053375999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.00336,7.056735999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,1901023232.0,4093763584.0,68067328.0,0,0.0,4161830912.0,4161830912.0,24993472.0,22182656.0,0.5297906602254429,2739927040.0,2858400.0,2.070176,9.126911999999997,126410752.0,233373696.0,1866989568.0,34033664.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85622720.0,89325.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002336,9.129247999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.00288,9.132127999999996,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002752,9.134879999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.005664,9.140543999999995,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002464,9.143007999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006144,9.149151999999996,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20613056.0,0.0,0.012416,9.161567999999995,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644158.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,289068.0,0.0,578136.0,0,0.0,578136.0,578136.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006144,9.167711999999996,0.0,0.0,0.0,289068.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,441728.0,0.0,883456.0,0,0.0,883456.0,883456.0,31416.0,460300.0,0.06389053844088864,20655296.0,0.0,0.012416,9.180127999999996,0.0,0.0,0.0,441728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645478.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243740.0,0.0,487480.0,0,0.0,487480.0,487480.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.005824,9.185951999999997,0.0,0.0,0.0,243740.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,441728.0,0.0,883456.0,0,0.0,883456.0,883456.0,31416.0,460300.0,0.06389053844088864,20620416.0,0.0,0.012704,9.198655999999996,0.0,0.0,0.0,441728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644388.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.00592,9.204575999999996,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20654400.0,128.0,0.01264,9.217215999999995,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645450.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.004096,9.221311999999996,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.0024,9.223711999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004896,9.228607999999996,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002368,9.230975999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004832,9.235807999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,165476.0,34560.0,0.8272310984022876,2473696.0,10208.0,0.008128,9.243935999999996,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,319.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006624,9.250559999999997,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006624,9.257183999999997,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,14208.0,0.007072,9.264255999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,444.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.007008,9.271263999999999,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388694.0,0.0,777388.0,0,0.0,777388.0,777388.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.006784,9.278047999999998,0.0,0.0,0.0,388694.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.002976,9.281023999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,489216.0,0.0,978432.0,0,0.0,978432.0,978432.0,166174.0,85680.0,0.6598029016811328,8515072.0,5577984.0,0.028416,9.309439999999999,0.0,0.0,0.0,489216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,266096.0,174312.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,97349.0,0.29026778358595245,8445440.0,7411328.0,0.023488,9.332927999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263920.0,231604.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,96205.0,0.2967213713951533,8431744.0,5616320.0,0.023296,9.356224,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263492.0,175510.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39186.0,95126.0,0.2917535290964322,8405376.0,7409792.0,0.023168,9.379392,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262668.0,231556.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.008896,9.388288,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.002912,9.3912,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,50088.0,0.4354500574829242,5963904.0,3839584.0,0.015104,9.406303999999999,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,186372.0,119987.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7334784.0,7292928.0,0.012192,9.418496,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229212.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066144,9.484639999999999,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.227712,9.712352,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.00544,9.717792,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002624,9.720416,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,226240.0,0.011648,9.732064,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,7070.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2048.0,0.00656,9.738624,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,64.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9884996.0,20076672.0,2753160.0,0,0.0,22829832.0,22829832.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066272,9.804896,2452096.0,607744.0,8508416.0,1376580.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008384,9.813279999999999,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002752,9.816031999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00816,9.824191999999998,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002816,9.827007999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.002912,9.829919999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003552,9.833471999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.008608,9.84208,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.00272,9.8448,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003776,9.848576,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.002688,9.851263999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003456,9.854719999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.00544,9.860159999999999,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649732.0,6082560.0,1216904.0,0,0.0,7299464.0,7299464.0,0.0,14280.0,0.0,4861952.0,93696.0,0.00928,9.869439999999999,0.0,0.0,3041280.0,608452.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,2928.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2656.0,0.00992,9.879359999999998,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,83.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.00304,9.882399999999999,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002336,9.884735999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002336,9.887071999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.00288,9.889951999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00272,9.892671999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003168,9.895839999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003488,9.899327999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002848,9.902175999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002816,9.904991999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,0.00384,9.908831999999999,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.003264,9.912095999999998,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.00272,9.914815999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,0.002752,9.917567999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,0.002816,9.920383999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.003008,9.923391999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,49920.0,49152.0,0.00656,9.929951999999997,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1560.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,0.002912,9.932863999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,0.003872,9.936735999999996,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002912,9.939647999999996,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.002688,9.942335999999996,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.002976,9.945311999999996,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,0.003744,9.949055999999995,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.003008,9.952063999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.003552,9.955615999999996,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.00288,9.958495999999995,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,9.961375999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006048,9.967423999999994,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,9.970143999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,9.973023999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003424,9.976447999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,9.979903999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43970560.0,49152.0,0.050304,10.030207999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1374080.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43714560.0,49184.0,0.050048,10.080255999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1366080.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,46084864.0,49152.0,0.049216,10.129471999999994,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1440152.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,10.132959999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,10.136447999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,10.140703999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003552,10.144255999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,10.147199999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,10.150655999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,10.154175999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.00416,10.158335999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,10.161791999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,10.164799999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003104,10.167903999999997,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003072,10.170975999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,192096.0,18039272.0,0.0,0,0.0,18039272.0,18039272.0,100158.0,192.0,0.9980866965620329,245760.0,49152.0,0.038688,10.209663999999997,15277731.0,2377349.0,192096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44031488.0,49376.0,0.049856,10.259519999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1375984.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003136,10.262655999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,10.265471999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,10.271423999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,10.274207999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00304,10.277247999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,10.280607999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003584,10.284191999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206078848.0,217920.0,0.176256,10.460447999999998,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6439964.0,6810.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003296,10.463743999999998,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202017792.0,216512.0,0.174912,10.638656,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6313056.0,6766.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003392,10.642047999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,187157632.0,49312.0,0.179616,10.821663999999998,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5848676.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,10.824639999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,10.827455999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005984,10.833439999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,10.836159999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,10.839007999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003584,10.842591999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.00336,10.845951999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45648128.0,49184.0,0.049536,10.895487999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1426504.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43379584.0,49184.0,0.05152,10.947007999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1355612.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45222528.0,49216.0,0.050176,10.997183999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1413204.0,1538.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003584,11.000767999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003552,11.00432,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,11.008512,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,11.011968,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,11.014975999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,11.018431999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,11.02192,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004384,11.026304,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003744,11.030047999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,11.032991999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,11.035999999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003264,11.039263999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,193440.0,18042766.0,0.0,0,0.0,18042766.0,18042766.0,100032.0,192.0,0.9980842911877394,245760.0,49152.0,0.038208,11.077471999999997,15278445.0,2377441.0,193440.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43214464.0,49408.0,0.051008,11.128479999999996,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1350452.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,11.131423999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,11.134239999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00608,11.140319999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,11.143039999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,11.145887999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003584,11.149471999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,11.152863999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202909696.0,218496.0,0.175616,11.328479999999995,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6340928.0,6828.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003328,11.331807999999995,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204857984.0,220832.0,0.176288,11.508095999999995,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6401812.0,6901.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.00336,11.511455999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,190809856.0,49248.0,0.178464,11.689919999999995,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5962808.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,11.692895999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,11.695711999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005984,11.701695999999995,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,11.704511999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,11.707391999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003488,11.710879999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003424,11.714303999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43827328.0,49152.0,0.050304,11.764607999999996,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1369604.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44962432.0,49248.0,0.048672,11.813279999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1405076.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44382336.0,49152.0,0.053376,11.866655999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1386948.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,11.870111999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003392,11.873503999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,11.877727999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00368,11.881407999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,11.884351999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,11.887871999999994,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,11.891359999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004256,11.895615999999995,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,11.899103999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,11.902015999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,11.905023999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.00304,11.908063999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,194272.0,18044948.0,0.0,0,0.0,18044948.0,18044948.0,99924.0,192.0,0.9980822246194414,245760.0,49152.0,0.038272,11.946335999999995,15278887.0,2377517.0,194272.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43503744.0,49216.0,0.049824,11.996159999999994,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1359492.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,11.999135999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,12.001951999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,12.007903999999995,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,12.010623999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,12.013503999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003456,12.016959999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003648,12.020607999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202272000.0,216512.0,0.175296,12.195903999999993,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6321000.0,6766.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003232,12.199135999999994,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202210944.0,215424.0,0.175392,12.374527999999994,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6319092.0,6732.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003168,12.377695999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177482624.0,49344.0,0.190784,12.568479999999996,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5546332.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,12.571455999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,12.574271999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006048,12.580319999999995,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,12.583071999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,12.585919999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003392,12.589311999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003424,12.592735999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44681984.0,49216.0,0.05072,12.643455999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1396312.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44716032.0,49184.0,0.049088,12.692543999999994,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1397376.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,46299904.0,49152.0,0.049696,12.742239999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1446872.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003584,12.745823999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003616,12.749439999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.00432,12.753759999999994,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,12.757247999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,12.760255999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003584,12.763839999999995,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,12.767327999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004288,12.771615999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,12.775135999999996,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,12.778111999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.00336,12.781471999999997,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,12.784479999999997,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,194272.0,18044948.0,0.0,0,0.0,18044948.0,18044948.0,99924.0,192.0,0.9980822246194414,245760.0,49152.0,0.038688,12.823167999999997,15278887.0,2377517.0,194272.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44572032.0,49312.0,0.047872,12.871039999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1392876.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003136,12.874175999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,12.877055999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006144,12.883199999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,12.886015999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,12.888895999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003328,12.892223999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,12.895615999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,201016704.0,217184.0,0.17568,13.071295999999995,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6281772.0,6787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003424,13.074719999999996,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202966400.0,216864.0,0.173984,13.248703999999996,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6342700.0,6777.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003264,13.251967999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,178457088.0,49248.0,0.184672,13.436639999999997,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5576784.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,13.439551999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,13.442367999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00592,13.448287999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,13.451007999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,13.453855999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003424,13.457279999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003584,13.460863999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45312256.0,49152.0,0.048704,13.509567999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1416008.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44358912.0,49152.0,0.04816,13.557727999999997,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1386216.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44917760.0,49152.0,0.051296,13.609023999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1403680.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,13.612479999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003456,13.615935999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004224,13.620159999999998,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,13.623615999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,13.626591999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003648,13.630239999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,13.633728,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,13.63792,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.00352,13.64144,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,13.644416,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,13.647423999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003072,13.650495999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,194272.0,18044948.0,0.0,0,0.0,18044948.0,18044948.0,99924.0,192.0,0.9980822246194414,245760.0,49152.0,0.03808,13.688576,15278887.0,2377517.0,194272.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44567680.0,49376.0,0.047968,13.736543999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1392740.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,13.739487999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,13.742367999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.005952,13.748319999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002848,13.751167999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,13.754079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003584,13.757663999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003552,13.761216,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206194304.0,219136.0,0.174464,13.93568,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6443572.0,6848.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003456,13.939136,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204410240.0,217728.0,0.177184,14.11632,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6387820.0,6804.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003232,14.119552,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175492096.0,49344.0,0.18272,14.302272,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5484128.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,14.305184,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002912,14.308096,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006144,14.314240000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,14.316992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,14.319872,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003392,14.323264,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003392,14.326656,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43598848.0,49152.0,0.052192,14.378848,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1362464.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43675520.0,49152.0,0.04992,14.428768,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1364860.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44910848.0,49152.0,0.050016,14.478784,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1403464.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003616,14.482399999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,14.485888,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,14.490079999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,14.493504,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.0032,14.496704,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003392,14.500096,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.00352,14.503616,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.00432,14.507935999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,14.511424,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002912,14.514336,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.00304,14.517376,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,14.520384,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,194272.0,18044948.0,0.0,0,0.0,18044948.0,18044948.0,99924.0,192.0,0.9980822246194414,245760.0,49152.0,0.038272,14.558656,15278887.0,2377517.0,194272.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43461376.0,49248.0,0.049472,14.608127999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1358168.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,14.611168,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002848,14.614016,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00608,14.620096,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,14.622816,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,14.625728,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003616,14.629344,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,14.6328,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203504896.0,213568.0,0.175552,14.808352,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6359528.0,6674.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.00336,14.811712,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203932288.0,214944.0,0.175808,14.98752,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6372884.0,6717.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003296,14.990816,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175763968.0,49408.0,0.189088,15.179904,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5492624.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003104,15.183008000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,15.185824,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00624,15.192064,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,15.194784,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,15.197728,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003392,15.20112,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003552,15.204672,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,43640832.0,49152.0,0.051296,15.255968000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1363776.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44322944.0,49184.0,0.049024,15.304992,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1385092.0,1537.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44232320.0,49184.0,0.050304,15.355296000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1382260.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003456,15.358752,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003456,15.362208,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,15.3664,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,15.369888000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003104,15.372992000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,15.376416000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,15.379904000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004192,15.384096000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,15.387520000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,15.390560000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003136,15.393696000000004,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003136,15.396832000000003,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,194272.0,18044948.0,0.0,0,0.0,18044948.0,18044948.0,99924.0,192.0,0.9980822246194414,245760.0,49152.0,0.03856,15.435392000000004,15278887.0,2377517.0,194272.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44159360.0,49216.0,0.050016,15.485408000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1379980.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003136,15.488544000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,15.491424000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006176,15.497600000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,15.500352000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,15.503232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003552,15.506784000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003552,15.510336000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205179008.0,218880.0,0.175648,15.685984000000003,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6411844.0,6840.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003296,15.689280000000004,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203678336.0,218720.0,0.17584,15.865120000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6364948.0,6835.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003424,15.868544000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,185432064.0,49312.0,0.178656,16.047200000000004,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5794752.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002976,16.050176000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.00288,16.053056000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006176,16.059232000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,16.061952000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,16.064864000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.003744,16.068608000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003456,16.072064000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,45035776.0,49152.0,0.050048,16.122112000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1407368.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44600320.0,49152.0,0.048352,16.170464000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1393760.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44504832.0,49184.0,0.049504,16.219968000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1390776.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003424,16.223392000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003456,16.226848000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.004096,16.230944000000004,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,16.234432000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00304,16.237472000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003584,16.241056000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,0.003488,16.244544000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,0.00432,16.248864000000005,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,0.003488,16.252352000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.002944,16.255296000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.003008,16.258304000000006,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,0.00336,16.261664000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,0.038272,16.299936000000006,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43126528.0,49344.0,0.0512,16.351136000000007,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1347704.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.003008,16.35414400000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,16.356960000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.006016,16.362976000000007,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,16.365696000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,16.368608000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00368,16.372288000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003584,16.375872000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203252096.0,219232.0,0.17552,16.551392000000003,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6351628.0,6851.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,0.003424,16.554816000000002,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203036928.0,215968.0,0.173856,16.728672000000003,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6344904.0,6749.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,0.003296,16.731968000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,181417728.0,49280.0,0.183872,16.915840000000003,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5669304.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,0.00288,16.918720000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,0.002816,16.921536000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,0.00592,16.927456000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,16.93024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,16.933248000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,0.00336,16.936608000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,0.003552,16.940160000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,1901023232.0,4093763584.0,68067328.0,0,0.0,4161830912.0,4161830912.0,24993472.0,22182656.0,0.5297906602254429,2743155200.0,2878176.0,2.07264,19.012800000000002,126410752.0,233373696.0,1866989568.0,34033664.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85723600.0,89943.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002272,19.015072000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.002944,19.018016000000003,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00272,19.020736000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.0056,19.026336000000004,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002368,19.028704000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006176,19.034880000000005,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20609472.0,0.0,0.01232,19.047200000000004,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644046.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,288730.0,0.0,577460.0,0,0.0,577460.0,577460.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.00624,19.053440000000002,0.0,0.0,0.0,288730.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,441728.0,0.0,883456.0,0,0.0,883456.0,883456.0,31416.0,460300.0,0.06389053844088864,20690592.0,0.0,0.01264,19.066080000000003,0.0,0.0,0.0,441728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646581.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243732.0,0.0,487464.0,0,0.0,487464.0,487464.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006048,19.072128000000003,0.0,0.0,0.0,243732.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,441728.0,0.0,883456.0,0,0.0,883456.0,883456.0,31416.0,460300.0,0.06389053844088864,20624064.0,0.0,0.012576,19.084704000000002,0.0,0.0,0.0,441728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644502.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006368,19.091072,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,456960.0,0.0,913920.0,0,0.0,913920.0,913920.0,31416.0,460776.0,0.06382874975619271,20690240.0,128.0,0.012288,19.103360000000002,0.0,0.0,0.0,456960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646570.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.003936,19.107296,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002336,19.109632,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004864,19.114496000000003,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002432,19.116928,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004928,19.121856,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,150265.0,34558.0,0.8130211066804456,2473696.0,10624.0,0.008992,19.130848,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,332.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006624,19.137472,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006912,19.144384,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,4096.0,0.007136,19.151519999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,128.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.006976,19.158496,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388706.0,0.0,777412.0,0,0.0,777412.0,777412.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.006784,19.16528,0.0,0.0,0.0,388706.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.002848,19.168128,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,506496.0,0.0,1012992.0,0,0.0,1012992.0,1012992.0,173194.0,83126.0,0.6756944444444445,8355200.0,5617280.0,0.027936,19.196064,0.0,0.0,0.0,506496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261100.0,175540.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,41218.0,98693.0,0.294601568139746,8403072.0,5436096.0,0.023808,19.219872,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262596.0,169878.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,94791.0,0.2998205065703459,8418560.0,5613376.0,0.023424,19.243295999999997,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263080.0,175418.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39186.0,93091.0,0.29624197706328387,8440576.0,7410304.0,0.0232,19.266495999999997,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263768.0,231572.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.008896,19.275391999999997,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.002912,19.278303999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,50176.0,0.4350185789888526,5927040.0,3840192.0,0.015296,19.293599999999994,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185220.0,120006.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7332352.0,7292928.0,0.012224,19.305823999999994,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229136.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.065856,19.371679999999994,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.227968,19.599647999999995,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.005792,19.605439999999994,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002624,19.608063999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,222432.0,0.011584,19.619647999999994,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6951.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,7552.0,0.007008,19.626655999999993,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,236.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884998.0,20076672.0,2753164.0,0,0.0,22829836.0,22829836.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.06624,19.692895999999994,2452096.0,607744.0,8508416.0,1376582.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00864,19.701535999999994,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002816,19.704351999999993,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008416,19.712767999999993,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002848,19.715615999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.002848,19.718463999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003584,19.722047999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.008576,19.730623999999995,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.00272,19.733343999999995,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003712,19.737055999999995,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.00288,19.739935999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003488,19.743423999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.005568,19.748991999999998,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649734.0,6082560.0,1216908.0,0,0.0,7299468.0,7299468.0,0.0,14280.0,0.0,4861952.0,109056.0,0.009344,19.758335999999996,0.0,0.0,3041280.0,608454.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,3408.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2784.0,0.00992,19.768255999999997,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,87.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.003072,19.771327999999997,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002368,19.773695999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002464,19.776159999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.002816,19.778975999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00272,19.781695999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003168,19.784863999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00352,19.788383999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.00272,19.791103999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
