Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.24,5.5040000000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.36,8.864,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.784,11.648,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.048,13.696,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,15.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,17.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.176,19.648000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.848,22.496000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,25.056,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,27.552,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,3.136,30.688,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,33.12,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.528,35.647999999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.56,38.208,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,3264.0,6144.0,3.776,41.983999999999995,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,44.736,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.488,48.224,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,518.0,0.0,1036.0,0,0.0,1036.0,1036.0,0.0,2.0,0.0,32.0,32.0,2.72,50.943999999999996,0.0,0.0,0.0,518.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.104,54.047999999999995,0.0,256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,2.496,56.544,0.0,0.0,0.0,320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,2816.0,4608.0,1536.0,0,0.0,6144.0,6144.0,0.0,16.0,0.0,1024.0,1024.0,3.168,59.711999999999996,0.0,512.0,2048.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.56,62.272,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,2688.0,4608.0,1280.0,0,0.0,5888.0,5888.0,0.0,16.0,0.0,1024.0,1024.0,3.072,65.344,0.0,512.0,2048.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.464,67.80799999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,70.39999999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,74.24,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,77.056,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,79.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,82.72,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,85.76,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.064,93.82400000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.648,101.47200000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2879104.0,6144.0,8.0,109.47200000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89972.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,112.64000000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.2,115.84000000000002,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,119.45600000000002,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,122.59200000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,125.24800000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,128.35200000000003,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.232,131.58400000000003,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,135.20000000000005,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,138.36800000000005,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,140.92800000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.192,161.12000000000006,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876672.0,6144.0,7.648,168.76800000000006,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89896.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,171.32800000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,173.85600000000005,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,177.69600000000005,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,180.12800000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,182.88000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,185.95200000000006,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,189.02400000000006,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10034560.0,24576.0,15.136,204.16000000000005,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313580.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.072,207.23200000000006,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10092800.0,24576.0,15.648,222.88000000000005,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315400.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,225.47200000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505024.0,6144.0,20.96,246.43200000000007,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359532.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,248.99200000000008,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.624,251.61600000000007,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,255.36000000000007,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,257.76000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,260.32000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,263.36000000000007,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,266.4320000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878720.0,6144.0,8.16,274.5920000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.776,282.3680000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.128,290.4960000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,293.7600000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,296.8000000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,300.4160000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,303.6800000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,306.40000000000015,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,309.56800000000015,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.104,312.67200000000014,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,316.32000000000016,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,319.42400000000015,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,322.08000000000015,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.448,342.52800000000013,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875904.0,6144.0,7.648,350.17600000000016,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89872.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,352.83200000000016,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,355.3600000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,359.1360000000002,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,361.5360000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,364.1920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,2.976,367.1680000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,370.2080000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10102144.0,24576.0,14.752,384.9600000000002,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315692.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.944,387.9040000000002,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10045696.0,24576.0,15.424,403.3280000000002,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313928.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,405.8880000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11510912.0,6144.0,20.832,426.7200000000002,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359716.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,429.2800000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,431.8080000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.904,435.7120000000002,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,438.1120000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,440.7360000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,443.77600000000024,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,446.91200000000026,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878592.0,6144.0,8.32,455.23200000000026,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89956.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.936,463.16800000000023,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878976.0,6144.0,8.064,471.23200000000026,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89968.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,474.33600000000024,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,477.37600000000026,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,480.99200000000025,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,484.06400000000025,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,486.62400000000025,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,489.72800000000024,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,492.7360000000002,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,496.38400000000024,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,499.52000000000027,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,502.2400000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.096,522.3360000000002,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876032.0,6144.0,7.456,529.7920000000003,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89876.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,532.4480000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,534.9440000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,538.8160000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,541.3440000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,543.9040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,546.9760000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,550.0480000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10056320.0,24576.0,14.944,564.9920000000001,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314260.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,567.9040000000001,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10055424.0,24576.0,14.528,582.4320000000001,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314232.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,585.0880000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11504256.0,6144.0,21.568,606.6560000000001,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359508.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,609.1840000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,611.7120000000001,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,615.4560000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,617.9200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,620.5120000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,623.5840000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,626.6560000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.84,634.4960000000002,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.584,642.0800000000002,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.064,650.1440000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,653.2800000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,656.2880000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,659.9360000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,663.2000000000002,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,665.7600000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,668.9280000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,671.9680000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,675.6160000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,678.7200000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,681.2800000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,701.4080000000001,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875776.0,6144.0,7.424,708.8320000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89868.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,711.488,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,714.08,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,717.856,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,720.256,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,722.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.168,725.952,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,729.024,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9962368.0,24576.0,16.544,745.568,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,311324.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,748.448,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10149760.0,24576.0,14.88,763.328,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,317180.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,765.92,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11506688.0,6144.0,21.024,786.944,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359584.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,789.472,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,791.968,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,795.712,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,798.08,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,800.6080000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,803.7120000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.232,806.9440000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.68,814.624,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.584,822.208,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2879104.0,6144.0,7.712,829.92,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89972.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.328,833.2479999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,836.256,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.744,840.0,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,843.104,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,845.7280000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,848.864,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,851.8720000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,855.488,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,858.72,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,861.248,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,881.3760000000001,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876160.0,6144.0,7.872,889.248,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89880.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,891.808,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,894.3679999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,898.112,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,900.48,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,903.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.168,906.176,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,909.216,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10082304.0,24576.0,15.552,924.768,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315072.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.04,927.808,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10094592.0,24576.0,14.656,942.4639999999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315456.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,945.0559999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11510528.0,6144.0,21.312,966.3679999999999,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359704.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,968.9599999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.656,971.6159999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,975.3919999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,977.8239999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,980.3839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,983.5199999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,986.5599999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.584,994.1439999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.68,1001.8239999999996,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.84,1009.6639999999996,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,1012.8959999999996,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1015.9359999999996,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.68,1019.6159999999995,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,1022.8479999999995,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,1025.5039999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1028.6399999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1031.6799999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1035.2959999999994,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1038.3999999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1040.9599999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,1061.0879999999993,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,7.904,1068.9919999999993,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,1071.4879999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,1074.0159999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,4.032,1078.0479999999993,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.624,1080.6719999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1083.1999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,1086.2399999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.168,1089.4079999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10016000.0,24576.0,15.392,1104.7999999999993,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313000.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,1107.6799999999994,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10040960.0,24576.0,15.488,1123.1679999999994,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313780.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1125.7599999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11502464.0,6144.0,20.992,1146.7519999999995,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359452.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1149.3439999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,1151.9359999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.968,1155.9039999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1158.3039999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1160.8319999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,1163.9679999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1167.0079999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.744,1174.7519999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.904,1182.6559999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.616,1190.2719999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1193.3759999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.104,1196.4799999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1200.0959999999998,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,1203.2639999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,1205.9199999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1209.0239999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.104,1212.1279999999997,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,1215.7759999999996,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1218.8799999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1221.4719999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,1241.5999999999997,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2878592.0,6144.0,7.68,1249.2799999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89956.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1251.8399999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,1254.4319999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,1258.2399999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1260.6399999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1263.168,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,1266.2399999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1269.2799999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9985280.0,24576.0,16.224,1285.5039999999997,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312040.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,1288.3839999999998,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10109184.0,24576.0,15.52,1303.9039999999998,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315912.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,1306.4639999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505280.0,6144.0,21.12,1327.5839999999996,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359540.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,1330.1119999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,1332.6399999999996,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,1336.3519999999996,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1338.7199999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1341.3759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,1344.5119999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,1347.5839999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.128,1355.7119999999993,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.224,1363.9359999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.936,1371.8719999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1375.0079999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1378.047999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,1381.695999999999,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.296,1384.991999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1387.5839999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1390.7199999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1393.759999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1397.375999999999,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1400.511999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.784,1403.2959999999991,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.096,1423.3919999999991,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.264,1430.655999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1433.215999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,1435.743999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,1439.519999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1441.9199999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1444.4479999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,1447.4559999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.2,1450.6559999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9998208.0,24576.0,15.904,1466.5599999999993,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312444.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.2,1469.7599999999993,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10100608.0,24576.0,15.232,1484.9919999999993,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315644.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1487.6159999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505920.0,6144.0,20.928,1508.5439999999994,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359560.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,1511.0719999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.656,1513.7279999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,1517.5359999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.336,1519.8719999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1522.4319999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,1525.4719999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1528.5119999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,245528576.0,515366912.0,24309760.0,0,0.0,539676672.0,539676672.0,5697600.0,4710016.0,0.5474452554744526,547879424.0,1432736.0,517.984,2046.4959999999992,19447808.0,29171712.0,233373696.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,17121232.0,44773.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2048.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.496,2051.0079999999994,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2053.5999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,304128.0,0.0,0,0.0,304128.0,304128.0,0.0,4784.0,0.0,1215488.0,1215488.0,3.872,2057.4719999999993,0.0,304128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2059.4879999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,455936.0,0.0,911872.0,0,0.0,911872.0,911872.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.416,2063.9039999999995,0.0,0.0,0.0,455936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,257472.0,0.0,514944.0,0,0.0,514944.0,514944.0,19668.0,359094.0,0.05192706765726234,12846400.0,0.0,10.464,2074.3679999999995,0.0,0.0,0.0,257472.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,401450.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,152684.0,0.0,305368.0,0,0.0,305368.0,305368.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.352,2078.7199999999993,0.0,0.0,0.0,152684.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,314688.0,0.0,629376.0,0,0.0,629376.0,629376.0,19668.0,360882.0,0.051683090264091444,12888544.0,0.0,10.24,2088.959999999999,0.0,0.0,0.0,314688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,402767.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,152080.0,0.0,304160.0,0,0.0,304160.0,304160.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.352,2093.311999999999,0.0,0.0,0.0,152080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,19668.0,360584.0,0.051723593827251405,12882816.0,0.0,10.88,2104.191999999999,0.0,0.0,0.0,305152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,402588.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,152066.0,0.0,304132.0,0,0.0,304132.0,304132.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.416,2108.6079999999993,0.0,0.0,0.0,152066.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,257472.0,0.0,514944.0,0,0.0,514944.0,514944.0,19668.0,359094.0,0.05192706765726234,12846656.0,64.0,10.208,2118.8159999999993,0.0,0.0,0.0,257472.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,401458.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1066.0,0.0,2132.0,0,0.0,2132.0,2132.0,0.0,30.0,0.0,9568.0,1216.0,3.52,2122.3359999999993,0.0,0.0,0.0,1066.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2124.4159999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,29.0,0.956390977443609,1216.0,0.0,4.512,2128.9279999999994,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,2131.071999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,29.0,0.956390977443609,1216.0,0.0,4.544,2135.615999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,380616.0,0.0,761232.0,0,0.0,761232.0,761232.0,74456.0,19200.0,0.7949944477662937,1242240.0,5056.0,6.4,2142.015999999999,0.0,0.0,0.0,380616.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38820.0,158.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.272,2148.287999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,1220864.0,75968.0,4.384,2152.671999999999,0.0,0.0,0.0,607744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38152.0,2374.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,38016.0,0.0,76032.0,0,0.0,76032.0,76032.0,0.0,7176.0,0.0,1519360.0,512.0,5.568,2158.2399999999993,0.0,0.0,0.0,38016.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,47480.0,16.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,911872.0,0.0,1823744.0,0,0.0,1823744.0,1823744.0,0.0,9496.0,0.0,0.0,2430976.0,4.352,2162.591999999999,0.0,0.0,0.0,911872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,387794.0,0.0,775588.0,0,0.0,775588.0,775588.0,64512.0,9496.0,0.8716895470759918,1215488.0,0.0,4.96,2167.551999999999,0.0,0.0,0.0,387794.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,2170.1439999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,249600.0,0.0,499200.0,0,0.0,499200.0,499200.0,84881.0,41952.0,0.6692343475278516,4192640.0,2785216.0,16.704,2186.8479999999995,0.0,0.0,0.0,249600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131020.0,87038.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,91776.0,0.0,183552.0,0,0.0,183552.0,183552.0,20605.0,44328.0,0.31732709100149387,4207616.0,3704832.0,14.368,2201.2159999999994,0.0,0.0,0.0,91776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131488.0,115776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,94080.0,0.0,188160.0,0,0.0,188160.0,188160.0,21701.0,44005.0,0.33027425197090066,4203008.0,3705472.0,15.904,2217.1199999999994,0.0,0.0,0.0,94080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131344.0,115796.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,94080.0,0.0,188160.0,0,0.0,188160.0,188160.0,21701.0,44225.0,0.3291721020538179,4198272.0,3291776.0,15.712,2232.8319999999994,0.0,0.0,0.0,94080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131196.0,102868.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,9496.0,0.49767245027507406,2430976.0,0.0,5.792,2238.6239999999993,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,2241.247999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,48053.0,0.0,96106.0,0,0.0,96106.0,96106.0,19325.0,23933.0,0.44673817559757734,2926592.0,2077856.0,10.048,2251.295999999999,0.0,0.0,0.0,48053.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,91456.0,64933.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,911872.0,0.0,1823744.0,0,0.0,1823744.0,1823744.0,0.0,37984.0,0.0,3666368.0,3646464.0,7.808,2259.103999999999,0.0,0.0,0.0,911872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,114574.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,4942492.0,10038336.0,1376568.0,0,0.0,11414904.0,11414904.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,66.016,2325.119999999999,1226048.0,303872.0,4254208.0,688284.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,308224.0,1526058.0,616448.0,0,0.0,2142506.0,2142506.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,227.616,2552.735999999999,1526058.0,0.0,0.0,308224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,4784.0,0.0,1215488.0,303296.0,4.032,2556.767999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.144,2558.911999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,911616.0,0.0,1823232.0,0,0.0,1823232.0,1823232.0,0.0,28488.0,0.0,2734848.0,108448.0,9.408,2568.319999999999,0.0,0.0,0.0,911616.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85464.0,3389.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,38016.0,0.0,76032.0,0,0.0,76032.0,76032.0,0.0,7176.0,0.0,1519360.0,0.0,5.44,2573.759999999999,0.0,0.0,0.0,38016.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,4942496.0,10038336.0,1376576.0,0,0.0,11414912.0,11414912.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,65.76,2639.519999999999,1226048.0,303872.0,4254208.0,688288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,59904.0,0.0,119808.0,0,0.0,119808.0,119808.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.88,2646.399999999999,0.0,0.0,0.0,59904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2648.7999999999993,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,59904.0,0.0,119808.0,0,0.0,119808.0,119808.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.944,2655.7439999999992,0.0,0.0,0.0,59904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2658.1439999999993,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,2660.7359999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,2664.0639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,100352.0,492838.0,200704.0,0,0.0,693542.0,693542.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,6.656,2670.7199999999993,492838.0,0.0,0.0,100352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.432,2673.151999999999,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.264,2676.4159999999993,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,2678.879999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2682.1439999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,1852160.0,2930176.0,1381888.0,0,0.0,4312064.0,4312064.0,0.0,9496.0,0.0,0.0,1215488.0,4.192,2686.3359999999993,0.0,607744.0,1161216.0,690944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,1825056.0,3041280.0,608832.0,0,0.0,3650112.0,3650112.0,0.0,7176.0,0.0,2430976.0,0.0,6.56,2692.8959999999993,0.0,0.0,1520640.0,304416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,270720.0,0.0,541440.0,0,0.0,541440.0,541440.0,6726.0,2456.0,0.7325201481158788,1216128.0,1312.0,8.672,2701.5679999999993,0.0,0.0,0.0,270720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38004.0,41.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.528,2704.095999999999,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.08,2706.175999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,2708.223999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.528,2710.7519999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.496,2713.2479999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.104,2716.3519999999985,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.2,2719.5519999999983,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2721.9519999999984,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2724.383999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,3.0,0.0,64.0,32.0,3.264,2727.6479999999983,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.912,2730.559999999998,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,2733.023999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,2735.423999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.464,2737.887999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.528,2740.415999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.128,2744.543999999998,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,2747.295999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.328,2750.623999999998,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,518.0,0.0,1036.0,0,0.0,1036.0,1036.0,0.0,2.0,0.0,32.0,32.0,2.752,2753.375999999998,0.0,0.0,0.0,518.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,2.624,2755.9999999999977,0.0,256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,2.496,2758.495999999998,0.0,0.0,0.0,320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,2816.0,4616.0,1536.0,0,0.0,6152.0,6152.0,0.0,16.0,0.0,1024.0,1024.0,3.008,2761.5039999999976,8.0,512.0,2048.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.528,2764.0319999999974,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,2688.0,4608.0,1280.0,0,0.0,5888.0,5888.0,0.0,16.0,0.0,1024.0,1024.0,3.04,2767.0719999999974,0.0,512.0,2048.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.496,2769.5679999999975,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2772.0959999999973,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.968,2776.063999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2778.463999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2781.0559999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,2784.063999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.008,2787.071999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.064,2795.135999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.936,2803.071999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878976.0,6144.0,8.032,2811.103999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89968.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,2814.207999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2817.247999999997,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,2820.863999999997,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,2824.095999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2826.6239999999966,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,2829.8879999999967,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,2832.8959999999965,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.68,2836.5759999999964,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,2839.8079999999964,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2842.335999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.816,2845.151999999996,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.528,2847.6799999999957,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,24384.0,2255880.0,0.0,0,0.0,2255880.0,2255880.0,12486.0,24.0,0.9980815347721822,30720.0,6144.0,20.352,2868.0319999999956,1909914.0,297198.0,24384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876800.0,6144.0,7.488,2875.5199999999954,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89900.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2878.047999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.752,2880.799999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2884.5439999999953,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2886.9439999999954,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2889.5359999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,2892.5759999999955,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,2895.6159999999954,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10127872.0,24576.0,14.72,2910.3359999999952,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,316496.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.944,2913.279999999995,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10011136.0,24608.0,15.776,2929.055999999995,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312848.0,769.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,2931.711999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505664.0,6144.0,21.024,2952.735999999995,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359552.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,2955.391999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,2957.983999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2961.727999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,2964.223999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2966.783999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,2969.887999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,2972.959999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.968,2980.927999999995,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.904,2988.831999999995,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2879488.0,6144.0,7.776,2996.6079999999947,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89984.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2999.7439999999947,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,3002.7519999999945,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,3006.3359999999943,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,3009.5039999999944,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3012.0319999999942,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,3015.263999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3018.4319999999943,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,3022.015999999994,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3025.151999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3027.7439999999942,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3030.303999999994,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3032.863999999994,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,24544.0,2256300.0,0.0,0,0.0,2256300.0,2256300.0,12483.0,24.0,0.998081074598225,30720.0,6144.0,20.192,3053.055999999994,1909999.0,297213.0,24544.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.328,3060.383999999994,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3063.007999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,3065.599999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,3069.407999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3071.871999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3074.3999999999937,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,3077.4399999999937,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.104,3080.5439999999935,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10033024.0,24576.0,15.584,3096.1279999999933,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313532.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,3099.0079999999934,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9976192.0,24576.0,16.032,3115.0399999999936,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,311756.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3117.6639999999934,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505664.0,6144.0,20.896,3138.5599999999936,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359552.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3141.1519999999937,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.72,3143.8719999999935,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,3147.6799999999935,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3150.0799999999936,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3152.6399999999935,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,3155.7759999999935,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.168,3158.9439999999936,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.904,3166.8479999999936,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.872,3174.7199999999934,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878592.0,6144.0,7.744,3182.4639999999936,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89956.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.296,3185.7599999999934,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,3188.7999999999934,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,3192.383999999993,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,3195.615999999993,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3198.175999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3201.311999999993,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,3204.319999999993,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.712,3208.031999999993,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3211.167999999993,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3213.6959999999926,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3216.2559999999926,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3218.8479999999927,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,24544.0,2256300.0,0.0,0,0.0,2256300.0,2256300.0,12483.0,24.0,0.998081074598225,30720.0,6144.0,20.256,3239.1039999999925,1909999.0,297213.0,24544.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875904.0,6144.0,7.808,3246.9119999999925,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89872.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3249.5359999999923,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,3252.0959999999923,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3255.871999999992,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3258.271999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3260.831999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,3263.9039999999923,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.104,3267.007999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10026240.0,24576.0,15.328,3282.335999999992,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313320.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,3285.215999999992,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10024832.0,24576.0,14.976,3300.1919999999923,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313276.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3302.7839999999924,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11504000.0,6144.0,21.152,3323.9359999999924,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359500.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,3326.5919999999924,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,3329.0879999999925,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,3332.7999999999925,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3335.2319999999922,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,3337.951999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,3340.959999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.104,3344.0639999999917,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.808,3351.8719999999917,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.712,3359.5839999999916,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.84,3367.423999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,3370.6239999999916,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,2.976,3373.5999999999917,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.712,3377.3119999999917,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,3380.5439999999917,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3383.1679999999915,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,3386.3359999999916,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3389.5039999999917,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,3393.0879999999916,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,3396.2559999999917,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3398.8479999999918,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.528,3401.3759999999916,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3403.9359999999915,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,24544.0,2256300.0,0.0,0,0.0,2256300.0,2256300.0,12483.0,24.0,0.998081074598225,30720.0,6144.0,20.32,3424.2559999999917,1909999.0,297213.0,24544.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.488,3431.7439999999915,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.752,3434.4959999999915,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,3437.0239999999912,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,3440.7359999999912,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3443.1359999999913,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3445.7919999999913,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,3448.9279999999912,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3451.9999999999914,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10112896.0,24576.0,14.656,3466.6559999999913,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,316028.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,3469.567999999991,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10017664.0,24576.0,15.296,3484.863999999991,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313052.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.72,3487.5839999999907,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11522688.0,6144.0,21.28,3508.863999999991,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,360084.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,3511.519999999991,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,3514.079999999991,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,3517.919999999991,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3520.383999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3522.975999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,3526.015999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3529.087999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.968,3537.055999999991,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.872,3544.927999999991,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878976.0,6144.0,8.032,3552.959999999991,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89968.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3556.0639999999908,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3559.231999999991,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3562.879999999991,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.36,3566.239999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3568.8319999999912,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3571.935999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3575.103999999991,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.776,3578.879999999991,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3581.983999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3584.5119999999906,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3587.0719999999906,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3589.6319999999905,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,24544.0,2256300.0,0.0,0,0.0,2256300.0,2256300.0,12483.0,24.0,0.998081074598225,30720.0,6144.0,20.224,3609.8559999999907,1909999.0,297213.0,24544.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876032.0,6144.0,7.424,3617.2799999999907,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89876.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,3619.7759999999907,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,3622.271999999991,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3626.0479999999907,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3628.4479999999908,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3631.039999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,3634.079999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.2,3637.2799999999907,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10042112.0,24576.0,15.584,3652.8639999999905,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313816.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.944,3655.8079999999904,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10024960.0,24576.0,15.424,3671.2319999999904,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313280.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,3673.8879999999904,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11501696.0,6144.0,21.504,3695.3919999999903,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359428.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3697.91999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.784,3700.70399999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3704.47999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3706.87999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3709.43999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,3712.57599999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3715.64799999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.488,3723.13599999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.808,3730.94399999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.776,3738.71999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,3741.9199999999896,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,3744.9599999999896,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.808,3748.7679999999896,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,3752.0319999999897,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3754.5919999999896,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,3757.7599999999898,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3760.92799999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3764.57599999999,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3767.71199999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3770.33599999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.496,3772.83199999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3775.42399999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,24544.0,2256300.0,0.0,0,0.0,2256300.0,2256300.0,12483.0,24.0,0.998081074598225,30720.0,6144.0,20.256,3795.67999999999,1909999.0,297213.0,24544.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876160.0,6144.0,7.424,3803.10399999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89880.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3805.6319999999896,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,3808.2239999999897,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3811.9999999999895,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,3814.5599999999895,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3817.1199999999894,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.168,3820.2879999999896,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3823.3599999999897,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10007808.0,24576.0,15.776,3839.1359999999895,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312744.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,3842.0479999999893,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9990528.0,24576.0,16.128,3858.1759999999895,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312204.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3860.7679999999896,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11502208.0,6144.0,21.44,3882.2079999999896,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359444.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3884.7679999999896,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,3887.3599999999897,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,3891.0399999999895,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3893.4399999999896,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3895.9999999999895,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,3899.0079999999894,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,3902.0479999999893,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.84,3909.8879999999895,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,8.16,3918.0479999999893,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878592.0,6144.0,7.712,3925.7599999999893,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89956.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3928.863999999989,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,3931.903999999989,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3935.551999999989,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3938.655999999989,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3941.215999999989,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,3944.447999999989,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,3947.487999999989,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,3951.103999999989,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,3954.2079999999887,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3956.7359999999885,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.624,3959.3599999999883,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3961.9519999999884,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,24576.0,2256384.0,0.0,0,0.0,2256384.0,2256384.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.224,3982.1759999999886,1910016.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.392,3989.5679999999884,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,3992.0639999999885,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,3994.5919999999883,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3998.367999999988,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4000.863999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4003.423999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.168,4006.5919999999883,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,4009.6639999999884,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10027648.0,24608.0,15.648,4025.3119999999885,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313364.0,769.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,4028.2239999999883,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10021248.0,24576.0,15.232,4043.4559999999883,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313164.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4046.0479999999884,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505152.0,6144.0,21.472,4067.5199999999886,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,4070.0479999999884,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,4072.6399999999885,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,4076.4799999999886,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4078.8799999999887,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4081.4399999999887,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,4084.4799999999886,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,4087.5199999999886,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2880512.0,6144.0,7.84,4095.3599999999888,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,90016.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.872,4103.231999999989,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,24192.0,0.5434782608695652,2878464.0,6144.0,7.808,4111.039999999989,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89952.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,4114.1759999999895,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,4117.183999999989,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,4120.799999999989,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,4123.93599999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,4126.5599999999895,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,4129.7919999999895,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,4132.831999999989,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,4136.447999999989,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,4139.58399999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,4142.30399999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.528,4144.83199999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,4147.42399999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,24576.0,2256384.0,0.0,0,0.0,2256384.0,2256384.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.352,4167.77599999999,1910016.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.552,4175.3279999999895,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,4177.85599999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,4180.38399999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,4184.15999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4186.59199999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4189.15199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,4192.19199999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,4195.23199999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9988864.0,24576.0,16.256,4211.48799999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.072,4214.55999999999,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10044288.0,24576.0,14.816,4229.37599999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313884.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4231.96799999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11503616.0,6144.0,20.992,4252.95999999999,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359488.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,4255.48799999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,4258.0159999999905,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,4261.695999999991,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,4264.191999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4266.783999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,4269.8239999999905,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,4272.959999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,245528576.0,515366912.0,24309760.0,0,0.0,539676672.0,539676672.0,5697600.0,4710016.0,0.5474452554744526,542811008.0,1423872.0,522.88,4795.839999999991,19447808.0,29171712.0,233373696.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16962844.0,44496.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,4797.919999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.528,4800.447999999991,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4802.879999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,304128.0,0.0,0,0.0,304128.0,304128.0,0.0,4784.0,0.0,1215488.0,1215488.0,4.032,4806.911999999991,0.0,304128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4808.959999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,455936.0,0.0,911872.0,0,0.0,911872.0,911872.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.736,4813.695999999991,0.0,0.0,0.0,455936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,257472.0,0.0,514944.0,0,0.0,514944.0,514944.0,19668.0,359094.0,0.05192706765726234,12846592.0,0.0,10.56,4824.255999999991,0.0,0.0,0.0,257472.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,401456.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,152695.0,0.0,305390.0,0,0.0,305390.0,305390.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.608,4828.863999999991,0.0,0.0,0.0,152695.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,314688.0,0.0,629376.0,0,0.0,629376.0,629376.0,19668.0,360882.0,0.051683090264091444,12888640.0,0.0,10.048,4838.911999999991,0.0,0.0,0.0,314688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,402770.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,152073.0,0.0,304146.0,0,0.0,304146.0,304146.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.32,4843.231999999991,0.0,0.0,0.0,152073.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,300384.0,0.0,600768.0,0,0.0,600768.0,600768.0,19668.0,360435.0,0.05174386942486642,12881152.0,0.0,10.208,4853.4399999999905,0.0,0.0,0.0,300384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,402536.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,152066.0,0.0,304132.0,0,0.0,304132.0,304132.0,4768.0,14264.0,0.2505254308532997,1218176.0,76288.0,4.48,4857.91999999999,0.0,0.0,0.0,152066.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38068.0,2384.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,290848.0,0.0,581696.0,0,0.0,581696.0,581696.0,19668.0,360137.0,0.0517844683455984,12872512.0,64.0,10.272,4868.19199999999,0.0,0.0,0.0,290848.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,402266.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1066.0,0.0,2132.0,0,0.0,2132.0,2132.0,0.0,30.0,0.0,9568.0,1216.0,3.68,4871.87199999999,0.0,0.0,0.0,1066.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4873.91999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,29.0,0.956390977443609,1216.0,0.0,4.608,4878.52799999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4880.57599999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,29.0,0.956390977443609,1216.0,0.0,4.544,4885.11999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,380616.0,0.0,761232.0,0,0.0,761232.0,761232.0,64903.0,19200.0,0.7717085002913094,1242240.0,5536.0,6.304,4891.42399999999,0.0,0.0,0.0,380616.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38820.0,173.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.144,4897.56799999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,1220864.0,75968.0,4.384,4901.95199999999,0.0,0.0,0.0,607744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38152.0,2374.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,38016.0,0.0,76032.0,0,0.0,76032.0,76032.0,0.0,7176.0,0.0,1519360.0,0.0,5.664,4907.61599999999,0.0,0.0,0.0,38016.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,47480.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,911872.0,0.0,1823744.0,0,0.0,1823744.0,1823744.0,0.0,9496.0,0.0,0.0,2430976.0,4.32,4911.93599999999,0.0,0.0,0.0,911872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,387792.0,0.0,775584.0,0,0.0,775584.0,775584.0,64512.0,9496.0,0.8716895470759918,1215488.0,0.0,5.024,4916.95999999999,0.0,0.0,0.0,387792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,4919.58399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,242688.0,0.0,485376.0,0,0.0,485376.0,485376.0,82073.0,41718.0,0.6629965021689783,4143744.0,2840320.0,16.8,4936.38399999999,0.0,0.0,0.0,242688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129492.0,88760.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,95232.0,0.0,190464.0,0,0.0,190464.0,190464.0,22009.0,44536.0,0.3307385979412428,4193408.0,2455168.0,14.976,4951.35999999999,0.0,0.0,0.0,95232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131044.0,76724.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,94080.0,0.0,188160.0,0,0.0,188160.0,188160.0,21701.0,44051.0,0.33004319260250636,4210048.0,3705088.0,15.84,4967.19999999999,0.0,0.0,0.0,94080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131564.0,115784.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,94080.0,0.0,188160.0,0,0.0,188160.0,188160.0,21701.0,44112.0,0.3297372859465455,4194176.0,3287392.0,15.424,4982.62399999999,0.0,0.0,0.0,94080.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131068.0,102731.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,9496.0,0.49767245027507406,2430976.0,0.0,5.856,4988.47999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,4991.103999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,48053.0,0.0,96106.0,0,0.0,96106.0,96106.0,19325.0,24277.0,0.4432136140544012,2922752.0,2077280.0,10.144,5001.24799999999,0.0,0.0,0.0,48053.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,91336.0,64915.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,911872.0,0.0,1823744.0,0,0.0,1823744.0,1823744.0,0.0,37984.0,0.0,3665952.0,3646464.0,7.456,5008.70399999999,0.0,0.0,0.0,911872.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,114561.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,4942492.0,10038336.0,1376568.0,0,0.0,11414904.0,11414904.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,65.632,5074.335999999989,1226048.0,303872.0,4254208.0,688284.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,308224.0,1526058.0,616448.0,0,0.0,2142506.0,2142506.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,227.488,5301.82399999999,1526058.0,0.0,0.0,308224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,4784.0,0.0,1215488.0,303296.0,3.744,5305.567999999989,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.144,5307.7119999999895,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,911616.0,0.0,1823232.0,0,0.0,1823232.0,1823232.0,0.0,28488.0,0.0,2734848.0,110432.0,9.472,5317.183999999989,0.0,0.0,0.0,911616.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85464.0,3451.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,38016.0,0.0,76032.0,0,0.0,76032.0,76032.0,0.0,7176.0,0.0,1519360.0,0.0,5.76,5322.9439999999895,0.0,0.0,0.0,38016.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,4942497.0,10038336.0,1376578.0,0,0.0,11414914.0,11414914.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,66.048,5388.991999999989,1226048.0,303872.0,4254208.0,688289.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,59904.0,0.0,119808.0,0,0.0,119808.0,119808.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,6.88,5395.871999999989,0.0,0.0,0.0,59904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,5398.335999999989,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,59904.0,0.0,119808.0,0,0.0,119808.0,119808.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,7.072,5405.407999999989,0.0,0.0,0.0,59904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,5407.807999999989,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,5410.335999999989,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,5413.567999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,100352.0,492838.0,200704.0,0,0.0,693542.0,693542.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,6.752,5420.31999999999,492838.0,0.0,0.0,100352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.432,5422.7519999999895,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.264,5426.01599999999,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,5428.47999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,5431.74399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,1852160.0,2930176.0,1381888.0,0,0.0,4312064.0,4312064.0,0.0,9496.0,0.0,0.0,1215488.0,4.288,5436.031999999989,0.0,607744.0,1161216.0,690944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,1825057.0,3041280.0,608834.0,0,0.0,3650114.0,3650114.0,0.0,7176.0,0.0,2430976.0,33792.0,6.272,5442.303999999989,0.0,0.0,1520640.0,304417.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,1056.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,270720.0,0.0,541440.0,0,0.0,541440.0,541440.0,6726.0,2456.0,0.7325201481158788,1216128.0,1312.0,8.32,5450.623999999989,0.0,0.0,0.0,270720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,38004.0,41.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.528,5453.151999999989,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,5455.199999999989,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,5457.247999999989,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.464,5459.711999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.464,5462.175999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.104,5465.279999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.104,5468.383999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,5470.847999999989,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
