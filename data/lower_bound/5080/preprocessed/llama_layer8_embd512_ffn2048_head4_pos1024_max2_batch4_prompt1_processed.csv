Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.728,1.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.928,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.944,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.536,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.912,12.448,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.0,16.448,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.424,19.872,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.848,22.72,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,24.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,26.816000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,28.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,31.872,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,34.368,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,36.768,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.944,39.712,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,42.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,44.992000000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.56,47.55200000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,0.0,192.0,0.0,2176.0,8192.0,4.192,51.74400000000001,0.0,0.0,0.0,2560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.784,54.528000000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.456,57.98400000000001,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.72,60.70400000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.656,63.36000000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.528,65.888,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.328,69.21600000000001,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.624,71.84,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.264,75.104,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,77.632,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,80.28800000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,83.87200000000001,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,86.30400000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,88.96000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,92.06400000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,95.16800000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.176,101.34400000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,107.07200000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,112.83200000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,115.93600000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.104,119.04000000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,122.68800000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,125.82400000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,128.41600000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.36,131.77600000000004,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,134.81600000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,138.46400000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,141.60000000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,144.25600000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,164.41600000000003,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,170.30400000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,172.86400000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,175.42400000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,178.84800000000004,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,181.31200000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,183.90400000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,186.94400000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,189.98400000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4900864.0,32832.0,8.8,198.78400000000005,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153152.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,201.79200000000006,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891264.0,32864.0,9.024,210.81600000000006,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152852.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.688,213.50400000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.296,228.80000000000004,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,231.36000000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,233.92000000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,237.44000000000005,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,239.87200000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,242.46400000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,245.60000000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,248.73600000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,254.62400000000005,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.984,260.60800000000006,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.632,266.24000000000007,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,269.34400000000005,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,272.35200000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,276.00000000000006,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,279.1360000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,281.6960000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,284.8960000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.976,287.87200000000007,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.968,291.8400000000001,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,295.0080000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,297.6000000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,317.72800000000007,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,323.61600000000004,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,326.208,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,328.76800000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,332.192,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,334.624,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,337.24800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,340.25600000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,343.32800000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891776.0,32800.0,8.832,352.16,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152868.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.848,355.00800000000004,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4887296.0,32800.0,8.896,363.90400000000005,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152728.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,366.49600000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.744,382.24,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,384.76800000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,387.42400000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,390.88000000000005,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,393.31200000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,395.87200000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,398.88000000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.008,401.88800000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.08,407.968,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,413.728,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.632,419.36,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,422.464,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,425.472,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,429.152,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,432.352,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,434.912,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.328,438.23999999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,441.376,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,445.056,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,448.15999999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,450.71999999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,470.84799999999996,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,476.63999999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.72,479.35999999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,481.91999999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,485.34399999999994,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,487.80799999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,490.52799999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,493.568,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.168,496.736,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4893952.0,32768.0,8.736,505.472,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152936.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.88,508.352,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4892416.0,32800.0,8.896,517.2479999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152888.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,519.8079999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.2,535.0079999999999,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,537.5999999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,540.1599999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,543.6799999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,546.2079999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,548.8959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,551.9679999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.2,555.1679999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,560.9599999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,566.848,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.016,572.8639999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,575.9999999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,579.0719999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,4.032,583.1039999999999,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,586.2399999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,588.7999999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,591.9359999999998,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.976,594.9119999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.744,598.6559999999998,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,601.8239999999998,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,604.3839999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.096,624.4799999999998,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.048,630.5279999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,633.0879999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,635.6159999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,639.1039999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,641.5359999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,644.0959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,2.976,647.0719999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,650.1119999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884480.0,32768.0,9.248,659.3599999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152640.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,662.2719999999998,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4886016.0,32800.0,8.896,671.1679999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152688.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,673.7279999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.456,689.1839999999997,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,691.8399999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,694.4959999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,697.9839999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,700.4159999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,702.9759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,706.1119999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,709.2479999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.048,715.2959999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,721.0559999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,726.8799999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,730.1439999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,733.1839999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,736.8319999999995,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,739.9359999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,742.5919999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,745.7279999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,748.7359999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,752.3839999999996,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,755.4879999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,758.0479999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,778.2079999999995,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,783.9679999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,786.5599999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,789.0879999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,792.5439999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,795.0079999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,797.5999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,800.6399999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,803.7439999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4895616.0,32864.0,9.152,812.8959999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152988.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,815.8079999999997,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4902912.0,32768.0,8.64,824.4479999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153216.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.688,827.1359999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.584,842.7199999999996,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,845.2799999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.688,847.9679999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,851.4239999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,853.8559999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,856.4159999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,859.4239999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.264,862.6879999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,868.4799999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,874.3039999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,880.2239999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,883.4239999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,886.5599999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,890.2079999999995,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,893.3439999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,895.9039999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,899.0079999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.944,901.9519999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,905.5999999999995,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,908.7039999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,911.2639999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,931.3919999999995,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,937.1839999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,939.7759999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,942.3359999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,945.8239999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,948.2879999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,950.8479999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,953.8879999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,956.9919999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4897920.0,32896.0,8.896,965.8879999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153060.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,968.8959999999995,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4888576.0,32800.0,9.184,978.0799999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152768.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,980.6399999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.136,995.7759999999994,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.784,998.5599999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,1001.0879999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,1004.6719999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1007.2319999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1009.8239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,1012.8639999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,1015.9359999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,1021.8559999999992,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,1027.5839999999992,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.048,1033.6319999999992,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1036.7679999999991,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,1039.839999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,1043.519999999999,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,1046.783999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.816,1049.599999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,1052.767999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.944,1055.7119999999989,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1059.3599999999988,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,1062.4639999999988,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1065.055999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,1085.1839999999988,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,1090.9759999999987,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,1093.6319999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,1096.1919999999986,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,1099.6479999999985,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1102.1119999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1104.7679999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,1107.8399999999983,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,1110.9439999999984,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4883840.0,32928.0,9.056,1119.9999999999984,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152620.0,1029.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.976,1122.9759999999985,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4909824.0,32896.0,9.024,1131.9999999999984,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153432.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.528,1134.5279999999984,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.36,1149.8879999999983,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1152.4479999999983,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,1154.9759999999983,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,1158.5599999999984,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,1161.0559999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1163.6479999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,1166.7839999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,1169.8239999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.632,1175.4559999999985,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,1181.2799999999986,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,1187.0399999999986,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,1190.2719999999986,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,1193.3119999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1196.9599999999984,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1200.0959999999984,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1202.6559999999984,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,1205.8559999999984,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,1208.8959999999984,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1212.5439999999983,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,1215.6479999999983,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,1218.1759999999983,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,1238.3359999999984,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,1244.0639999999985,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1246.6239999999984,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,1249.1839999999984,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1252.6719999999984,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1255.1039999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1257.6959999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,1260.7039999999986,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.008,1263.7119999999986,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4888704.0,32800.0,9.184,1272.8959999999986,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152772.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.976,1275.8719999999987,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4894848.0,32800.0,8.768,1284.6399999999987,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152964.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,1287.2319999999988,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.264,1302.4959999999987,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1305.0879999999988,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,1307.679999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.648,1311.3279999999988,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1313.7919999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1316.3839999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,1319.487999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,1322.5599999999988,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,524544000.0,1052672000.0,512000.0,0,0.0,1053184000.0,1053184000.0,1804000.0,16000.0,0.9912087912087912,67551744.0,2048000.0,93.856,1416.4159999999988,0.0,4096000.0,524288000.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2110992.0,64000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,128000.0,640000.0,256000.0,0,0.0,896000.0,896000.0,0.0,20000.0,0.0,2048000.0,512000.0,8.16,1424.5759999999989,512000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,1426.591999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,1429.087999999999,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,1431.551999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.2,1434.751999999999,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1436.8639999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.064,1440.9279999999992,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.736,1445.6639999999993,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,88592.0,0.0,177184.0,0,0.0,177184.0,177184.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.128,1449.7919999999992,0.0,0.0,0.0,88592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.704,1454.4959999999992,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.032,1458.527999999999,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,4.928,1463.4559999999992,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.16,1467.6159999999993,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,128.0,4.704,1472.3199999999993,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.072,1475.3919999999991,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1477.4399999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.48,1481.9199999999992,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,1483.9359999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.384,1488.3199999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,38868.0,8424.0,0.8218726211621415,525824.0,6752.0,6.048,1494.3679999999993,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,211.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.24,1500.6079999999993,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.192,1504.7999999999993,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.424,1508.2239999999993,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.104,1511.3279999999993,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387912.0,0.0,775824.0,0,0.0,775824.0,775824.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.224,1515.5519999999992,0.0,0.0,0.0,387912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.816,1518.3679999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17804.0,0.7005919547961792,1695232.0,1183424.0,15.552,1533.9199999999992,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52976.0,36982.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17710.0,0.34875340148562184,1695872.0,1560576.0,12.96,1546.8799999999992,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52996.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17626.0,0.3793224874991197,1687424.0,1320064.0,14.272,1561.1519999999991,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52732.0,41252.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17652.0,0.37897551365043625,1687168.0,990624.0,14.08,1575.231999999999,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52724.0,30957.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.32,1579.551999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,1582.175999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9560.0,0.5248272776976987,1158144.0,820512.0,7.84,1590.015999999999,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36192.0,25641.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548608.0,1536000.0,4.48,1594.495999999999,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48394.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1051136.0,512000.0,18.72,1613.215999999999,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32848.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.104,1664.319999999999,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.04,1667.359999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.176,1669.535999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,49632.0,9.152,1678.687999999999,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1551.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.392,1682.079999999999,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,2097984.0,4245120.0,611968.0,0,0.0,4857088.0,4857088.0,528.0,5248.0,0.09141274238227147,1023872.0,512000.0,18.4,1700.479999999999,533120.0,128000.0,1792000.0,305984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31996.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.928,1729.4079999999992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,1731.8719999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.672,1760.5439999999992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,1762.9759999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,1765.6319999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,1768.895999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.472,1778.367999999999,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.464,1780.831999999999,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,1784.127999999999,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,1786.559999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,1789.791999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.064,1793.855999999999,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,767808.0,1280000.0,255616.0,0,0.0,1535616.0,1535616.0,0.0,3000.0,0.0,1024000.0,0.0,4.608,1798.463999999999,0.0,0.0,640000.0,127808.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.96,1811.423999999999,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,1813.8239999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1816.3519999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.624,1818.9759999999992,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,1821.4719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.528,1823.9999999999993,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.016,1826.0159999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,1828.0639999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,1830.5599999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.016,1832.5759999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.56,1835.1359999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.856,1840.9919999999995,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.56,1843.5519999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,1845.9839999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,1849.0559999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.392,1852.4479999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,1854.9439999999995,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,1857.3439999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.232,1860.5759999999996,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,1863.5199999999995,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.4,1865.9199999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.368,1868.2879999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.432,1870.7199999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.432,1873.1519999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,0.0,192.0,0.0,6272.0,8192.0,4.864,1878.0159999999996,0.0,0.0,0.0,2560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.752,1880.7679999999996,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.36,1884.1279999999995,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.88,1887.0079999999996,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.592,1889.5999999999997,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.528,1892.1279999999997,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,1895.4559999999997,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1897.9839999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.2,1901.1839999999997,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,1903.7119999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,1906.2719999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1909.7919999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1912.1919999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1914.7519999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,1917.7919999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,1920.8319999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.112,1926.9439999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,1932.6719999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,1938.5919999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,1941.792,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.104,1944.896,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.744,1948.6399999999999,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,1951.744,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1954.336,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1957.472,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,1960.48,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1964.128,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1967.264,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,1969.952,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.624,1972.576,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.624,1975.2,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.48,1995.68,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,2001.5040000000001,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2004.064,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,2006.624,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2010.144,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2012.544,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2015.1680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,2018.1760000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,2021.3120000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891776.0,32800.0,8.896,2030.208,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152868.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.976,2033.1840000000002,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4896640.0,32768.0,8.768,2041.9520000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153020.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,2044.5120000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.488,2060.0,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2062.592,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,2065.248,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2068.736,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2071.1679999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2073.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.168,2076.9599999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2079.9999999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.632,2085.6319999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,2091.392,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,2097.2799999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2100.3839999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2103.3919999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,2107.0079999999994,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,2110.2719999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,2112.9599999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2116.0959999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2119.1039999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2122.7519999999995,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2125.8559999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2128.479999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2131.039999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2133.631999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.48,2154.111999999999,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,2160.0319999999992,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,2162.7199999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2165.247999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,2168.831999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2171.295999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2173.9199999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,2176.9279999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2179.9679999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4882944.0,32800.0,9.344,2189.3119999999985,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152592.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2192.2239999999983,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4882560.0,32768.0,9.024,2201.2479999999982,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152580.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.528,2203.775999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.264,2219.039999999998,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2221.599999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.784,2224.383999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2227.8399999999983,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2230.271999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2232.863999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.264,2236.1279999999983,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2239.1679999999983,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,2244.8959999999984,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,2250.6239999999984,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,2256.4479999999985,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,2259.6479999999983,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.976,2262.6239999999984,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2266.3039999999983,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2269.407999999998,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2271.999999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2275.1679999999983,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2278.175999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2281.8239999999983,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2284.9919999999984,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2287.615999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2290.175999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2292.735999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,2313.055999999998,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.984,2319.039999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2321.599999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2324.127999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2327.6159999999977,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2330.015999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2332.607999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,2335.743999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,2338.815999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890112.0,32832.0,9.248,2348.063999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152816.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.88,2350.943999999998,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884608.0,32800.0,9.152,2360.095999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152644.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.72,2362.815999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.392,2378.207999999998,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2380.799999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,2383.391999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2386.911999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2389.343999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2391.8719999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,2395.0079999999975,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2398.0479999999975,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,2403.9359999999974,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.984,2409.9199999999973,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.08,2415.9999999999973,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2419.1679999999974,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,2422.2399999999975,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2425.8879999999976,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2428.9919999999975,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2431.5519999999974,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2434.6879999999974,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,2437.7279999999973,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2441.407999999997,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2444.511999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2447.135999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2449.6959999999967,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2452.287999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,2472.607999999997,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,2478.399999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2480.959999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2483.4879999999966,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2486.9759999999965,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2489.3759999999966,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2492.0319999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,2495.0719999999965,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2498.1119999999964,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4889728.0,32896.0,8.832,2506.9439999999963,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152804.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2509.855999999996,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891264.0,32800.0,9.088,2518.9439999999963,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152852.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,2521.5039999999963,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.392,2536.895999999996,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2539.487999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,2542.0799999999963,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2545.5039999999963,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,2548.031999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2550.687999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,2553.727999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2556.767999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,2562.559999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,2568.319999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,2574.239999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2577.375999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2580.383999999996,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2584.0639999999958,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,2587.2639999999956,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2589.8239999999955,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2592.9599999999955,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,2596.0959999999955,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2599.7759999999953,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2602.9119999999953,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,2605.567999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2608.127999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2610.7199999999953,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.384,2631.1039999999953,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,2636.991999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,2639.519999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,2642.175999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2645.6639999999948,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2648.063999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2650.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,2653.6639999999948,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2656.7039999999947,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4898304.0,32768.0,8.928,2665.6319999999946,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153072.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2668.5439999999944,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4889984.0,32800.0,9.024,2677.5679999999943,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152812.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,2680.1279999999942,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.136,2695.263999999994,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2697.823999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2700.351999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,2703.871999999994,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2706.271999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2708.799999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,2711.839999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.168,2715.007999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,2720.799999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,2726.6879999999937,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,2732.415999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2735.5519999999938,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2738.5599999999936,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2742.2399999999934,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,2745.4399999999932,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,2748.095999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2751.199999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,2754.239999999993,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2757.887999999993,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2760.991999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2763.583999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2766.143999999993,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2768.735999999993,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.288,2789.023999999993,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.016,2795.039999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.816,2797.855999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2800.3839999999927,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2803.839999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2806.239999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2808.799999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,2811.9039999999927,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.264,2815.167999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4894336.0,32896.0,8.8,2823.967999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152948.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.944,2826.911999999993,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891392.0,32768.0,8.864,2835.775999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152856.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,2838.367999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.232,2853.599999999993,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2856.159999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,2858.719999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2862.143999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2864.543999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2867.103999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,2870.175999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,2873.215999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,2878.943999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,2884.831999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,2890.751999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2893.887999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,2896.959999999993,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2900.639999999993,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,2903.743999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2906.3679999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2909.5039999999926,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,2912.5439999999926,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.744,2916.2879999999927,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2919.455999999993,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2922.0799999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.88,2924.9599999999928,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2927.551999999993,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.224,2947.775999999993,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,6.08,2953.855999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,2956.543999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.624,2959.167999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2962.6559999999927,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2965.0879999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2967.6479999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,2970.7199999999925,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.008,2973.7279999999923,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4892544.0,32768.0,9.12,2982.847999999992,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152892.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,2985.759999999992,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4887808.0,32768.0,9.12,2994.879999999992,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152744.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,2997.471999999992,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.232,3012.703999999992,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,3015.327999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,3017.919999999992,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3021.4079999999917,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3023.8719999999917,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3026.4319999999916,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,3029.4719999999916,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,3032.5119999999915,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,3038.3359999999916,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,3044.2559999999917,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.824,3050.0799999999917,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,3053.2159999999917,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.2,3056.4159999999915,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3060.0639999999917,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,3063.1999999999916,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,3065.8239999999914,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,3068.9919999999915,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,3072.0319999999915,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3075.6799999999917,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,3078.7839999999915,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,3081.3759999999916,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,3083.9679999999917,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,3086.5599999999918,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,3106.879999999992,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,3112.607999999992,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,3115.295999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,3117.823999999992,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,3121.279999999992,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3123.711999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3126.2719999999917,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,3129.4079999999917,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.168,3132.575999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4886400.0,32832.0,9.248,3141.823999999992,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152700.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.944,3144.767999999992,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4883072.0,32800.0,9.216,3153.9839999999917,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152596.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.528,3156.5119999999915,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.552,3172.0639999999917,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,3174.6559999999918,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3177.2159999999917,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,3180.671999999992,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,3183.1999999999916,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3185.7919999999917,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,3188.8319999999917,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,3191.9679999999917,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,524544000.0,1052672000.0,512000.0,0,0.0,1053184000.0,1053184000.0,1804000.0,16000.0,0.9912087912087912,67549248.0,2048000.0,94.464,3286.4319999999916,0.0,4096000.0,524288000.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2110914.0,64000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,128000.0,640000.0,256000.0,0,0.0,896000.0,896000.0,0.0,20000.0,0.0,2048000.0,512000.0,7.904,3294.3359999999916,512000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3296.3839999999914,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.56,3298.9439999999913,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,3301.3439999999914,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,2.976,3304.3199999999915,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,3306.3359999999916,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.032,3310.3679999999918,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.832,3315.1999999999916,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,88899.0,0.0,177798.0,0,0.0,177798.0,177798.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,3319.5519999999915,0.0,0.0,0.0,88899.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.896,3324.4479999999917,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64528.0,0.0,129056.0,0,0.0,129056.0,129056.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.096,3328.5439999999917,0.0,0.0,0.0,64528.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,119808.0,0.0,239616.0,0,0.0,239616.0,239616.0,8448.0,34728.0,0.19566425792106726,2106624.0,0.0,5.024,3333.5679999999916,0.0,0.0,0.0,119808.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,3337.9199999999914,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,8448.0,34632.0,0.19610027855153203,2106624.0,128.0,4.736,3342.6559999999913,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.072,3345.7279999999914,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,3347.7439999999915,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.448,3352.1919999999914,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,3354.335999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.288,3358.623999999991,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,30135.0,8414.0,0.7817323406573452,525824.0,7264.0,6.176,3364.799999999991,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,227.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.144,3370.943999999991,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.224,3375.167999999991,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.296,3378.463999999991,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.136,3381.599999999991,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387908.0,0.0,775816.0,0,0.0,775816.0,775816.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.128,3385.727999999991,0.0,0.0,0.0,387908.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,3388.319999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17594.0,0.7030748978971884,1695232.0,1210944.0,15.392,3403.711999999991,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52976.0,37842.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,45184.0,0.0,90368.0,0,0.0,90368.0,90368.0,10888.0,17699.0,0.3808724245286319,1700352.0,1488224.0,13.088,3416.799999999991,0.0,0.0,0.0,45184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53136.0,46507.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17620.0,0.3794026486334179,1688320.0,1207520.0,14.432,3431.231999999991,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52760.0,37735.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17622.0,0.37937592449108964,1689216.0,1281056.0,14.176,3445.407999999991,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52788.0,40033.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.192,3449.599999999991,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,3452.191999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9606.0,0.523630052070419,1158144.0,823648.0,7.712,3459.903999999991,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36192.0,25739.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548928.0,1536000.0,4.384,3464.287999999991,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48404.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,996608.0,512000.0,18.464,3482.751999999991,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31144.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,50.848,3533.599999999991,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.072,3536.671999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,3538.8159999999907,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,51552.0,8.8,3547.615999999991,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1611.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.328,3550.943999999991,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,2097985.0,4245120.0,611970.0,0,0.0,4857090.0,4857090.0,528.0,5248.0,0.09141274238227147,1028096.0,512000.0,18.688,3569.631999999991,533120.0,128000.0,1792000.0,305985.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32128.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.448,3598.079999999991,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,3600.6079999999906,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.48,3629.0879999999906,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,3631.5199999999904,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,3634.04799999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,3637.24799999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.696,3646.94399999999,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,3649.3759999999897,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,3652.6719999999896,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,3655.1039999999894,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,3658.4319999999893,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.096,3662.5279999999893,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,767809.0,1280000.0,255618.0,0,0.0,1535618.0,1535618.0,0.0,3000.0,0.0,1024000.0,0.0,4.576,3667.1039999999894,0.0,0.0,640000.0,127809.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.896,3679.9999999999895,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,3682.4639999999895,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,3684.8959999999893,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,3687.3919999999894,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,3689.919999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.496,3692.4159999999893,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,3694.463999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,3696.511999999989,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,3699.007999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,3701.0559999999887,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.496,3703.5519999999888,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.856,3709.407999999989,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,3711.903999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,3714.335999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.04,3717.375999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.264,3720.639999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.368,3723.007999999989,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
