Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.6,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.24,5.5360000000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.36,8.896,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.816,11.712,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.048,13.76,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,15.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.208,17.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,19.808,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,22.816,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,25.375999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,27.807999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.976,30.783999999999995,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,33.215999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.496,35.711999999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.528,38.239999999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,0.0,192.0,0.0,2176.0,8192.0,4.384,42.623999999999995,0.0,0.0,0.0,2560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.848,45.471999999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.392,48.864,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.816,51.68,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.752,54.432,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.688,57.120000000000005,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.264,60.38400000000001,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.656,63.040000000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.264,66.304,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,68.83200000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.624,71.456,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.616,75.072,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.912,77.98400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,80.64000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,83.71200000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,86.78400000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.304,93.08800000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.208,99.29600000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,105.40800000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,108.57600000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,111.64800000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,115.26400000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,118.40000000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,120.92800000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.456,124.38400000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,127.42400000000004,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.712,131.13600000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,134.30400000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,136.83200000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,156.99200000000002,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.856,162.848,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,165.40800000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,167.96800000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,171.45600000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,173.85600000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,176.41600000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,179.55200000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,182.68800000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884864.0,32832.0,9.28,191.96800000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152652.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,194.97600000000003,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4889472.0,32832.0,9.216,204.19200000000004,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152796.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,206.78400000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.488,222.27200000000005,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,224.86400000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,227.39200000000005,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,230.81600000000006,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,233.21600000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,235.80800000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,238.9120000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,242.0480000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,248.1280000000001,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,254.2400000000001,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.888,260.1280000000001,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,263.3920000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.168,266.5600000000001,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,270.2400000000001,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,273.40800000000013,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,276.03200000000015,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,279.2640000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,282.3360000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,286.0160000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,289.2800000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,291.8720000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.416,312.2880000000002,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.632,317.9200000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,320.5760000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.624,323.2000000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,326.75200000000024,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,329.1520000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,331.87200000000024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,334.94400000000024,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,338.01600000000025,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884480.0,32768.0,9.28,347.2960000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152640.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,350.3040000000002,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4883328.0,32800.0,9.28,359.5840000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152604.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.624,362.2080000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,16.0,378.2080000000002,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,380.7680000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,383.3280000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,386.7520000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,389.15200000000016,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,391.74400000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,394.8480000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,397.98400000000015,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,404.0960000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.304,410.40000000000015,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.888,416.2880000000001,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,419.52000000000015,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,422.5600000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,426.2080000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,429.4400000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,432.09600000000023,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,435.32800000000026,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.168,438.49600000000027,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,442.1760000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,445.3120000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,447.8720000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.288,468.1600000000003,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.888,474.0480000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,476.6080000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,479.1360000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,482.7200000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,485.1520000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,487.7440000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,490.8160000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,493.8880000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4886016.0,32864.0,9.152,503.0400000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152688.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.976,506.0160000000003,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4888704.0,32896.0,8.832,514.8480000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152772.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,517.4400000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.616,533.0560000000003,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,535.6160000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,538.2080000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,541.6960000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,544.1280000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,546.7840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,549.8880000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,552.9920000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,559.1040000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.952,565.0560000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,571.1680000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,574.3360000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.168,577.5040000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,581.1520000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,584.4160000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,587.0720000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,590.2400000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,2.976,593.2160000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,596.8640000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,600.1280000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,602.6560000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,622.7840000000003,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,628.5760000000004,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,631.1680000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,633.8240000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,637.3440000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,639.7440000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,642.3360000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,645.4400000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,648.5440000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4882944.0,32832.0,8.992,657.5360000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152592.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,660.5440000000003,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4885120.0,32896.0,9.312,669.8560000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152660.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,672.4160000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.392,687.8080000000003,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.72,690.5280000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,693.0560000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,696.5120000000004,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,698.9120000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,701.5040000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,704.5440000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,707.5840000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.048,713.6320000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.92,719.5520000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.208,725.7600000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,729.0240000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.104,732.1280000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,735.7760000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.296,739.0720000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,741.6320000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,744.8000000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,747.9360000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,751.5840000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,754.7200000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,757.2480000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.32,777.5680000000003,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.856,783.4240000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,785.9520000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,788.4800000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,792.0000000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,794.4320000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,797.0240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.008,800.0320000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,803.1360000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4904448.0,32800.0,9.12,812.2560000000004,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153264.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.072,815.3280000000004,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4895104.0,32832.0,9.088,824.4160000000004,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152972.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.56,826.9760000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.36,842.3360000000004,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,844.9280000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.496,847.4240000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,850.8800000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,853.2800000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,855.8400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,858.9120000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,862.0160000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.952,867.9680000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.952,873.9200000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.92,879.8400000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,882.9760000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,886.0480000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,889.6640000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,892.8640000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,895.4880000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,898.6240000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.2,901.8240000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,905.4400000000003,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,908.5760000000002,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,911.2000000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.128,931.3280000000003,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,937.0880000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,939.6480000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,942.1760000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.648,945.8240000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,948.1920000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,950.7840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.168,953.9520000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.008,956.9600000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4887808.0,32800.0,8.992,965.9520000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152744.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,968.8640000000004,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4892288.0,32768.0,9.248,978.1120000000004,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152884.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,980.7040000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.328,996.0320000000004,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,998.5600000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,1001.1200000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.52,1004.6400000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1007.0720000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1009.6640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,1012.7040000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,1015.8400000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.048,1021.8880000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,1027.9680000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.048,1034.0160000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,1037.2480000000003,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,1040.3200000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.712,1044.0320000000002,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,1047.2640000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1049.824,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,1053.0240000000001,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,1056.16,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.712,1059.872,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1063.008,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1065.568,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.16,1085.728,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,1091.52,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1094.112,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,1096.768,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,1100.256,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1102.6560000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,1105.3760000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,1108.448,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,1111.584,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4885504.0,32800.0,8.896,1120.48,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152672.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.912,1123.392,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890112.0,32832.0,9.152,1132.544,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152816.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.816,1135.3600000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.968,1151.3280000000002,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,1153.9200000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,1156.4480000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,1159.9040000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1162.2720000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1164.8640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.2,1168.0640000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,1171.1680000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,1177.2480000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.144,1183.3920000000003,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.984,1189.3760000000002,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,1192.544,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.168,1195.712,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1199.36,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,1202.4959999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,1205.024,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,1208.2559999999999,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,1211.3279999999997,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,1214.9759999999997,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,1218.1759999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1220.7359999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,32768.0,3007488.0,0.0,0,0.0,3007488.0,3007488.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,20.096,1240.8319999999997,2545664.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.792,1246.6239999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1249.1839999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,1251.8399999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,1255.2959999999994,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1257.6959999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1260.2559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,1263.2959999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,1266.3679999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884864.0,32768.0,8.928,1275.2959999999994,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152652.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.944,1278.2399999999993,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4892928.0,32768.0,9.024,1287.2639999999992,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152904.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,1289.8559999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,14.944,1304.7999999999993,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,1307.3599999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,1309.8879999999992,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,1313.4719999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1315.8719999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1318.4959999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,1321.5679999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,1324.6079999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,320888832.0,690397184.0,19447808.0,0,0.0,709844992.0,709844992.0,5241792.0,3950336.0,0.5702479338842975,409641088.0,2778816.0,347.552,1672.1599999999994,29171712.0,38895616.0,311164928.0,9723904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12801284.0,86838.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,1674.1759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.592,1676.7679999999996,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1679.1999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.312,1684.5119999999995,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,1686.5919999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.76,1692.3519999999994,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20661440.0,0.0,12.352,1704.7039999999995,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645670.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,357596.0,0.0,715192.0,0,0.0,715192.0,715192.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.6,1710.3039999999994,0.0,0.0,0.0,357596.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,396032.0,0.0,792064.0,0,0.0,792064.0,792064.0,31416.0,458872.0,0.06407662435140163,20650464.0,0.0,12.096,1722.3999999999994,0.0,0.0,0.0,396032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645327.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243732.0,0.0,487464.0,0,0.0,487464.0,487464.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.696,1728.0959999999993,0.0,0.0,0.0,243732.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20701408.0,0.0,12.352,1740.4479999999994,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646919.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.632,1746.0799999999995,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,502656.0,0.0,1005312.0,0,0.0,1005312.0,1005312.0,31416.0,462204.0,0.0636440986994044,20826752.0,128.0,12.704,1758.7839999999994,0.0,0.0,0.0,502656.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,650836.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.584,1762.3679999999995,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1764.4479999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.672,1769.1199999999994,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1771.1679999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.576,1775.7439999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,98564.0,34560.0,0.7403924160932664,2473696.0,10464.0,7.328,1783.0719999999994,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,327.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.24,1789.3119999999994,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,6.4,1795.7119999999995,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,768.0,6.464,1802.1759999999995,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,24.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.624,1808.7999999999995,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388610.0,0.0,777220.0,0,0.0,777220.0,777220.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.72,1815.5199999999995,0.0,0.0,0.0,388610.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,1818.1439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,468480.0,0.0,936960.0,0,0.0,936960.0,936960.0,157750.0,83461.0,0.6539917333786601,8372992.0,5497792.0,27.648,1845.7919999999995,0.0,0.0,0.0,468480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261656.0,171806.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,45430.0,88913.0,0.33816425120772947,8422784.0,4747072.0,24.096,1869.8879999999995,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263212.0,148346.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90712.0,0.30913466664635725,8407936.0,4258432.0,23.264,1893.1519999999994,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262748.0,133076.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,88802.0,0.3136979102262891,8426368.0,5296896.0,23.648,1916.7999999999993,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263324.0,165528.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.672,1925.4719999999993,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,1928.0639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,52292.0,0.42489496953566636,5952640.0,3836672.0,14.464,1942.5279999999993,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,186020.0,119896.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7328736.0,7292928.0,11.52,1954.0479999999993,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229023.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.344,2019.3919999999994,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,228.96,2248.3519999999994,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.312,2253.6639999999993,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,2255.807999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,217120.0,10.56,2266.367999999999,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6785.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,0.0,6.624,2272.991999999999,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9884992.0,20076672.0,2753152.0,0,0.0,22829824.0,22829824.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,66.016,2339.007999999999,2452096.0,607744.0,8508416.0,1376576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.84,2346.847999999999,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2349.247999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.936,2357.1839999999993,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2359.5839999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,2362.1439999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,2365.4719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,8.16,2373.631999999999,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,2376.063999999999,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,2379.3599999999988,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,2381.759999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,2384.9599999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.12,2390.0799999999986,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649728.0,6082560.0,1216896.0,0,0.0,7299456.0,7299456.0,0.0,14280.0,0.0,4861952.0,72704.0,9.024,2399.1039999999985,0.0,0.0,3041280.0,608448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,2272.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2656.0,9.184,2408.2879999999986,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,83.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.528,2410.8159999999984,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2412.863999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,2414.943999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,2417.4399999999982,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.4,2419.8399999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,2422.9119999999984,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.36,2426.2719999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.56,2428.8319999999985,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2431.2639999999983,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.136,2434.3999999999983,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,2437.3439999999982,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.496,2439.8399999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.4,2442.2399999999984,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.496,2444.7359999999985,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.496,2447.2319999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,0.0,192.0,0.0,8320.0,8192.0,5.472,2452.703999999999,0.0,0.0,0.0,2560.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,260.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.784,2455.487999999999,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.328,2458.815999999999,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.72,2461.5359999999987,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.56,2464.0959999999986,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.592,2466.6879999999987,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2469.855999999999,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.56,2472.415999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.296,2475.7119999999986,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2478.2399999999984,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.624,2480.863999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2484.351999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2486.751999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2489.3439999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,2492.383999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,2495.4559999999983,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.048,2501.503999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.24,2507.743999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.952,2513.695999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,2516.927999999998,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2519.935999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2523.6159999999977,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2526.7519999999977,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2529.3119999999976,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,2532.4479999999976,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2535.4559999999974,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2539.1359999999972,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2542.3039999999974,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2544.8959999999975,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.624,2547.5199999999973,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.656,2550.175999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.512,2570.6879999999974,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,2576.4479999999976,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2579.0719999999974,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,2581.6319999999973,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2585.0559999999973,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2587.4559999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,2590.175999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,2593.2479999999973,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,2596.3199999999974,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884736.0,32832.0,9.184,2605.5039999999976,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152648.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.944,2608.4479999999976,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884736.0,32832.0,9.28,2617.727999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152648.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.624,2620.3519999999976,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.136,2635.4879999999976,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2638.0799999999977,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,2640.7359999999976,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,2644.2239999999974,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2646.655999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2649.215999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,2652.2879999999973,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,2655.391999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.272,2661.663999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,2667.743999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.272,2674.015999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2677.183999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.2,2680.383999999997,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2684.031999999997,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,2687.263999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,2689.823999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,2693.087999999997,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,2696.223999999997,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2699.903999999997,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.296,2703.1999999999966,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2705.7919999999967,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2708.3519999999967,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2710.9119999999966,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.672,2731.5839999999966,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.856,2737.439999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2740.031999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2742.5599999999968,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2746.015999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,2748.5439999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2751.135999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,2754.2719999999968,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,2757.343999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890624.0,32896.0,8.832,2766.1759999999967,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152832.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.136,2769.3119999999967,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4897536.0,32800.0,8.832,2778.1439999999966,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153048.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.624,2780.7679999999964,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.616,2796.3839999999964,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.688,2799.0719999999965,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,2801.6319999999964,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,2805.0559999999964,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2807.4559999999965,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2810.0799999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,2.976,2813.0559999999964,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,2816.159999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,2822.2719999999963,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.016,2828.2879999999964,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.92,2834.2079999999964,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2837.3759999999966,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.008,2840.3839999999964,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,2844.0319999999965,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,2847.2639999999965,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,2849.9199999999964,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,2853.1199999999963,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,2856.159999999996,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,2859.839999999996,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,2863.007999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,2865.631999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,2868.223999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,2870.783999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.288,2891.071999999996,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,2896.991999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2899.583999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2902.111999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,2905.567999999996,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2907.967999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2910.5599999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,2913.5999999999963,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.168,2916.7679999999964,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890496.0,32896.0,8.992,2925.7599999999966,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152828.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.04,2928.7999999999965,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890368.0,32896.0,9.248,2938.0479999999966,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152824.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.624,2940.6719999999964,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.52,2956.1919999999964,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,2958.7839999999965,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,2961.3119999999963,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,2964.895999999996,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,2967.455999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2970.047999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,2973.1199999999963,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.2,2976.319999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.176,2982.495999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.144,2988.639999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.112,2994.751999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,2997.983999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,3001.055999999996,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,3004.671999999996,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,3007.839999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3010.399999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.328,3013.727999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,3016.767999999996,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3020.415999999996,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,3023.519999999996,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.528,3026.0479999999957,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.656,3028.7039999999956,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,3031.2959999999957,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,3051.615999999996,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.952,3057.567999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,3060.159999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,3062.687999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,3066.239999999996,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3068.7359999999962,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,3071.487999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,3074.591999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.168,3077.759999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4890112.0,32832.0,9.184,3086.9439999999963,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152816.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.944,3089.8879999999963,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884736.0,33056.0,9.024,3098.911999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152648.0,1033.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,3101.5039999999963,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.328,3116.8319999999962,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3119.391999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3121.951999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,3125.375999999996,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3127.743999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3130.335999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,3133.4079999999963,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.2,3136.607999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,3142.687999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.24,3148.927999999996,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.144,3155.0719999999956,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,3158.2079999999955,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,3161.2479999999955,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3164.8959999999956,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,3167.9999999999955,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3170.5599999999954,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,3173.7919999999954,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.136,3176.9279999999953,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.744,3180.6719999999955,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,3183.8719999999953,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3186.4319999999952,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,3188.991999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.528,3191.519999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.32,3211.839999999995,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,3217.5999999999954,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.624,3220.223999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3222.783999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.584,3226.367999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,3228.8959999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3231.4559999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.232,3234.6879999999946,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,3237.7919999999945,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4882560.0,32864.0,9.088,3246.8799999999947,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152580.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.976,3249.8559999999948,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884480.0,32832.0,9.152,3259.007999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152640.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,3261.599999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.52,3277.119999999995,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3279.679999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.528,3282.2079999999946,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,3285.6639999999948,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3288.063999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3290.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,3293.727999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.2,3296.927999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.888,3302.815999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.048,3308.8639999999946,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.08,3314.9439999999945,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.168,3318.1119999999946,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.168,3321.2799999999947,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.616,3324.8959999999947,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.264,3328.159999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3330.719999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,3333.8559999999948,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,3336.927999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3340.575999999995,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.104,3343.679999999995,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3346.239999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.528,3348.7679999999946,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.688,3351.4559999999947,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.512,3371.967999999995,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.92,3377.887999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3380.447999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3383.007999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.424,3386.431999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3388.8639999999946,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3391.4559999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,3394.527999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.072,3397.599999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4903296.0,32800.0,9.184,3406.783999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153228.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.008,3409.791999999995,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4898816.0,32832.0,9.024,3418.815999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,153088.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.656,3421.4719999999948,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.424,3436.8959999999947,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3439.4559999999947,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3442.0159999999946,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3445.5039999999944,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3447.8719999999944,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3450.4639999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.232,3453.6959999999945,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,3456.7359999999944,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.176,3462.9119999999944,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.272,3469.1839999999943,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,5.824,3475.0079999999944,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,3478.207999999994,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,3481.247999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,3484.927999999994,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,3488.127999999994,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3490.6879999999937,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.136,3493.8239999999937,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.04,3496.8639999999937,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.68,3500.5439999999935,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,3503.7759999999935,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3506.3359999999934,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.592,3508.9279999999935,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.56,3511.4879999999935,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.352,3531.8399999999933,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.76,3537.5999999999935,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3540.1599999999935,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3542.7199999999934,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.456,3546.1759999999936,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3548.5759999999937,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3551.1359999999936,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.104,3554.2399999999934,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,3557.3439999999932,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4889984.0,32800.0,9.152,3566.4959999999933,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152812.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,2.88,3569.3759999999934,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4891904.0,32768.0,8.896,3578.2719999999936,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152872.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.592,3580.8639999999937,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.392,3596.2559999999935,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3598.8159999999934,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.56,3601.3759999999934,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3604.863999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3607.295999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3609.887999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.072,3612.959999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.104,3616.063999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.272,3622.335999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.144,3628.4799999999927,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.144,3634.6239999999925,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.328,3637.9519999999925,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.232,3641.1839999999925,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3644.8319999999926,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,3648.0639999999926,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,3650.6559999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.2,3653.8559999999925,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,3.072,3656.9279999999926,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,176128.0,0.0,352256.0,0,0.0,352256.0,352256.0,0.0,128.0,0.0,8192.0,8192.0,3.648,3660.5759999999927,0.0,0.0,0.0,176128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,6144.0,2048.0,12288.0,0,0.0,14336.0,14336.0,0.0,192.0,0.0,12288.0,8192.0,3.232,3663.8079999999927,0.0,2048.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.56,3666.3679999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.656,3669.0239999999926,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,160.0,0.0,16384.0,16384.0,2.688,3671.7119999999927,0.0,0.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,32768.0,3008512.0,0.0,0,0.0,3008512.0,3008512.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,20.64,3692.3519999999926,2546688.0,396288.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1280.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13312.0,0.5702479338842975,1572864.0,8192.0,5.728,3698.0799999999927,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,49152.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.656,3700.7359999999926,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.656,3703.3919999999925,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.552,3706.9439999999927,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3709.3759999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3711.9359999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.136,3715.0719999999924,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.136,3718.2079999999924,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4884608.0,32768.0,9.184,3727.3919999999925,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152644.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,90112.0,172032.0,16384.0,0,0.0,188416.0,188416.0,0.0,128.0,0.0,32768.0,32768.0,3.04,3730.4319999999925,8192.0,0.0,81920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,4887808.0,32768.0,9.056,3739.4879999999926,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,152744.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,2.624,3742.1119999999923,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,4276224.0,9207808.0,163840.0,0,0.0,9371648.0,9371648.0,57600.0,50176.0,0.5344418052256532,6291456.0,8192.0,15.52,3757.6319999999923,294912.0,524288.0,4194304.0,81920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,196608.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,2.592,3760.2239999999924,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,2.592,3762.8159999999925,0.0,2048.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,3.488,3766.3039999999924,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3768.6719999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3771.295999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,8448.0,8192.0,3.04,3774.335999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,16384.0,8192.0,3.04,3777.375999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,320888832.0,690397184.0,19447808.0,0,0.0,709844992.0,709844992.0,5241792.0,3950336.0,0.5702479338842975,408377344.0,2761920.0,347.36,4124.735999999992,29171712.0,38895616.0,311164928.0,9723904.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12761792.0,86310.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4126.7839999999915,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.56,4129.343999999992,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4131.775999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.056,4136.831999999991,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4138.879999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.92,4144.799999999991,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20722592.0,32.0,12.672,4157.471999999991,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,647581.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,357885.0,0.0,715770.0,0,0.0,715770.0,715770.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.664,4163.13599999999,0.0,0.0,0.0,357885.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,396032.0,0.0,792064.0,0,0.0,792064.0,792064.0,31416.0,458872.0,0.06407662435140163,20793952.0,0.0,12.8,4175.935999999991,0.0,0.0,0.0,396032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,649811.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243724.0,0.0,487448.0,0,0.0,487448.0,487448.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.6,4181.535999999991,0.0,0.0,0.0,243724.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,449344.0,0.0,898688.0,0,0.0,898688.0,898688.0,31416.0,460538.0,0.06385962915231912,20776032.0,96.0,12.512,4194.047999999991,0.0,0.0,0.0,449344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,649251.0,3.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.76,4199.807999999991,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,472192.0,0.0,944384.0,0,0.0,944384.0,944384.0,31416.0,461252.0,0.06376708046798249,20854080.0,128.0,12.832,4212.639999999991,0.0,0.0,0.0,472192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,651690.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.616,4216.255999999991,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4218.303999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.768,4223.071999999991,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4225.119999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.544,4229.663999999991,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,117916.0,34556.0,0.7733616664043235,2473696.0,10528.0,7.616,4237.279999999991,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,329.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.176,4243.455999999991,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,6.304,4249.759999999991,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,71808.0,6.88,4256.639999999991,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,2244.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.592,4263.231999999991,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388612.0,0.0,777224.0,0,0.0,777224.0,777224.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.368,4269.599999999991,0.0,0.0,0.0,388612.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,4272.223999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,496128.0,0.0,992256.0,0,0.0,992256.0,992256.0,168982.0,83639.0,0.668915094152901,8416512.0,5657856.0,28.0,4300.223999999991,0.0,0.0,0.0,496128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263016.0,176808.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,90976.0,0.3044116522669929,8430720.0,7410560.0,23.936,4324.159999999991,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263460.0,231580.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90686.0,0.3091958926231756,8408192.0,6221120.0,22.752,4346.911999999991,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262756.0,194410.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90979.0,0.30850732315363044,8457088.0,4589088.0,23.52,4370.431999999992,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264284.0,143409.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.352,4378.7839999999915,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,4381.407999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,52201.0,0.4253206363185997,5919360.0,3846080.0,14.336,4395.7439999999915,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,184980.0,120190.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7330528.0,7292928.0,11.52,4407.263999999992,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229079.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.76,4473.023999999992,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,228.928,4701.951999999992,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.088,4707.039999999992,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,4709.183999999992,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,215552.0,10.688,4719.871999999992,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6736.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2944.0,6.432,4726.303999999992,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,92.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884992.0,20076672.0,2753152.0,0,0.0,22829824.0,22829824.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.952,4792.255999999992,2452096.0,607744.0,8508416.0,1376576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.968,4800.223999999992,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,4802.623999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.032,4810.655999999992,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.56,4813.215999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,4815.743999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,4819.071999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.808,4826.879999999993,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,4829.311999999993,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,4832.575999999993,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,4834.975999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4838.175999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.12,4843.295999999992,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649728.0,6082560.0,1216896.0,0,0.0,7299456.0,7299456.0,0.0,14280.0,0.0,4861952.0,119296.0,8.928,4852.223999999992,0.0,0.0,3041280.0,608448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,3728.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2688.0,9.536,4861.759999999992,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,84.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.688,4864.447999999992,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4866.495999999992,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4868.543999999992,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,4871.071999999992,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,4873.503999999992,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.168,4876.671999999991,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.2,4879.871999999991,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,4882.271999999991,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
