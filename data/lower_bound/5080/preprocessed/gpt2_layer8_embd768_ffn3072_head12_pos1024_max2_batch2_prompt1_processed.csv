Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.6,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.928,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,6.976,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.568,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.592,12.16,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.776,15.936,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.296,19.232,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,21.695999999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,23.775999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,25.823999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,27.967999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.168,31.135999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,33.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,36.096,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.912,39.007999999999996,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,41.407999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.56,43.967999999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.528,46.495999999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,3264.0,6144.0,3.872,50.367999999999995,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,3264.0,6144.0,3.36,53.727999999999994,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.816,56.544,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,58.976,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.52,62.496,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.152,67.648,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.672,84.32,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,87.32799999999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,90.368,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,93.408,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,11.04,104.44800000000001,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.488,119.936,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,122.49600000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.152,127.64800000000001,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,17.408,145.056,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,147.68,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.72,150.4,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,153.056,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,155.64800000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,158.20800000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,36502.0,89900.0,1536.0,0,0.0,91436.0,91436.0,0.0,96.0,0.0,24576.0,24576.0,2.688,160.89600000000002,6144.0,12288.0,35734.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.592,163.48800000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,166.08000000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),43,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.376,183.45600000000005,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.584,187.04000000000005,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,189.66400000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,194.75200000000004,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.968,210.72000000000003,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.072,213.79200000000003,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,216.80000000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,219.84000000000003,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.336,230.17600000000004,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",52,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.616,245.79200000000003,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,248.38400000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,253.44000000000005,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.48,269.9200000000001,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,272.4480000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",57,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,274.9760000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,277.50400000000013,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,280.06400000000014,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,282.59200000000016,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,36460.0,89816.0,1536.0,0,0.0,91352.0,91352.0,0.0,96.0,0.0,24576.0,24576.0,2.72,285.3120000000002,6144.0,12288.0,35692.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,287.8400000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",63,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.688,290.5280000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),64,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.216,307.7440000000002,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.52,311.2640000000002,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,313.8880000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.12,319.0080000000002,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.648,334.65600000000023,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,337.6640000000002,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.136,340.80000000000024,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,343.8080000000002,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.336,354.14400000000023,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.296,369.4400000000002,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,372.09600000000023,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.152,377.2480000000002,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",76,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.672,393.92000000000024,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,396.48000000000025,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",78,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.752,399.23200000000026,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,401.7600000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,404.35200000000026,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,406.8800000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,36456.0,89808.0,1536.0,0,0.0,91344.0,91344.0,0.0,96.0,0.0,24576.0,24576.0,2.72,409.6000000000003,6144.0,12288.0,35688.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",83,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,412.1280000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,414.78400000000033,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),85,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.088,431.87200000000036,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.52,435.39200000000034,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,437.95200000000034,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,443.04000000000036,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.064,459.1040000000004,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,462.11200000000036,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.2,465.31200000000035,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.072,468.38400000000036,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.336,478.72000000000037,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.328,494.04800000000034,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,496.60800000000035,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,501.63200000000035,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",97,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.448,518.0800000000004,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,520.6400000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",99,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.592,523.2320000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,525.7600000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",101,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,528.3840000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,530.9120000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,36492.0,89880.0,1536.0,0,0.0,91416.0,91416.0,0.0,96.0,0.0,24576.0,24576.0,2.624,533.5360000000004,6144.0,12288.0,35724.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",104,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,536.0640000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.752,538.8160000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),106,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.12,555.9360000000004,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.552,559.4880000000004,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,562.0800000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,567.1040000000004,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",110,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.224,583.3280000000004,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,586.3360000000005,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.104,589.4400000000005,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,592.4800000000005,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.304,602.7840000000004,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.912,617.6960000000005,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,620.2560000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,625.2800000000004,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.864,642.1440000000005,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,644.8000000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",120,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,647.3600000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",121,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,649.8880000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,652.5120000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,655.0400000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,36474.0,89844.0,1536.0,0,0.0,91380.0,91380.0,0.0,96.0,0.0,24576.0,24576.0,2.624,657.6640000000004,6144.0,12288.0,35706.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",125,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,660.1920000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.816,663.0080000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),127,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.992,680.0000000000005,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.52,683.5200000000004,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,686.0800000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,691.1360000000004,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.904,707.0400000000004,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,710.0480000000005,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,713.0880000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.168,716.2560000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.272,726.5280000000005,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.2,741.7280000000005,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,744.2560000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.216,749.4720000000005,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.8,766.2720000000005,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",140,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,768.8000000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",141,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.72,771.5200000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",142,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,774.0800000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,776.6720000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",144,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,779.2000000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",145,36474.0,89844.0,1536.0,0,0.0,91380.0,91380.0,0.0,96.0,0.0,24576.0,24576.0,2.624,781.8240000000005,6144.0,12288.0,35706.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,784.3520000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",147,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,786.9440000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),148,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.056,804.0000000000006,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.552,807.5520000000006,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,810.1120000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.28,815.3920000000005,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.16,831.5520000000005,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,834.5920000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.072,837.6640000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.136,840.8000000000004,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.304,851.1040000000004,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.072,866.1760000000004,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,868.7360000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,873.8240000000003,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.832,890.6560000000003,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,893.1840000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",162,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,895.7440000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",163,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,898.2720000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.848,901.1200000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",165,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,903.6480000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,36458.0,89812.0,1536.0,0,0.0,91348.0,91348.0,0.0,96.0,0.0,24576.0,24576.0,2.688,906.3360000000002,6144.0,12288.0,35690.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",167,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.656,908.9920000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",168,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,911.5840000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),169,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.64,928.2240000000002,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.488,931.7120000000002,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,934.3040000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,939.3280000000002,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.096,955.4240000000002,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,958.4320000000002,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,961.4720000000002,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,964.4800000000002,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,49152.0,1731072.0,0.0,0,0.0,1731072.0,1731072.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,10.464,974.9440000000003,1333248.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.912,989.8560000000003,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,992.5120000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,997.5360000000003,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.672,1014.2080000000003,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1016.7680000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1019.3920000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,1022.0480000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,1024.6080000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1027.1680000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,36536.0,89968.0,1536.0,0,0.0,91504.0,91504.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1029.7920000000001,6144.0,12288.0,35768.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1032.352,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,1035.008,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),190,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.832,1051.8400000000001,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.52,1055.3600000000001,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1057.92,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,4.96,1062.88,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,81215424.0,170473088.0,8041344.0,0,0.0,178514432.0,178514432.0,1884696.0,1558034.0,0.5474422914373186,177353600.0,553632.0,174.048,1236.928,6432896.0,9650688.0,77194752.0,4020672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5542300.0,17301.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,1238.9440000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.56,1241.5040000000001,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1243.9360000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,101376.0,0.0,0,0.0,101376.0,101376.0,0.0,1580.0,0.0,402080.0,402080.0,2.976,1246.9120000000003,0.0,101376.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.176,1249.0880000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,151202.0,0.0,302404.0,0,0.0,302404.0,302404.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,3.936,1253.0240000000001,0.0,0.0,0.0,151202.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,86400.0,0.0,172800.0,0,0.0,172800.0,172800.0,6600.0,41304.0,0.1377755511022044,2466176.0,0.0,6.016,1259.0400000000002,0.0,0.0,0.0,86400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,50856.0,0.0,101712.0,0,0.0,101712.0,101712.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,3.968,1263.0080000000003,0.0,0.0,0.0,50856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,105600.0,0.0,211200.0,0,0.0,211200.0,211200.0,6600.0,41904.0,0.13607125185551708,2466176.0,0.0,5.824,1268.8320000000003,0.0,0.0,0.0,105600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,50694.0,0.0,101388.0,0,0.0,101388.0,101388.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,3.968,1272.8000000000004,0.0,0.0,0.0,50694.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,6600.0,41804.0,0.13635236757292785,2466176.0,0.0,6.144,1278.9440000000004,0.0,0.0,0.0,102400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,50690.0,0.0,101380.0,0,0.0,101380.0,101380.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,4.128,1283.0720000000003,0.0,0.0,0.0,50690.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,92800.0,0.0,185600.0,0,0.0,185600.0,185600.0,6600.0,41504.0,0.13720272742391484,2466176.0,64.0,5.824,1288.8960000000004,0.0,0.0,0.0,92800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,556.0,0.0,1112.0,0,0.0,1112.0,1112.0,0.0,12.0,0.0,3232.0,416.0,3.2,1292.0960000000005,0.0,0.0,0.0,556.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1294.1760000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,416.0,0.0,4.48,1298.6560000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1300.7040000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,416.0,0.0,4.384,1305.0880000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,126664.0,0.0,253328.0,0,0.0,253328.0,253328.0,28700.0,6506.0,0.8152019542123502,415584.0,4320.0,5.92,1311.0080000000005,0.0,0.0,0.0,126664.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12987.0,135.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.432,1317.4400000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,407232.0,25152.0,4.16,1321.6000000000006,0.0,0.0,0.0,201028.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12726.0,786.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,12672.0,0.0,25344.0,0,0.0,25344.0,25344.0,0.0,2370.0,0.0,502624.0,0.0,3.104,1324.7040000000006,0.0,0.0,0.0,12672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,0.0,3142.0,0.0,0.0,804128.0,3.072,1327.7760000000005,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,387467.0,0.0,774934.0,0,0.0,774934.0,774934.0,64512.0,3142.0,0.9535578088509179,402080.0,0.0,4.128,1331.9040000000005,0.0,0.0,0.0,387467.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.56,1334.4640000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,94464.0,0.0,188928.0,0,0.0,188928.0,188928.0,32883.0,13860.0,0.7034850137988575,1324352.0,963872.0,15.584,1350.0480000000005,0.0,0.0,0.0,94464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41386.0,30121.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,7799.0,13710.0,0.36259240318006414,1320640.0,1225664.0,12.736,1362.7840000000006,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41270.0,38302.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,35712.0,0.0,71424.0,0,0.0,71424.0,71424.0,9015.0,13811.0,0.39494436169280644,1315008.0,1225920.0,13.888,1376.6720000000005,0.0,0.0,0.0,35712.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41094.0,38310.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,35712.0,0.0,71424.0,0,0.0,71424.0,71424.0,9015.0,13651.0,0.39773228624371304,1314752.0,1085792.0,13.952,1390.6240000000005,0.0,0.0,0.0,35712.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41086.0,33931.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,3142.0,0.7496414342629482,804128.0,0.0,4.096,1394.7200000000005,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,1397.3440000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,21138.0,0.0,42276.0,0,0.0,42276.0,42276.0,7422.0,7278.0,0.5048979591836734,903200.0,690816.0,7.424,1404.7680000000005,0.0,0.0,0.0,21138.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28225.0,21588.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,301892.0,0.0,603784.0,0,0.0,603784.0,603784.0,0.0,12568.0,0.0,1214432.0,1206208.0,4.032,1408.8000000000004,0.0,0.0,0.0,301892.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37951.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,1641054.0,3327522.0,467716.0,0,0.0,3795238.0,3795238.0,264.0,3352.0,0.07300884955752213,1141568.0,375488.0,25.344,1434.1440000000005,412616.0,100514.0,1407196.0,233858.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,35674.0,11734.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,105472.0,512100.0,210944.0,0,0.0,723044.0,723044.0,56142.0,6284.0,0.8993368147887099,402240.0,325408.0,77.568,1511.7120000000004,512100.0,0.0,0.0,105472.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12570.0,10169.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,1580.0,0.0,402080.0,100416.0,2.944,1514.6560000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.144,1516.8000000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,301542.0,0.0,603084.0,0,0.0,603084.0,603084.0,0.0,9426.0,0.0,904672.0,38528.0,9.28,1526.0800000000004,0.0,0.0,0.0,301542.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28271.0,1204.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,12672.0,0.0,25344.0,0,0.0,25344.0,25344.0,0.0,2370.0,0.0,502624.0,0.0,3.456,1529.5360000000003,0.0,0.0,0.0,12672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,1641060.0,3327522.0,467728.0,0,0.0,3795250.0,3795250.0,264.0,3352.0,0.07300884955752213,1136960.0,375488.0,25.472,1555.0080000000003,412616.0,100514.0,1407196.0,233864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,35530.0,11734.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,23.808,1578.8160000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,1581.2480000000003,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,23.648,1604.8960000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,1607.4240000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.688,1610.1120000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,1613.4080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,4096.0,110114.0,8192.0,0,0.0,118306.0,118306.0,152.0,791.0,0.16118769883351008,402112.0,64.0,13.472,1626.8800000000003,110114.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.4,1629.2800000000004,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.296,1632.5760000000005,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,1635.0720000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,1638.3040000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,1408512.0,2011972.0,1006080.0,0,0.0,3018052.0,3018052.0,0.0,3142.0,0.0,0.0,402080.0,4.064,1642.3680000000006,0.0,201028.0,905472.0,503040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,608546.0,1013760.0,203332.0,0,0.0,1217092.0,1217092.0,0.0,2370.0,0.0,804160.0,0.0,4.384,1646.7520000000006,0.0,0.0,506880.0,101666.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,55377.0,0.0,110754.0,0,0.0,110754.0,110754.0,304.0,791.0,0.2776255707762557,402112.0,64.0,17.728,1664.4800000000007,0.0,0.0,0.0,55377.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.368,1666.8480000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1669.2800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.496,1671.7760000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,1674.2400000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.464,1676.7040000000006,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,1678.7520000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,1680.8000000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.72,1683.5200000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.016,1685.5360000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.56,1688.0960000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,3.0,0.0,32.0,32.0,4.288,1692.3840000000007,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.528,1694.9120000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,1697.3120000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.072,1700.3840000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.168,1703.5520000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.656,1706.2080000000005,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,1708.7360000000006,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,3.0,0.0,64.0,32.0,3.232,1711.9680000000005,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.88,1714.8480000000006,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,1717.2480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,1719.6800000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.432,1722.1120000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,1724.5760000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,3.616,1728.1920000000007,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,3264.0,6144.0,3.264,1731.4560000000006,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1734.0160000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,1736.4480000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,1739.7120000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.12,1744.8320000000003,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.096,1760.9280000000003,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.712,1764.6400000000003,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1768.2880000000002,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.104,1771.3920000000003,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.4,1781.7920000000004,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.944,1796.7360000000003,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1799.2960000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,4.928,1804.2240000000004,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.896,1821.1200000000003,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",287,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1823.6800000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",288,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.592,1826.2720000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",289,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.496,1828.7680000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.688,1831.4560000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.688,1834.1440000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",292,36523.0,89942.0,1536.0,0,0.0,91478.0,91478.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1836.7680000000007,6144.0,12288.0,35755.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.496,1839.2640000000008,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",294,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,1841.8240000000008,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),295,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.184,1859.0080000000007,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.488,1862.4960000000008,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1865.0880000000009,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,1870.1120000000008,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",299,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.032,1886.1440000000007,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1889.7920000000006,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1893.4400000000005,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,1896.4800000000005,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.464,1906.9440000000004,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",304,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.2,1922.1440000000005,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1924.7040000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",306,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,1929.7280000000003,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",307,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.8,1946.5280000000002,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,1949.1840000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",309,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.72,1951.9040000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.592,1954.4960000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1957.0880000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1959.7120000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,36496.0,89888.0,1536.0,0,0.0,91424.0,91424.0,0.0,96.0,0.0,24576.0,24576.0,2.624,1962.3360000000005,6144.0,12288.0,35728.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",314,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1964.8960000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",315,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1967.4880000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),316,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.28,1984.7680000000005,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",317,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.648,1988.4160000000004,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,1991.0720000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.12,1996.1920000000002,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",320,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.872,2012.0640000000003,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2015.7120000000002,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2019.3600000000001,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,2022.4,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.368,2032.768,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",325,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.136,2047.904,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2050.464,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,2055.488,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",328,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.672,2072.16,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2074.6879999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.656,2077.3439999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2079.9039999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2082.4959999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2085.0559999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,36518.0,89932.0,1536.0,0,0.0,91468.0,91468.0,0.0,96.0,0.0,24576.0,24576.0,2.688,2087.7439999999997,6144.0,12288.0,35750.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2090.2719999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.72,2092.9919999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),337,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.12,2110.111999999999,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.488,2113.599999999999,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,2116.191999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,4.992,2121.1839999999993,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",341,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.512,2137.6959999999995,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.744,2141.4399999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.616,2145.0559999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.04,2148.0959999999995,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.24,2158.3359999999993,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.912,2173.247999999999,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.688,2175.9359999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,2180.9919999999993,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.928,2197.919999999999,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.496,2200.4159999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2202.943999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2205.471999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2208.063999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2210.623999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,36469.0,89834.0,1536.0,0,0.0,91370.0,91370.0,0.0,96.0,0.0,24576.0,24576.0,2.656,2213.279999999999,6144.0,12288.0,35701.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2215.8079999999986,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2218.3999999999987,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),358,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.96,2235.3599999999988,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.584,2238.9439999999986,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2241.5039999999985,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.248,2246.7519999999986,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.512,2263.2639999999988,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2266.9439999999986,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2270.5919999999987,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.072,2273.663999999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.304,2283.967999999999,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.976,2298.943999999999,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,2301.599999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.024,2306.623999999999,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",370,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.544,2323.1679999999988,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",371,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2325.6959999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",372,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.592,2328.2879999999986,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,2330.9119999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",374,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,2333.5359999999982,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.496,2336.0319999999983,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,36444.0,89784.0,1536.0,0,0.0,91320.0,91320.0,0.0,96.0,0.0,24576.0,24576.0,2.688,2338.7199999999984,6144.0,12288.0,35676.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",377,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2341.2479999999982,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2343.8399999999983,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),379,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.992,2360.8319999999985,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.52,2364.3519999999985,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,2366.9439999999986,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,4.992,2371.935999999999,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.0,2387.935999999999,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2391.583999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2395.231999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.104,2398.335999999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.304,2408.639999999999,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",388,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.392,2424.031999999999,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2426.5919999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",390,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,2431.679999999999,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,17.024,2448.703999999999,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,2451.3599999999988,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",393,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2453.9199999999987,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2456.4479999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2459.0399999999986,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.72,2461.7599999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,36462.0,89820.0,1536.0,0,0.0,91356.0,91356.0,0.0,96.0,0.0,24576.0,24576.0,2.656,2464.4159999999983,6144.0,12288.0,35694.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.496,2466.9119999999984,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",399,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2469.5039999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),400,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,16.992,2486.4959999999987,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",401,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.488,2489.9839999999986,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,2492.6399999999985,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,2497.7279999999987,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,15.904,2513.6319999999987,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2517.3119999999985,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.744,2521.0559999999987,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.2,2524.2559999999985,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.304,2534.5599999999986,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,15.36,2549.9199999999987,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2552.4799999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",411,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,2557.5359999999987,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.608,2574.143999999999,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2576.703999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",414,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2579.2639999999988,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",415,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,2581.7919999999986,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,2584.4479999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",417,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2587.0079999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,36513.0,89922.0,1536.0,0,0.0,91458.0,91458.0,0.0,96.0,0.0,24576.0,24576.0,2.656,2589.6639999999984,6144.0,12288.0,35745.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.688,2592.3519999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,2595.0079999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),421,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.088,2612.0959999999986,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",422,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.584,2615.6799999999985,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2618.2399999999984,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,2623.2959999999985,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,3575808.0,7188480.0,73728.0,0,0.0,7262208.0,7262208.0,32544.0,57456.0,0.3616,7308288.0,18432.0,16.064,2639.3599999999983,55296.0,55296.0,3538944.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2643.0079999999984,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2646.6879999999983,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,96.0,0.0,6144.0,6144.0,3.008,2649.695999999998,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,49152.0,1732608.0,0.0,0,0.0,1732608.0,1732608.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,10.208,2659.903999999998,1334784.0,299520.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,1191936.0,2396160.0,24576.0,0,0.0,2420736.0,2420736.0,10848.0,19152.0,0.3616,2436096.0,6144.0,14.88,2674.7839999999983,18432.0,18432.0,1179648.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2677.3439999999982,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.056,2682.3999999999983,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",433,4767744.0,9584640.0,98304.0,0,0.0,9682944.0,9682944.0,43392.0,76608.0,0.3616,9744384.0,24576.0,16.96,2699.3599999999983,73728.0,73728.0,4718592.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.592,2701.9519999999984,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2704.5119999999984,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2707.0719999999983,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,2709.7279999999982,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2712.287999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,36501.0,89898.0,1536.0,0,0.0,91434.0,91434.0,0.0,96.0,0.0,24576.0,24576.0,2.72,2715.007999999998,6144.0,12288.0,35733.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2717.567999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.752,2720.319999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),442,75546624.0,151781376.0,98304.0,0,0.0,151879680.0,151879680.0,272640.0,1536.0,0.9943977591036415,9584640.0,196608.0,17.056,2737.375999999998,0.0,786432.0,75497472.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,299520.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,15360.0,52224.0,30720.0,0,0.0,82944.0,82944.0,0.0,2064.0,0.0,199680.0,6144.0,3.552,2740.927999999998,50688.0,1536.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6240.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2743.455999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,12450.0,43386.0,1536.0,0,0.0,44922.0,44922.0,34.0,136.0,0.2,18432.0,6272.0,5.088,2748.543999999998,12056.0,7966.0,11682.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,196.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,81215424.0,170473088.0,8041344.0,0,0.0,178514432.0,178514432.0,1884696.0,1558034.0,0.5474422914373186,177727616.0,559456.0,174.112,2922.655999999998,6432896.0,9650688.0,77194752.0,4020672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5553988.0,17483.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2924.703999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.496,2927.199999999998,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2929.631999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,101376.0,0.0,0,0.0,101376.0,101376.0,0.0,1580.0,0.0,402080.0,402080.0,2.88,2932.511999999998,0.0,101376.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2934.527999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,151202.0,0.0,302404.0,0,0.0,302404.0,302404.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,4.0,2938.527999999998,0.0,0.0,0.0,151202.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,86400.0,0.0,172800.0,0,0.0,172800.0,172800.0,6600.0,41304.0,0.1377755511022044,2466176.0,0.0,6.08,2944.607999999998,0.0,0.0,0.0,86400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,50894.0,0.0,101788.0,0,0.0,101788.0,101788.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,3.904,2948.511999999998,0.0,0.0,0.0,50894.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,105600.0,0.0,211200.0,0,0.0,211200.0,211200.0,6600.0,41904.0,0.13607125185551708,2466176.0,0.0,6.08,2954.591999999998,0.0,0.0,0.0,105600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,50696.0,0.0,101392.0,0,0.0,101392.0,101392.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,4.224,2958.815999999998,0.0,0.0,0.0,50696.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,6600.0,41604.0,0.13691809808314662,2466176.0,0.0,5.888,2964.703999999998,0.0,0.0,0.0,96000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,50690.0,0.0,101380.0,0,0.0,101380.0,101380.0,1600.0,4742.0,0.2522863450015768,406368.0,25600.0,3.904,2968.607999999998,0.0,0.0,0.0,50690.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12699.0,800.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,92800.0,0.0,185600.0,0,0.0,185600.0,185600.0,6600.0,41504.0,0.13720272742391484,2466176.0,64.0,5.952,2974.559999999998,0.0,0.0,0.0,92800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77068.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,556.0,0.0,1112.0,0,0.0,1112.0,1112.0,0.0,12.0,0.0,3232.0,416.0,3.104,2977.663999999998,0.0,0.0,0.0,556.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,2979.8079999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,416.0,0.0,4.288,2984.0959999999977,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,2986.1759999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,416.0,0.0,4.288,2990.4639999999977,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,126664.0,0.0,253328.0,0,0.0,253328.0,253328.0,21566.0,6500.0,0.7684030499536806,415584.0,4320.0,5.888,2996.3519999999976,0.0,0.0,0.0,126664.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12987.0,135.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.176,3002.5279999999975,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,407232.0,25152.0,4.416,3006.9439999999977,0.0,0.0,0.0,201028.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12726.0,786.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,12672.0,0.0,25344.0,0,0.0,25344.0,25344.0,0.0,2370.0,0.0,502624.0,0.0,3.232,3010.1759999999977,0.0,0.0,0.0,12672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,0.0,3142.0,0.0,0.0,804128.0,3.072,3013.247999999998,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,387467.0,0.0,774934.0,0,0.0,774934.0,774934.0,64512.0,3142.0,0.9535578088509179,402080.0,0.0,4.0,3017.247999999998,0.0,0.0,0.0,387467.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,3019.839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,94464.0,0.0,188928.0,0,0.0,188928.0,188928.0,32883.0,13908.0,0.7027633519266525,1320128.0,924064.0,15.264,3035.103999999998,0.0,0.0,0.0,94464.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41254.0,28877.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,7799.0,13786.0,0.3613157285151726,1321152.0,1225664.0,13.024,3048.127999999998,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41286.0,38302.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,35712.0,0.0,71424.0,0,0.0,71424.0,71424.0,9015.0,13741.0,0.3961592547020566,1315648.0,1226304.0,13.952,3062.079999999998,0.0,0.0,0.0,35712.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41114.0,38322.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,35712.0,0.0,71424.0,0,0.0,71424.0,71424.0,9015.0,13765.0,0.3957418788410887,1316544.0,1086048.0,14.272,3076.351999999998,0.0,0.0,0.0,35712.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,41142.0,33939.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,3142.0,0.7496414342629482,804128.0,0.0,4.256,3080.607999999998,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,3083.167999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,21138.0,0.0,42276.0,0,0.0,42276.0,42276.0,7422.0,7337.0,0.5028795988888136,902432.0,691904.0,7.168,3090.335999999998,0.0,0.0,0.0,21138.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28201.0,21622.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,301892.0,0.0,603784.0,0,0.0,603784.0,603784.0,0.0,12568.0,0.0,1214688.0,1206208.0,4.064,3094.399999999998,0.0,0.0,0.0,301892.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37959.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,1641054.0,3327522.0,467716.0,0,0.0,3795238.0,3795238.0,264.0,3352.0,0.07300884955752213,1143104.0,376128.0,25.216,3119.6159999999977,412616.0,100514.0,1407196.0,233858.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,35722.0,11754.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,105472.0,512100.0,210944.0,0,0.0,723044.0,723044.0,56142.0,6284.0,0.8993368147887099,402176.0,327712.0,78.848,3198.4639999999977,512100.0,0.0,0.0,105472.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12568.0,10241.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,1580.0,0.0,402080.0,100416.0,2.976,3201.439999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.272,3203.7119999999977,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,301542.0,0.0,603084.0,0,0.0,603084.0,603084.0,0.0,9426.0,0.0,904672.0,38560.0,9.088,3212.799999999998,0.0,0.0,0.0,301542.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28271.0,1205.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,12672.0,0.0,25344.0,0,0.0,25344.0,25344.0,0.0,2370.0,0.0,502624.0,0.0,3.36,3216.159999999998,0.0,0.0,0.0,12672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,1641059.0,3327522.0,467726.0,0,0.0,3795248.0,3795248.0,264.0,3352.0,0.07300884955752213,1140288.0,376640.0,25.568,3241.7279999999982,412616.0,100514.0,1407196.0,233863.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,35634.0,11770.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,23.52,3265.2479999999982,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,3267.679999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,23.744,3291.423999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.592,3294.0159999999983,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,3296.575999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,3299.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,4096.0,110114.0,8192.0,0,0.0,118306.0,118306.0,152.0,791.0,0.16118769883351008,402112.0,64.0,13.44,3313.311999999998,110114.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.432,3315.743999999998,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.36,3319.103999999998,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.56,3321.663999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.136,3324.799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,1408512.0,2011972.0,1006080.0,0,0.0,3018052.0,3018052.0,0.0,3142.0,0.0,0.0,402080.0,3.808,3328.607999999998,0.0,201028.0,905472.0,503040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,608545.0,1013760.0,203330.0,0,0.0,1217090.0,1217090.0,0.0,2370.0,0.0,804160.0,0.0,4.384,3332.991999999998,0.0,0.0,506880.0,101665.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,55377.0,0.0,110754.0,0,0.0,110754.0,110754.0,304.0,791.0,0.2776255707762557,402176.0,64.0,17.696,3350.687999999998,0.0,0.0,0.0,55377.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12568.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,3353.1199999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,3355.5519999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.496,3358.0479999999975,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,3360.5119999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.496,3363.0079999999975,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,3365.0559999999973,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.08,3367.1359999999972,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.528,3369.663999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,3371.711999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,96.0,32.0,2.528,3374.2399999999966,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,3.0,0.0,32.0,32.0,4.16,3378.3999999999965,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.496,3380.8959999999965,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,3383.3279999999963,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.04,3386.3679999999963,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.168,3389.5359999999964,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,3391.9999999999964,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
