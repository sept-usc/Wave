Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,1.6,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.664,4.96,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.976,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.592,9.568,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,32.0,2.56,12.128,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,128.0,3.744,15.872,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.392,19.264,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,21.759999999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.176,23.936,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,25.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,28.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,31.008,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,33.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,35.903999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,176.0,16.0,0.9166666666666666,128.0,32.0,3.168,39.071999999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.432,41.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,128.0,32.0,2.56,44.064,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,0.0,2.56,46.624,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,3840.0,49152.0,7.872,54.496,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,120.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,3840.0,49152.0,7.52,62.016000000000005,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,120.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,64.64,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,128.0,32.0,2.432,67.072,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.424,70.49600000000001,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,75.52000000000001,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),26,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,78125.0,0.7235540772456255,9100192.0,412544.0,24.48,100.00000000000001,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284381.0,12892.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,103.07200000000002,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,106.20800000000001,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,109.28000000000002,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,21.312,130.592,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.552,146.144,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,148.768,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.056,153.824,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),34,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.784,168.608,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",35,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.904,172.512,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,175.456,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.88,178.33599999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,180.992,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.136,184.128,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.88,187.00799999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,292016.0,719200.0,12288.0,0,0.0,731488.0,731488.0,0.0,768.0,0.0,196608.0,196608.0,2.848,189.856,49152.0,98304.0,285872.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,192.512,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,195.456,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),44,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,325098.0,0.45611957078184756,12733600.0,734720.0,59.808,255.26399999999998,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397925.0,22960.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,257.952,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.96,262.912,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),47,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,78389.0,0.7228787884144251,9100352.0,414208.0,24.864,287.77599999999995,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284386.0,12944.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,290.78399999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.2,293.9839999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.168,297.15199999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.448,317.5999999999999,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",52,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,16.096,333.6959999999999,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,336.31999999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.96,341.2799999999999,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),55,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.176,355.4559999999999,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",56,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.808,359.2639999999999,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,361.9199999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",58,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,364.6079999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,367.2959999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,370.5279999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,373.24799999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,291680.0,718528.0,12288.0,0,0.0,730816.0,730816.0,0.0,768.0,0.0,196608.0,196608.0,2.752,375.99999999999994,49152.0,98304.0,285536.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.72,378.71999999999997,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.072,381.792,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),65,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,324908.0,0.45626460133746577,12741344.0,733952.0,60.32,442.11199999999997,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,398167.0,22936.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,444.768,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.992,449.76,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),68,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76884.0,0.7267454258540538,9103136.0,411968.0,24.832,474.592,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284473.0,12874.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,477.728,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,480.736,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,483.74399999999997,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.544,504.28799999999995,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.488,519.776,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,522.4,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.96,527.36,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),76,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.304,541.664,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.776,545.4399999999999,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",78,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,548.064,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",79,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.912,550.976,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,553.664,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.848,556.512,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,559.232,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,291648.0,718464.0,12288.0,0,0.0,730752.0,730752.0,0.0,768.0,0.0,196608.0,196608.0,3.04,562.2719999999999,49152.0,98304.0,285504.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,564.9279999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",85,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,567.8399999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),86,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,331290.0,0.45144304803536833,12732576.0,723712.0,59.264,627.1039999999999,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397893.0,22616.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,629.824,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.248,635.072,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),89,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76752.0,0.7270865335381465,9099744.0,408704.0,24.608,659.68,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284367.0,12772.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.04,662.7199999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,665.8559999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,668.8639999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.416,689.28,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.616,704.896,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,707.52,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.12,712.64,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),97,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.304,726.944,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,4.096,731.04,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",99,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.752,733.7919999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",100,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,736.4479999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",101,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,739.1039999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,742.3039999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,744.9279999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",104,291936.0,719040.0,12288.0,0,0.0,731328.0,731328.0,0.0,768.0,0.0,196608.0,196608.0,2.784,747.7119999999999,49152.0,98304.0,285792.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",105,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,750.3999999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",106,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.88,753.2799999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),107,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,324355.0,0.45668724193669963,12738880.0,754560.0,59.904,813.1839999999999,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,398090.0,23580.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,815.8399999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.28,821.1199999999998,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),110,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76838.0,0.7268642603743806,9102560.0,434432.0,24.768,845.8879999999998,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284455.0,13576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,848.9599999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.04,851.9999999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,855.0719999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.384,875.4559999999998,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.648,891.1039999999998,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,893.9839999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.928,898.9119999999998,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),118,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.208,913.1199999999998,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.776,916.8959999999997,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",120,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,919.5839999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",121,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.752,922.3359999999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",122,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,925.0239999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",123,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,928.2879999999997,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,930.9759999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,291792.0,718752.0,12288.0,0,0.0,731040.0,731040.0,0.0,768.0,0.0,196608.0,196608.0,2.784,933.7599999999996,49152.0,98304.0,285648.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",126,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,936.4159999999996,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",127,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.88,939.2959999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),128,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,323795.0,0.4571160310846949,12734720.0,693632.0,59.936,999.2319999999996,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397960.0,21676.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.752,1001.9839999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.056,1007.0399999999996,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),131,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76968.0,0.7265285239191609,9100800.0,438400.0,24.992,1032.0319999999997,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284400.0,13700.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.04,1035.0719999999997,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,1038.2079999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,1041.2799999999995,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.48,1061.7599999999995,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.392,1077.1519999999996,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,1079.8079999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.12,1084.9279999999994,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),139,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.592,1099.5199999999995,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",140,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.84,1103.3599999999994,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",141,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1106.0159999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",142,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1108.6719999999993,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",143,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1111.3279999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.976,1114.3039999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",145,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,1116.9279999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,291792.0,718752.0,12288.0,0,0.0,731040.0,731040.0,0.0,768.0,0.0,196608.0,196608.0,2.816,1119.7439999999995,49152.0,98304.0,285648.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",147,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1122.3999999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",148,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.072,1125.4719999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),149,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,325623.0,0.45571930739490824,12739712.0,721536.0,60.0,1185.4719999999993,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,398116.0,22548.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,1188.1919999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.896,1193.0879999999993,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),152,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76673.0,0.7272908345278194,9099424.0,428928.0,24.64,1217.7279999999994,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284357.0,13404.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.168,1220.8959999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.04,1223.9359999999992,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.104,1227.0399999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.608,1247.6479999999992,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.328,1262.9759999999992,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,1265.5999999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.088,1270.6879999999992,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),160,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.4,1285.0879999999993,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.744,1288.8319999999992,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,1291.4559999999992,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",163,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,1294.1439999999993,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",164,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,1296.8319999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.072,1299.9039999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",166,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,1302.6239999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,291664.0,718496.0,12288.0,0,0.0,730784.0,730784.0,0.0,768.0,0.0,196608.0,196608.0,2.752,1305.3759999999993,49152.0,98304.0,285520.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.72,1308.0959999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",169,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,1311.0399999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),170,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,338054.0,0.44644289938987447,12719648.0,715392.0,61.408,1372.4479999999992,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397489.0,22356.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.816,1375.2639999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.992,1380.2559999999992,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),173,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76382.0,0.7280443776659,9100320.0,433792.0,24.64,1404.8959999999993,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284385.0,13556.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,1408.0319999999992,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,1411.1039999999991,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,1414.175999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.32,1434.495999999999,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.84,1450.3359999999989,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,1452.959999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.992,1457.9519999999989,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),181,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.336,1472.2879999999989,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",182,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.872,1476.159999999999,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1478.815999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",184,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,1481.4719999999988,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.816,1484.2879999999989,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",186,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,1487.2319999999988,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",187,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,1489.9519999999989,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,292288.0,719744.0,12288.0,0,0.0,732032.0,732032.0,0.0,768.0,0.0,196608.0,196608.0,2.752,1492.7039999999988,49152.0,98304.0,286144.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",189,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,1495.391999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,1498.303999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),191,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,332315.0,0.45067814961443414,12719392.0,704000.0,61.568,1559.871999999999,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397481.0,22000.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,1562.655999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.96,1567.615999999999,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),194,1239792384.0,2483810304.0,603648.0,0,0.0,2484413952.0,2484413952.0,3937860.0,128038.0,0.9685092936418965,180429024.0,3496288.0,270.176,1837.791999999999,0.0,4829184.0,1239490560.0,301824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5638407.0,109259.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.176,1839.967999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,272.0,0.0,544.0,0,0.0,544.0,544.0,0.0,6.0,0.0,256.0,512.0,2.528,1842.495999999999,0.0,0.0,0.0,272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1844.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,804864.0,0.0,0,0.0,804864.0,804864.0,0.0,12578.0,0.0,3216448.0,3216448.0,6.08,1851.007999999999,0.0,804864.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,100514.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.144,1853.151999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,1037584.0,0.0,2075168.0,0,0.0,2075168.0,2075168.0,7424.0,32560.0,0.18567426970788314,3235040.0,118784.0,7.232,1860.3839999999989,0.0,0.0,0.0,1037584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101095.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,400896.0,0.0,801792.0,0,0.0,801792.0,801792.0,30624.0,113712.0,0.21217159960093115,6916000.0,224.0,6.4,1866.783999999999,0.0,0.0,0.0,400896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216125.0,7.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,234816.0,0.0,469632.0,0,0.0,469632.0,469632.0,7424.0,32560.0,0.18567426970788314,3235104.0,118784.0,7.136,1873.919999999999,0.0,0.0,0.0,234816.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101097.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,489984.0,0.0,979968.0,0,0.0,979968.0,979968.0,30624.0,116496.0,0.20815660685154977,6920064.0,128.0,6.464,1880.3839999999989,0.0,0.0,0.0,489984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216252.0,4.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,233520.0,0.0,467040.0,0,0.0,467040.0,467040.0,7424.0,32560.0,0.18567426970788314,3235104.0,118784.0,7.232,1887.6159999999988,0.0,0.0,0.0,233520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101097.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,475136.0,0.0,950272.0,0,0.0,950272.0,950272.0,30624.0,116032.0,0.20881518655902248,6919232.0,256.0,6.56,1894.1759999999988,0.0,0.0,0.0,475136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216226.0,8.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,233488.0,0.0,466976.0,0,0.0,466976.0,466976.0,7424.0,32560.0,0.18567426970788314,3235136.0,118784.0,7.136,1901.3119999999988,0.0,0.0,0.0,233488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101098.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,430592.0,0.0,861184.0,0,0.0,861184.0,861184.0,30624.0,114640.0,0.21081616918162793,6917088.0,512.0,6.336,1907.6479999999988,0.0,0.0,0.0,430592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216159.0,16.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,1232.0,0.0,2464.0,0,0.0,2464.0,2464.0,0.0,45.0,0.0,14912.0,1856.0,3.616,1911.2639999999988,0.0,0.0,0.0,1232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,466.0,58.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1913.3119999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1856.0,0.0,4.704,1918.0159999999987,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1920.0959999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1856.0,0.0,4.608,1924.7039999999986,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,927296.0,0.0,1854592.0,0,0.0,1854592.0,1854592.0,229600.0,41296.0,0.8475577343334711,3276704.0,28704.0,10.144,1934.8479999999986,0.0,0.0,0.0,927296.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102397.0,897.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,6.336,1941.1839999999986,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,1608224.0,0.0,3216448.0,0,0.0,3216448.0,3216448.0,0.0,75387.0,0.0,3255360.0,201056.0,6.88,1948.0639999999987,0.0,0.0,0.0,1608224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101730.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,100608.0,0.0,201216.0,0,0.0,201216.0,201216.0,0.0,18867.0,0.0,4020576.0,37248.0,7.488,1955.5519999999988,0.0,0.0,0.0,100608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,125643.0,1164.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,2413088.0,0.0,4826176.0,0,0.0,4826176.0,4826176.0,0.0,25129.0,0.0,0.0,6432896.0,7.936,1963.4879999999987,0.0,0.0,0.0,2413088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,201028.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,390203.0,0.0,780406.0,0,0.0,780406.0,780406.0,64512.0,25129.0,0.7196706864046586,3216448.0,0.0,7.36,1970.8479999999986,0.0,0.0,0.0,390203.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.688,1973.5359999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,748416.0,0.0,1496832.0,0,0.0,1496832.0,1496832.0,260870.0,110820.0,0.7018483144555947,11086912.0,7495840.0,31.168,2004.7039999999986,0.0,0.0,0.0,748416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,346466.0,234245.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,234768.0,0.0,469536.0,0,0.0,469536.0,469536.0,51946.0,119083.0,0.30372626864449886,11114304.0,9804736.0,25.376,2030.0799999999986,0.0,0.0,0.0,234768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347322.0,306398.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,236928.0,0.0,473856.0,0,0.0,473856.0,473856.0,53078.0,120252.0,0.30622511971384064,11063872.0,9804864.0,27.232,2057.3119999999985,0.0,0.0,0.0,236928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,345746.0,306402.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,236928.0,0.0,473856.0,0,0.0,473856.0,473856.0,53078.0,120242.0,0.30624278790676207,11115200.0,9802944.0,26.656,2083.9679999999985,0.0,0.0,0.0,236928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347350.0,306342.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,25129.0,0.2724035092799027,6432896.0,0.0,10.432,2094.3999999999983,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201028.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,2096.9919999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,163340.0,0.0,326680.0,0,0.0,326680.0,326680.0,59342.0,68659.0,0.4636057530800541,7763328.0,5394048.0,16.768,2113.7599999999984,0.0,0.0,0.0,163340.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,242604.0,168564.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,2412576.0,0.0,4825152.0,0,0.0,4825152.0,4825152.0,0.0,100516.0,0.0,9714880.0,9649344.0,14.272,2128.0319999999983,0.0,0.0,0.0,2412576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303590.0,301542.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,13136624.0,26620176.0,3758112.0,0,0.0,30378288.0,30378288.0,2112.0,26816.0,0.07300884955752213,8704832.0,2901568.0,26.208,2154.2399999999984,3300928.0,804112.0,11257568.0,1879056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272026.0,90674.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,843776.0,4096800.0,1687552.0,0,0.0,5784352.0,5784352.0,449136.0,50272.0,0.8993368147887099,3218048.0,2084480.0,78.432,2232.671999999998,4096800.0,0.0,0.0,843776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100564.0,65140.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,12578.0,0.0,3216448.0,803936.0,5.92,2238.5919999999983,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,25123.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,2.144,2240.735999999998,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,2412336.0,0.0,4824672.0,0,0.0,4824672.0,4824672.0,0.0,75387.0,0.0,7237024.0,304096.0,12.416,2253.151999999998,0.0,0.0,0.0,2412336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,226157.0,9503.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,100608.0,0.0,201216.0,0,0.0,201216.0,201216.0,0.0,18867.0,0.0,4020576.0,20992.0,7.168,2260.3199999999983,0.0,0.0,0.0,100608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,125643.0,656.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,13136672.0,26620176.0,3758208.0,0,0.0,30378384.0,30378384.0,2112.0,26816.0,0.07300884955752213,8722784.0,2894656.0,26.048,2286.367999999998,3300928.0,804112.0,11257568.0,1879104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272587.0,90458.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,153600.0,0.0,307200.0,0,0.0,307200.0,307200.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.864,2295.231999999998,0.0,0.0,0.0,153600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2297.663999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,153600.0,0.0,307200.0,0,0.0,307200.0,307200.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,8.992,2306.655999999998,0.0,0.0,0.0,153600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2309.055999999998,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2311.679999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,2315.007999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,24576.0,877328.0,49152.0,0,0.0,926480.0,926480.0,736.0,6328.0,0.10419026047565119,3216896.0,512.0,13.088,2328.095999999998,877328.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100528.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,2.0,0.0,64.0,32.0,2.432,2330.527999999998,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.296,2333.823999999998,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,2336.319999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,2339.6159999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,2739472.0,4962848.0,2124320.0,0,0.0,7087168.0,7087168.0,0.0,25129.0,0.0,0.0,3216448.0,5.344,2344.9599999999978,0.0,1608224.0,1677312.0,1062160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,100514.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,4828816.0,8048640.0,1608992.0,0,0.0,9657632.0,9657632.0,0.0,18867.0,0.0,6432896.0,222208.0,10.592,2355.551999999998,0.0,0.0,4024320.0,804496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201028.0,6944.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,434824.0,0.0,869648.0,0,0.0,869648.0,869648.0,1472.0,6328.0,0.18871794871794872,3217088.0,512.0,17.12,2372.6719999999978,0.0,0.0,0.0,434824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100534.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.656,2375.3279999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.4,2377.727999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,2.656,2380.3839999999977,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.56,2382.9439999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,272.0,0.0,544.0,0,0.0,544.0,544.0,0.0,6.0,0.0,256.0,512.0,2.496,2385.439999999998,0.0,0.0,0.0,272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,2387.4879999999976,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.016,2389.5039999999976,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.496,2391.9999999999977,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,2394.0479999999975,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,288.0,32.0,2.496,2396.5439999999976,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,20.0,0.0,40.0,0,0.0,40.0,40.0,0.0,5.0,0.0,32.0,32.0,5.952,2402.495999999998,0.0,0.0,0.0,20.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.528,2405.0239999999976,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,2.496,2407.5199999999977,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,3.04,2410.5599999999977,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.232,2413.7919999999976,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2416.2239999999974,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2418.655999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,160.0,0.0,320.0,0,0.0,320.0,320.0,0.0,3.0,0.0,288.0,128.0,3.296,2421.951999999997,0.0,0.0,0.0,160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,176.0,16.0,0.9166666666666666,256.0,64.0,3.072,2425.023999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,2.496,2427.5199999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,256.0,32.0,2.464,2429.983999999997,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,288.0,0.0,2.496,2432.4799999999973,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,256.0,128.0,2.496,2434.9759999999974,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,40704.0,49152.0,11.008,2445.983999999997,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1272.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,13056.0,0.0,26112.0,0,0.0,26112.0,26112.0,0.0,1152.0,0.0,3840.0,49152.0,7.36,2453.3439999999973,0.0,0.0,0.0,13056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,120.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,2456.255999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,256.0,32.0,2.432,2458.687999999997,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,96.0,0.0,192.0,0,0.0,192.0,192.0,0.0,2.0,0.0,32.0,32.0,3.36,2462.047999999997,0.0,0.0,0.0,96.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.992,2467.0399999999972,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),278,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76741.0,0.7271149736328368,9101376.0,412704.0,24.672,2491.7119999999973,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284418.0,12897.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.712,2495.4239999999972,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.744,2499.1679999999974,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,2502.2399999999975,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.448,2522.6879999999974,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.424,2538.1119999999974,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,2540.735999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,2545.759999999997,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),286,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.144,2559.903999999997,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",287,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,4.0,2563.903999999997,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,2566.5599999999968,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",289,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.752,2569.3119999999967,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",290,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.88,2572.191999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,2575.135999999997,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,2577.7919999999967,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,292118.0,719404.0,12288.0,0,0.0,731692.0,731692.0,0.0,768.0,0.0,196608.0,196608.0,2.848,2580.6399999999967,49152.0,98304.0,285974.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",294,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.752,2583.3919999999966,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.976,2586.3679999999968,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),296,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,333068.0,0.4501178785817589,12712576.0,712832.0,60.736,2647.1039999999966,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397268.0,22276.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,2649.7919999999967,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,2654.8159999999966,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),299,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,77106.0,0.7261724659606656,9101408.0,419072.0,24.864,2679.6799999999967,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284419.0,13096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,2683.327999999997,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.68,2687.0079999999966,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.232,2690.2399999999966,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.512,2710.7519999999968,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",304,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.744,2726.495999999997,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.784,2729.279999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",306,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.056,2734.335999999997,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),307,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.08,2748.415999999997,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",308,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.808,2752.223999999997,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.752,2754.975999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",310,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,2757.631999999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",311,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.784,2760.415999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",312,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,2763.327999999997,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,2766.0479999999966,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,291808.0,718784.0,12288.0,0,0.0,731072.0,731072.0,0.0,768.0,0.0,196608.0,196608.0,2.752,2768.7999999999965,49152.0,98304.0,285664.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",315,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.72,2771.5199999999963,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",316,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,2774.4639999999963,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),317,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,328015.0,0.4539044876010355,12758784.0,742528.0,59.744,2834.2079999999964,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,398712.0,23204.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,2836.8639999999964,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.12,2841.9839999999963,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),320,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76749.0,0.7270942897069648,9102112.0,424096.0,24.672,2866.6559999999963,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284441.0,13253.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,2870.3039999999964,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.064,2874.3679999999963,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,2877.375999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.512,2897.8879999999963,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",325,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.264,2913.1519999999964,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.592,2915.7439999999965,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.056,2920.7999999999965,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),328,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.208,2935.0079999999966,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",329,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.808,2938.8159999999966,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",330,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,2941.5039999999967,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",331,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,2944.191999999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",332,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,2947.135999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.04,2950.1759999999967,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",334,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,2952.8319999999967,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,291977.0,719122.0,12288.0,0,0.0,731410.0,731410.0,0.0,768.0,0.0,196608.0,196608.0,2.784,2955.615999999997,49152.0,98304.0,285833.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",336,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.624,2958.2399999999966,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,2961.1839999999966,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),338,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,322592.0,0.458039890328477,12744640.0,745472.0,59.488,3020.6719999999964,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,398270.0,23296.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3023.295999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3028.319999999996,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),341,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76734.0,0.7271330730333483,9101760.0,415392.0,24.32,3052.6399999999962,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284430.0,12981.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.616,3056.255999999996,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,3059.9039999999964,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,3062.911999999996,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.544,3083.455999999996,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.424,3098.879999999996,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,3101.567999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3106.591999999996,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),349,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.112,3120.703999999996,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.84,3124.5439999999962,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,3127.263999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",352,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.72,3129.983999999996,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3132.639999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.072,3135.711999999996,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",355,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3138.367999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,291805.0,718778.0,12288.0,0,0.0,731066.0,731066.0,0.0,768.0,0.0,196608.0,196608.0,3.04,3141.407999999996,49152.0,98304.0,285661.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3144.0639999999958,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,3147.2639999999956,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),359,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,328939.0,0.4532073094306816,12717792.0,705408.0,60.992,3208.2559999999958,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397431.0,22044.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,3210.943999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.12,3216.0639999999958,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),362,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,77653.0,0.7247645613948032,9100288.0,396672.0,24.768,3240.831999999996,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284384.0,12396.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,3244.479999999996,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.68,3248.1599999999958,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.136,3251.2959999999957,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.8,3272.095999999996,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.488,3287.5839999999957,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3290.175999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.056,3295.231999999996,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),370,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.208,3309.439999999996,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.776,3313.215999999996,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,3315.903999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",373,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,3318.9119999999957,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3321.5359999999955,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,3324.4479999999953,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3327.1039999999953,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,291863.0,718894.0,12288.0,0,0.0,731182.0,731182.0,0.0,768.0,0.0,196608.0,196608.0,2.752,3329.855999999995,49152.0,98304.0,285719.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",378,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,3332.5439999999953,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.008,3335.551999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),380,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,333841.0,0.44954417368392413,12707680.0,712832.0,60.032,3395.5839999999953,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397115.0,22276.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3398.2399999999952,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.12,3403.359999999995,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),383,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,76736.0,0.7271279016841147,9101856.0,411776.0,24.608,3427.9679999999953,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284433.0,12868.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.616,3431.5839999999953,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.68,3435.263999999995,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.008,3438.271999999995,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.48,3458.751999999995,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",388,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.52,3474.271999999995,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3476.8959999999947,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",390,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3481.9199999999946,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),391,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.528,3496.4479999999944,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",392,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.808,3500.2559999999944,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.784,3503.0399999999945,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",394,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.752,3505.7919999999945,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3508.4479999999944,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.008,3511.455999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,3514.1439999999943,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,291736.0,718640.0,12288.0,0,0.0,730928.0,730928.0,0.0,768.0,0.0,196608.0,196608.0,2.752,3516.8959999999943,49152.0,98304.0,285592.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3519.551999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",400,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,2.816,3522.367999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),401,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,339109.0,0.44567298025824315,12716096.0,718336.0,61.216,3583.583999999994,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397378.0,22448.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.688,3586.271999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,4.992,3591.263999999994,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),404,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,77979.0,0.7239280745170096,9097984.0,412480.0,24.32,3615.5839999999944,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284312.0,12890.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.68,3619.263999999994,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,3622.9119999999944,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.072,3625.9839999999945,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.64,3646.6239999999943,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.296,3661.919999999994,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3664.543999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",411,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3669.567999999994,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),412,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.336,3683.9039999999936,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",413,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.904,3687.8079999999936,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.72,3690.5279999999934,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",415,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.784,3693.3119999999935,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",416,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3695.9359999999933,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.944,3698.8799999999933,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3701.503999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,292209.0,719586.0,12288.0,0,0.0,731874.0,731874.0,0.0,768.0,0.0,196608.0,196608.0,2.816,3704.319999999993,49152.0,98304.0,286065.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",420,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3706.9439999999927,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",421,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.04,3709.9839999999926,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),422,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,323339.0,0.4574657831903473,12718848.0,670336.0,60.416,3770.399999999993,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397464.0,20948.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.72,3773.1199999999926,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.088,3778.207999999993,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),425,57249792.0,115015680.0,73728.0,0,0.0,115089408.0,115089408.0,204480.0,77891.0,0.7241536843372726,9099200.0,409088.0,24.672,3802.879999999993,0.0,589824.0,57212928.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,284350.0,12784.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.712,3806.591999999993,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,3.648,3810.239999999993,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.168,3813.407999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.512,3833.9199999999933,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,9486336.0,19169280.0,98304.0,0,0.0,19267584.0,19267584.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,15.52,3849.4399999999932,147456.0,147456.0,9437184.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3852.095999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3857.119999999993,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),433,75515904.0,151289856.0,36864.0,0,0.0,151326720.0,151326720.0,240480.0,4608.0,0.981198589894242,10616832.0,589824.0,14.208,3871.327999999993,0.0,294912.0,75497472.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331776.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",434,147456.0,245760.0,294912.0,0,0.0,540672.0,540672.0,0.0,10752.0,0.0,602112.0,196608.0,3.84,3875.1679999999933,196608.0,49152.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.752,3877.9199999999933,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",436,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.688,3880.6079999999934,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.624,3883.231999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,2.912,3886.143999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.688,3888.831999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,292042.0,719252.0,12288.0,0,0.0,731540.0,731540.0,0.0,768.0,0.0,196608.0,196608.0,2.752,3891.583999999993,49152.0,98304.0,285898.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",441,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.656,3894.239999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",442,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.04,3897.279999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),443,76333056.0,153354240.0,98304.0,0,0.0,153452544.0,153452544.0,272640.0,327197.0,0.45452347887842864,12730048.0,708096.0,60.896,3958.175999999993,0.0,786432.0,76283904.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,397814.0,22128.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.656,3960.831999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,99600.0,347088.0,12288.0,0,0.0,359376.0,359376.0,272.0,1088.0,0.2,147456.0,50176.0,5.024,3965.855999999993,96448.0,63728.0,93456.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1568.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),446,1239792384.0,2483810304.0,603648.0,0,0.0,2484413952.0,2484413952.0,3937860.0,128038.0,0.9685092936418965,180433248.0,3518688.0,270.176,4236.031999999993,0.0,4829184.0,1239490560.0,301824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5638539.0,109959.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.048,4238.079999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,280.0,0.0,560.0,0,0.0,560.0,560.0,0.0,6.0,0.0,384.0,640.0,2.592,4240.671999999992,0.0,0.0,0.0,280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4243.103999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,804864.0,0.0,0,0.0,804864.0,804864.0,0.0,12578.0,0.0,3216448.0,3216448.0,6.24,4249.343999999992,0.0,804864.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,100514.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.08,4251.423999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,1037584.0,0.0,2075168.0,0,0.0,2075168.0,2075168.0,7424.0,32560.0,0.18567426970788314,3235008.0,118784.0,7.456,4258.879999999992,0.0,0.0,0.0,1037584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101094.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,400896.0,0.0,801792.0,0,0.0,801792.0,801792.0,30624.0,113712.0,0.21217159960093115,6916320.0,256.0,6.464,4265.343999999992,0.0,0.0,0.0,400896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216135.0,8.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,234856.0,0.0,469712.0,0,0.0,469712.0,469712.0,7424.0,32560.0,0.18567426970788314,3234880.0,118784.0,7.232,4272.575999999992,0.0,0.0,0.0,234856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101090.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,489984.0,0.0,979968.0,0,0.0,979968.0,979968.0,30624.0,116496.0,0.20815660685154977,6918816.0,224.0,6.528,4279.103999999992,0.0,0.0,0.0,489984.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216213.0,7.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,233539.0,0.0,467078.0,0,0.0,467078.0,467078.0,7424.0,32560.0,0.18567426970788314,3234976.0,118784.0,7.488,4286.591999999992,0.0,0.0,0.0,233539.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101093.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,445440.0,0.0,890880.0,0,0.0,890880.0,890880.0,30624.0,115104.0,0.21014492753623187,6917600.0,64.0,6.368,4292.959999999993,0.0,0.0,0.0,445440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216175.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,233488.0,0.0,466976.0,0,0.0,466976.0,466976.0,7424.0,32560.0,0.18567426970788314,3234880.0,118784.0,7.136,4300.095999999993,0.0,0.0,0.0,233488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101090.0,3712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,437088.0,0.0,874176.0,0,0.0,874176.0,874176.0,30624.0,114843.0,0.21052197405597145,6917024.0,544.0,6.368,4306.463999999994,0.0,0.0,0.0,437088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,216157.0,17.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,1232.0,0.0,2464.0,0,0.0,2464.0,2464.0,0.0,45.0,0.0,14912.0,1856.0,3.616,4310.079999999994,0.0,0.0,0.0,1232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,466.0,58.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,4312.1599999999935,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1856.0,0.0,4.672,4316.831999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4318.879999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1856.0,0.0,4.608,4323.487999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,927296.0,0.0,1854592.0,0,0.0,1854592.0,1854592.0,181384.0,41272.0,0.8146378269617707,3276608.0,26240.0,9.888,4333.375999999993,0.0,0.0,0.0,927296.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102394.0,820.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,6.336,4339.711999999993,0.0,0.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,1608224.0,0.0,3216448.0,0,0.0,3216448.0,3216448.0,0.0,75387.0,0.0,3254880.0,201056.0,7.072,4346.783999999993,0.0,0.0,0.0,1608224.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,101715.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,100608.0,0.0,201216.0,0,0.0,201216.0,201216.0,0.0,18867.0,0.0,4020576.0,225664.0,7.232,4354.015999999993,0.0,0.0,0.0,100608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,125643.0,7052.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,2413088.0,0.0,4826176.0,0,0.0,4826176.0,4826176.0,0.0,25129.0,0.0,0.0,6432896.0,7.904,4361.919999999994,0.0,0.0,0.0,2413088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,201028.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,390176.0,0.0,780352.0,0,0.0,780352.0,780352.0,64512.0,25129.0,0.7196706864046586,3216448.0,0.0,7.136,4369.055999999994,0.0,0.0,0.0,390176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.752,4371.8079999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,748416.0,0.0,1496832.0,0,0.0,1496832.0,1496832.0,260870.0,111471.0,0.7006212047558555,11125952.0,7485856.0,31.264,4403.071999999995,0.0,0.0,0.0,748416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347686.0,233933.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,252048.0,0.0,504096.0,0,0.0,504096.0,504096.0,58966.0,121998.0,0.3258438142392962,11109184.0,6096128.0,26.016,4429.087999999994,0.0,0.0,0.0,252048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347162.0,190504.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,236928.0,0.0,473856.0,0,0.0,473856.0,473856.0,53078.0,118965.0,0.3085158942822434,11112256.0,9804480.0,27.008,4456.095999999994,0.0,0.0,0.0,236928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347258.0,306390.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,236928.0,0.0,473856.0,0,0.0,473856.0,473856.0,53078.0,119595.0,0.3073902694688805,11116352.0,9803456.0,27.52,4483.6159999999945,0.0,0.0,0.0,236928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,347386.0,306358.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,25129.0,0.2724035092799027,6432896.0,0.0,10.016,4493.631999999994,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201028.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,4496.255999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,163340.0,0.0,326680.0,0,0.0,326680.0,326680.0,59342.0,67008.0,0.4696636327661258,7746816.0,5396736.0,16.896,4513.151999999994,0.0,0.0,0.0,163340.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,242088.0,168648.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,2412576.0,0.0,4825152.0,0,0.0,4825152.0,4825152.0,0.0,100516.0,0.0,9717664.0,9649344.0,14.336,4527.487999999994,0.0,0.0,0.0,2412576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303677.0,301542.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,13136624.0,26620176.0,3758112.0,0,0.0,30378288.0,30378288.0,2112.0,26816.0,0.07300884955752213,8752352.0,2900672.0,26.048,4553.535999999994,3300928.0,804112.0,11257568.0,1879056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,273511.0,90646.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,843776.0,4096800.0,1687552.0,0,0.0,5784352.0,5784352.0,449136.0,50272.0,0.8993368147887099,3218816.0,2057056.0,79.392,4632.9279999999935,4096800.0,0.0,0.0,843776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100588.0,64283.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,12578.0,0.0,3216448.0,803936.0,6.048,4638.975999999993,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100514.0,25123.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,2.24,4641.215999999993,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,2412336.0,0.0,4824672.0,0,0.0,4824672.0,4824672.0,0.0,75387.0,0.0,7237024.0,306656.0,11.936,4653.151999999993,0.0,0.0,0.0,2412336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,226157.0,9583.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,100608.0,0.0,201216.0,0,0.0,201216.0,201216.0,0.0,18867.0,0.0,4020576.0,29696.0,7.2,4660.351999999993,0.0,0.0,0.0,100608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,125643.0,928.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,13136667.0,26620176.0,3758198.0,0,0.0,30378374.0,30378374.0,2112.0,26816.0,0.07300884955752213,8703040.0,2896064.0,25.6,4685.951999999993,3300928.0,804112.0,11257568.0,1879099.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,271970.0,90502.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,153600.0,0.0,307200.0,0,0.0,307200.0,307200.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,9.056,4695.0079999999925,0.0,0.0,0.0,153600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,4697.439999999992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,153600.0,0.0,307200.0,0,0.0,307200.0,307200.0,7883.0,6387.0,0.5524176594253679,3216864.0,3200.0,9.12,4706.559999999992,0.0,0.0,0.0,153600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100527.0,100.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,4709.0879999999925,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,4711.615999999993,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,4714.847999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,24576.0,877328.0,49152.0,0,0.0,926480.0,926480.0,736.0,6328.0,0.10419026047565119,3216896.0,512.0,13.152,4727.999999999993,877328.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100528.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,2.0,0.0,64.0,32.0,2.432,4730.4319999999925,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.424,4733.8559999999925,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,4736.319999999992,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4739.519999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,2739472.0,4962848.0,2124320.0,0,0.0,7087168.0,7087168.0,0.0,25129.0,0.0,0.0,3216448.0,5.312,4744.831999999992,0.0,1608224.0,1677312.0,1062160.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,100514.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,4828811.0,8048640.0,1608982.0,0,0.0,9657622.0,9657622.0,0.0,18867.0,0.0,6432896.0,546304.0,10.688,4755.519999999992,0.0,0.0,4024320.0,804491.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201028.0,17072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,434824.0,0.0,869648.0,0,0.0,869648.0,869648.0,1472.0,6328.0,0.18871794871794872,3217056.0,512.0,16.992,4772.511999999992,0.0,0.0,0.0,434824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,100533.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.432,4774.943999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.464,4777.407999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,2.496,4779.903999999992,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,2.432,4782.335999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,280.0,0.0,560.0,0,0.0,560.0,560.0,0.0,6.0,0.0,384.0,640.0,2.592,4784.927999999992,0.0,0.0,0.0,280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,4786.9759999999915,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.176,4789.151999999992,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.56,4791.711999999992,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,32.0,2.048,4793.759999999992,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,416.0,32.0,2.464,4796.223999999992,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,13.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,20.0,0.0,40.0,0,0.0,40.0,40.0,0.0,5.0,0.0,32.0,32.0,5.6,4801.823999999992,0.0,0.0,0.0,20.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,64.0,32.0,2.464,4804.287999999992,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,2.432,4806.719999999992,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,128.0,3.136,4809.8559999999925,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,3.328,4813.183999999993,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,4815.647999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
