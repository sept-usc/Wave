Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.952,3.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,5.984,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.336,8.32,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.04,11.36,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,14.207999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.776,17.983999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.712,21.695999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.848,24.543999999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.432,26.975999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.4,29.375999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.56,31.935999999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.296,35.23199999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,38.047999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,40.831999999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.36,44.19199999999999,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,46.943999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.72,49.663999999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.912,52.57599999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,8704.0,32768.0,4.608,57.18399999999999,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272.0,1024.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,8704.0,32768.0,4.576,61.75999999999999,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.784,64.544,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.72,67.264,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,4.064,71.328,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.264,78.592,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),26,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,64.992,143.584,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.376,148.96,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.68,152.64000000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.616,156.25600000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,159.80800000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,16.704,176.51200000000003,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),32,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.416,200.92800000000003,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",33,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.36,204.28800000000004,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,207.16800000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,214.46400000000003,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69925376.0,131072.0,81.216,295.68,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185168.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.104,298.784,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.008,301.792,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,304.70399999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.296,307.99999999999994,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,310.87999999999994,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,187240.0,464592.0,8192.0,0,0.0,472784.0,472784.0,0.0,512.0,0.0,131072.0,131072.0,3.104,313.9839999999999,32768.0,65536.0,183144.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.168,317.15199999999993,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,320.2559999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",45,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.592,466.84799999999996,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,469.69599999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",47,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.488,477.18399999999997,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),48,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.68,540.8639999999999,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",49,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.056,545.92,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,4.096,550.016,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,553.568,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.648,557.216,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",53,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,16.928,574.144,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),54,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.384,598.528,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",55,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.296,601.8240000000001,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",56,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,604.672,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",57,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,612.0640000000001,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69908864.0,131072.0,80.704,692.768,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184652.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,695.6800000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",60,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.848,698.528,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.04,701.568,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.136,704.704,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,707.584,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,187020.0,464152.0,8192.0,0,0.0,472344.0,472344.0,0.0,512.0,0.0,131072.0,131072.0,3.04,710.6239999999999,32768.0,65536.0,182924.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,713.5679999999999,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",66,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.136,716.7039999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.752,863.4559999999999,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,866.3039999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",69,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.424,873.7279999999998,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),70,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.04,936.7679999999998,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",71,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.024,941.7919999999998,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.744,945.5359999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,949.0879999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.744,952.8319999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",75,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.88,967.7119999999999,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),76,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.448,992.1599999999999,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.424,995.5839999999998,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,998.5599999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",79,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.264,1005.8239999999998,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",80,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69913216.0,131072.0,81.024,1086.848,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184788.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,1089.76,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",82,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,1092.672,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,1095.6480000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,1098.72,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,1101.6960000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,187356.0,464824.0,8192.0,0,0.0,473016.0,473016.0,0.0,512.0,0.0,131072.0,131072.0,3.008,1104.7040000000002,32768.0,65536.0,183260.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",87,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.88,1107.5840000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",88,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.2,1110.7840000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,144.512,1255.2960000000003,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,1258.2720000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",91,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,1265.6640000000004,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),92,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.264,1328.9280000000003,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.248,1334.1760000000004,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",94,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.52,1337.6960000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,1341.2800000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",96,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,1344.8640000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",97,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.912,1359.7760000000005,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),98,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.512,1384.2880000000005,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",99,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.488,1387.7760000000005,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",100,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,1390.6240000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",101,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.264,1397.8880000000004,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69924352.0,131072.0,80.992,1478.8800000000003,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185136.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,1481.8240000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",104,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.2,1485.0240000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",105,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,1487.9360000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.168,1491.1040000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",107,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,1493.9840000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,186772.0,463656.0,8192.0,0,0.0,471848.0,471848.0,0.0,512.0,0.0,131072.0,131072.0,2.944,1496.9280000000003,32768.0,65536.0,182676.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",109,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,1499.8720000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",110,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,1503.2320000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",111,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.528,1649.7600000000002,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,1652.6400000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.36,1660.0000000000002,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),114,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,64.096,1724.0960000000002,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.088,1729.1840000000002,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,1732.736,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.488,1736.2240000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.648,1739.872,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",119,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.944,1754.816,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),120,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.544,1779.3600000000001,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",121,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.456,1782.816,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.168,1785.984,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",123,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.36,1793.3439999999998,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",124,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69927552.0,131072.0,80.896,1874.2399999999998,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185236.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",125,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,1877.216,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",126,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.2,1880.416,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",127,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,1883.392,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.232,1886.624,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",129,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,1889.536,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",130,187256.0,464624.0,8192.0,0,0.0,472816.0,472816.0,0.0,512.0,0.0,131072.0,131072.0,3.04,1892.576,32768.0,65536.0,183160.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.976,1895.5520000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",132,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.264,1898.816,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",133,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.536,2044.352,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.816,2047.1680000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,2054.56,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),136,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.136,2117.696,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",137,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.184,2122.88,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.776,2126.656,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,2130.208,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.488,2133.696,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",141,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,15.04,2148.736,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),142,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,25.6,2174.336,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",143,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.296,2177.6319999999996,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,2180.4799999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,2187.7759999999994,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69916416.0,131072.0,80.768,2268.5439999999994,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184888.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",147,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,2271.4239999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",148,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,2274.3679999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",149,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.848,2277.2159999999994,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.008,2280.2239999999993,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",151,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,2283.135999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",152,186896.0,463904.0,8192.0,0,0.0,472096.0,472096.0,0.0,512.0,0.0,131072.0,131072.0,2.976,2286.111999999999,32768.0,65536.0,182800.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.88,2288.9919999999993,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",154,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.2,2292.191999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",155,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.44,2437.631999999999,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,2440.479999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,2447.871999999999,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),158,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,64.0,2511.871999999999,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",159,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,4.992,2516.863999999999,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.616,2520.479999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,2524.063999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.68,2527.743999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",163,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.848,2542.5919999999987,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),164,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.48,2567.0719999999988,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",165,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.552,2570.623999999999,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.816,2573.4399999999987,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",167,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,2580.7359999999985,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",168,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69939200.0,131072.0,80.768,2661.5039999999985,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185600.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",169,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.296,2664.7999999999984,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",170,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,2667.711999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",171,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,2670.6879999999983,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.136,2673.8239999999983,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",173,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,2676.767999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",174,187168.0,464448.0,8192.0,0,0.0,472640.0,472640.0,0.0,512.0,0.0,131072.0,131072.0,3.168,2679.9359999999983,32768.0,65536.0,183072.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,2682.847999999998,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",176,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.072,2685.9199999999983,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",177,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.344,2831.2639999999983,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,2834.1439999999984,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,2841.4399999999982,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),180,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.808,2905.2479999999982,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",181,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.024,2910.271999999998,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,2913.855999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.488,2917.343999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,2920.9279999999976,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",185,262144.0,9232384.0,0.0,0,0.0,9232384.0,9232384.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.88,2935.8079999999977,7110656.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),186,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.576,2960.3839999999977,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",187,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.488,2963.8719999999976,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",188,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.816,2966.6879999999974,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",189,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.328,2974.0159999999973,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",190,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69903232.0,131072.0,80.768,3054.7839999999974,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184476.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",191,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,3057.6639999999975,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",192,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,3060.5759999999973,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",193,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,3063.487999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",194,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.264,3066.751999999997,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",195,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.168,3069.9199999999973,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,186928.0,463968.0,8192.0,0,0.0,472160.0,472160.0,0.0,512.0,0.0,131072.0,131072.0,3.04,3072.9599999999973,32768.0,65536.0,182832.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",197,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.848,3075.8079999999973,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",198,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.136,3078.9439999999972,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",199,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.44,3224.3839999999973,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,3227.2319999999972,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",201,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.36,3234.5919999999974,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,419746576.0,903829056.0,16082464.0,0,0.0,919911520.0,919911520.0,5654076.0,4925476.0,0.5344343503392204,589240064.0,1176704.0,458.784,3693.3759999999975,28948032.0,51470336.0,411705344.0,8041232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18413752.0,36772.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.4,3695.7759999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",204,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,3.008,3698.7839999999974,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,3701.5359999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",206,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.712,3705.2479999999973,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",207,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.464,3707.7119999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",208,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.448,3712.159999999997,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",209,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.912,3719.071999999997,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",210,109064.0,0.0,218128.0,0,0.0,218128.0,218128.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.672,3723.743999999997,0.0,0.0,0.0,109064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",211,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,13200.0,83208.0,0.13691809808314662,5029376.0,0.0,6.752,3730.495999999997,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",212,101384.0,0.0,202768.0,0,0.0,202768.0,202768.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.48,3734.975999999997,0.0,0.0,0.0,101384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",213,211200.0,0.0,422400.0,0,0.0,422400.0,422400.0,13200.0,83808.0,0.13607125185551708,5029376.0,0.0,6.752,3741.727999999997,0.0,0.0,0.0,211200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",214,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.448,3746.1759999999967,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",215,166400.0,0.0,332800.0,0,0.0,332800.0,332800.0,13200.0,82408.0,0.13806376035478202,5029376.0,128.0,6.688,3752.863999999997,0.0,0.0,0.0,166400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",216,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.36,3756.223999999997,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,3758.591999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",218,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.576,3763.167999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,3765.471999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",220,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.672,3770.143999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",221,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,35588.0,13004.0,0.7323839315113599,829920.0,8960.0,6.464,3776.607999999997,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,280.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",222,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.56,3783.167999999997,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.736,3787.903999999997,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",224,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.16,3792.0639999999967,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",225,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,4.032,3796.095999999997,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",226,387911.0,0.0,775822.0,0,0.0,775822.0,775822.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,5.056,3801.151999999997,0.0,0.0,0.0,387911.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.976,3804.127999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",228,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28638.0,0.6966185007839315,2732224.0,1870208.0,16.672,3820.799999999997,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85382.0,58444.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",229,62276.0,0.0,124552.0,0,0.0,124552.0,124552.0,14202.0,28539.0,0.3322804801010739,2718272.0,2451264.0,13.856,3834.655999999997,0.0,0.0,0.0,62276.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84946.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",230,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28389.0,0.3489209458064812,2718784.0,1838112.0,14.688,3849.3439999999973,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84962.0,57441.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",231,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28253.0,0.35001265327719877,2711360.0,1835872.0,14.752,3864.0959999999973,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84730.0,57371.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",232,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,5.504,3869.599999999997,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.976,3872.5759999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",234,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15329.0,0.4920471866922924,1863328.0,1283296.0,9.216,3881.791999999997,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58229.0,40103.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",235,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2430368.0,2412352.0,6.24,3888.031999999997,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75949.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",236,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2278016.0,751296.0,25.856,3913.887999999997,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71188.0,23478.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",237,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804416.0,581312.0,79.744,3993.6319999999973,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25138.0,18166.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.68,3997.311999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.592,3999.9039999999973,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,78976.0,10.08,4009.983999999997,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2468.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",241,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.064,4014.047999999997,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",242,3284168.0,6655044.0,939552.0,0,0.0,7594596.0,7594596.0,528.0,6704.0,0.07300884955752213,2276608.0,751424.0,26.016,4040.063999999997,825232.0,201028.0,2814392.0,469776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71144.0,23482.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",243,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.584,4047.647999999997,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.848,4050.495999999997,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",245,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.904,4058.399999999997,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,3.232,4061.631999999997,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",247,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.976,4064.607999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.584,4068.191999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",249,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,14.112,4082.303999999997,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",250,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.72,4085.0239999999967,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",251,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,4.128,4089.151999999997,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.784,4091.935999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,4095.423999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",254,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.448,4099.871999999997,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,1210564.0,2017280.0,403848.0,0,0.0,2421128.0,2421128.0,0.0,4737.0,0.0,1608256.0,0.0,5.792,4105.663999999997,0.0,0.0,1008640.0,201924.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",256,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,18.208,4123.871999999997,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,4126.6879999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,4129.791999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",259,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,4132.639999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.816,4135.4559999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",261,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,4138.367999999997,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",262,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,4140.735999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,4143.1039999999975,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,4145.919999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",265,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,4148.255999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.816,4151.071999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.112,4157.1839999999975,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",268,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,4159.999999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.784,4162.783999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",270,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.168,4165.951999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",271,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.552,4169.503999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",272,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.656,4172.159999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,4174.943999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",274,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.712,4178.655999999996,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",275,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.264,4181.919999999996,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.752,4184.671999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",277,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.72,4187.391999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",278,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.784,4190.175999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.008,4193.183999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",280,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,33280.0,32768.0,6.688,4199.871999999997,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1040.0,1024.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",281,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,8704.0,32768.0,4.448,4204.319999999997,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.944,4207.263999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",283,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.688,4209.9519999999975,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",284,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.872,4213.823999999998,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.456,4221.279999999998,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),286,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,62.912,4284.191999999998,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",287,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.088,4289.279999999998,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,4293.535999999998,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",289,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,4297.759999999998,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,4301.343999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",291,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,16.384,4317.727999999998,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),292,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,25.184,4342.911999999998,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",293,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.52,4346.431999999999,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,4349.343999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",295,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,4356.639999999999,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69912960.0,131072.0,80.896,4437.535999999999,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184780.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",297,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,4440.48,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",298,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.136,4443.616,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,4446.56,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",300,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,4449.6320000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",301,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.008,4452.64,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,187009.0,464130.0,8192.0,0,0.0,472322.0,472322.0,0.0,512.0,0.0,131072.0,131072.0,2.976,4455.616,32768.0,65536.0,182913.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",303,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.88,4458.496,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",304,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,4461.792,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.496,4608.2880000000005,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,4611.168000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,4618.56,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),308,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,62.88,4681.4400000000005,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.376,4686.816000000001,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,4691.072000000001,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,4695.296000000001,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.584,4698.880000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",313,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,14.912,4713.792000000001,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),314,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.48,4738.272000000001,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.456,4741.728000000001,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,4744.608000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",317,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.328,4751.9360000000015,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",318,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69915904.0,131072.0,80.736,4832.672000000001,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184872.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",319,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,4835.616000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",320,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,4838.528000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",321,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,4841.504000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",322,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,4844.576000000002,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",323,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,4847.488000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",324,186985.0,464082.0,8192.0,0,0.0,472274.0,472274.0,0.0,512.0,0.0,131072.0,131072.0,3.136,4850.6240000000025,32768.0,65536.0,182889.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",325,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,4853.536000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",326,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.2,4856.736000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",327,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.592,5003.328000000002,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,5006.208000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",329,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,5013.600000000002,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),330,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.36,5076.960000000002,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",331,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.12,5082.080000000002,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,5086.336000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.288,5090.624000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.52,5094.144000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",335,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,15.168,5109.312000000002,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),336,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.416,5133.728000000002,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.456,5137.184000000002,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,5140.032000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",339,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.52,5147.552000000002,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",340,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69967744.0,131072.0,81.664,5229.216000000002,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2186492.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,5232.192000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",342,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.008,5235.200000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",343,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,5238.080000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",344,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.36,5241.440000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",345,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.912,5244.352000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,186985.0,464082.0,8192.0,0,0.0,472274.0,472274.0,0.0,512.0,0.0,131072.0,131072.0,3.296,5247.648000000002,32768.0,65536.0,182889.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",347,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,5250.560000000002,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.2,5253.760000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.568,5399.328000000002,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,5402.208000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",351,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.264,5409.4720000000025,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),352,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.36,5472.832000000002,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",353,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.056,5477.888000000002,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",354,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,5482.080000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",355,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,5486.304000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",356,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.52,5489.824000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",357,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,14.976,5504.800000000002,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),358,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.704,5529.504000000002,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.456,5532.960000000002,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,5535.9360000000015,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.488,5543.424000000002,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69912448.0,131072.0,81.024,5624.448000000002,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184764.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.88,5627.328000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",364,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,5630.2400000000025,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,5633.184000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",366,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,5636.256000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,5639.2000000000035,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,187089.0,464290.0,8192.0,0,0.0,472482.0,472482.0,0.0,512.0,0.0,131072.0,131072.0,2.976,5642.176000000003,32768.0,65536.0,182993.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",369,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,5645.1200000000035,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.104,5648.224000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",371,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,144.896,5793.1200000000035,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,5796.032000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.392,5803.424000000004,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),374,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.936,5867.360000000003,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",375,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.184,5872.5440000000035,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.352,5876.896000000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,5881.088000000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.52,5884.608000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",379,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,15.04,5899.648000000004,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),380,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.736,5924.384000000004,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",381,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.456,5927.840000000004,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.104,5930.944000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.264,5938.208000000004,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",384,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69919488.0,131072.0,80.64,6018.8480000000045,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184984.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6021.792000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",386,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.136,6024.928000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6027.872000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.04,6030.912000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",389,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6033.856000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,187093.0,464298.0,8192.0,0,0.0,472490.0,472490.0,0.0,512.0,0.0,131072.0,131072.0,2.976,6036.832000000006,32768.0,65536.0,182997.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",391,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,6039.744000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.072,6042.816000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.824,6188.640000000006,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,6191.616000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.328,6198.944000000006,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),396,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.2,6262.144000000006,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",397,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.344,6267.488000000006,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.224,6271.712000000006,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.192,6275.904000000006,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.552,6279.456000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",401,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,15.04,6294.496000000006,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),402,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.832,6319.328000000006,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",403,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.488,6322.816000000006,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",404,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.912,6325.728000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",405,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.424,6333.152000000006,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",406,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69907328.0,131072.0,81.056,6414.208000000006,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2184604.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,6417.184000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",408,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6420.128000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.072,6423.200000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,6426.272000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",411,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,6429.248000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,186939.0,463990.0,8192.0,0,0.0,472182.0,472182.0,0.0,512.0,0.0,131072.0,131072.0,3.232,6432.480000000006,32768.0,65536.0,182843.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.912,6435.392000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.232,6438.624000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,146.56,6585.184000000007,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,6588.0320000000065,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.424,6595.4560000000065,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),418,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,64.16,6659.616000000006,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",419,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.12,6664.736000000006,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,6668.992000000007,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",421,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.288,6673.280000000006,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.648,6676.928000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",423,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,14.976,6691.904000000006,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),424,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.704,6716.608000000006,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",425,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.552,6720.160000000005,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",426,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.848,6723.008000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",427,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.488,6730.496000000006,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69923456.0,131072.0,80.832,6811.328000000006,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185108.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",429,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.168,6814.496000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",430,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6817.440000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",431,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.136,6820.576000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.072,6823.6480000000065,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.008,6826.656000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,187087.0,464286.0,8192.0,0,0.0,472478.0,472478.0,0.0,512.0,0.0,131072.0,131072.0,3.008,6829.664000000006,32768.0,65536.0,182991.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.944,6832.6080000000065,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",436,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.36,6835.968000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",437,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,145.632,6981.600000000006,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.88,6984.480000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",439,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.296,6991.776000000006,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),440,402690048.0,805896192.0,73728.0,0,0.0,805969920.0,805969920.0,1218240.0,2304.0,0.998112317130722,51904512.0,294912.0,63.744,7055.520000000006,0.0,589824.0,402653184.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1622016.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",441,147456.0,122880.0,294912.0,0,0.0,417792.0,417792.0,0.0,7680.0,0.0,319488.0,98304.0,5.088,7060.608000000006,98304.0,24576.0,0.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9984.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.256,7064.864000000006,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,4.288,7069.1520000000055,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,512.0,0.0,32768.0,32768.0,3.744,7072.896000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",445,262144.0,9240576.0,0.0,0,0.0,9240576.0,9240576.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,15.072,7087.968000000005,7118848.0,1597440.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),446,134250496.0,268959744.0,65536.0,0,0.0,269025280.0,269025280.0,427520.0,2048.0,0.9952324195470799,17301504.0,262144.0,24.832,7112.800000000006,0.0,524288.0,134217728.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,540672.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,49152.0,81920.0,98304.0,0,0.0,180224.0,180224.0,0.0,3840.0,0.0,270336.0,32768.0,3.424,7116.224000000006,73728.0,8192.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8448.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,2.976,7119.200000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",449,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.424,7126.624000000005,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",450,67305472.0,135921664.0,393216.0,0,0.0,136314880.0,136314880.0,594944.0,559104.0,0.515527950310559,69928576.0,131072.0,80.704,7207.328000000005,655360.0,1048576.0,67108864.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2185268.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.944,7210.272000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",452,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.88,7213.1520000000055,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",453,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,2.976,7216.128000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.136,7219.264000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",455,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.04,7222.3040000000055,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,187122.0,464356.0,8192.0,0,0.0,472548.0,472548.0,0.0,512.0,0.0,131072.0,131072.0,2.976,7225.280000000005,32768.0,65536.0,183026.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",457,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,2.88,7228.160000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",458,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.232,7231.392000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",459,67256320.0,135823360.0,294912.0,0,0.0,136118272.0,136118272.0,591104.0,557568.0,0.5145977267662135,71311360.0,32768.0,144.992,7376.3840000000055,557056.0,1048576.0,67108864.0,147456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228480.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.072,7379.456000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",461,52804.0,175348.0,3072.0,0,0.0,178420.0,178420.0,68.0,712.0,0.08717948717948718,98304.0,33024.0,7.36,7386.816000000005,51760.0,21052.0,51268.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1032.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,419746576.0,903829056.0,16082464.0,0,0.0,919911520.0,919911520.0,5654076.0,4925476.0,0.5344343503392204,590275968.0,1178016.0,457.76,7844.5760000000055,28948032.0,51470336.0,411705344.0,8041232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18446124.0,36813.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,7846.912000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,3.008,7849.9200000000055,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,7852.672000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",466,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.648,7856.320000000006,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",467,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.464,7858.784000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",468,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.64,7863.424000000006,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",469,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.496,7869.920000000006,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",470,109128.0,0.0,218256.0,0,0.0,218256.0,218256.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.416,7874.336000000007,0.0,0.0,0.0,109128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",471,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,13200.0,83208.0,0.13691809808314662,5029376.0,0.0,6.592,7880.928000000006,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",472,101389.0,0.0,202778.0,0,0.0,202778.0,202778.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.64,7885.568000000007,0.0,0.0,0.0,101389.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",473,174400.0,0.0,348800.0,0,0.0,348800.0,348800.0,13200.0,82658.0,0.13770368670324856,5029376.0,0.0,6.656,7892.2240000000065,0.0,0.0,0.0,174400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",474,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.64,7896.864000000007,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",475,196800.0,0.0,393600.0,0,0.0,393600.0,393600.0,13200.0,83358.0,0.1367053998632946,5029376.0,128.0,6.496,7903.360000000007,0.0,0.0,0.0,196800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",476,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.424,7906.784000000007,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,7909.120000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",478,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.672,7913.792000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,7916.096000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",480,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.736,7920.832000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",481,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,55186.0,13012.0,0.8092026159124901,829920.0,8288.0,6.304,7927.136000000007,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,259.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",482,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.592,7933.728000000006,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.736,7938.464000000006,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",484,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.16,7942.624000000006,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",485,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.936,7946.560000000006,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",486,387899.0,0.0,775798.0,0,0.0,775798.0,775798.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.928,7951.488000000006,0.0,0.0,0.0,387899.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",487,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.976,7954.464000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",488,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28754.0,0.6957635009310987,2730688.0,1848992.0,16.608,7971.072000000006,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85334.0,57781.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",489,62276.0,0.0,124552.0,0,0.0,124552.0,124552.0,14202.0,28453.0,0.3329504161294104,2712768.0,2451392.0,13.664,7984.736000000005,0.0,0.0,0.0,62276.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84774.0,76606.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",490,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28441.0,0.34850532585041805,2715840.0,1934752.0,14.848,7999.584000000005,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84870.0,60461.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",491,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28245.0,0.3500770841482777,2708416.0,1464288.0,14.784,8014.368000000005,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84638.0,45759.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",492,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,5.504,8019.872000000005,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.912,8022.784000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",494,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15396.0,0.49095718300545543,1863840.0,1281376.0,9.216,8032.0000000000055,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58245.0,40043.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",495,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429568.0,2412352.0,6.528,8038.528000000006,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75924.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",496,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2279296.0,751424.0,25.472,8064.0000000000055,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71228.0,23482.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",497,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804352.0,581408.0,79.936,8143.936000000005,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25136.0,18169.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.744,8147.680000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.624,8150.304000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,77408.0,9.568,8159.872000000005,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2419.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",501,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.128,8164.000000000005,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",502,3284168.0,6655044.0,939552.0,0,0.0,7594596.0,7594596.0,528.0,6704.0,0.07300884955752213,2281088.0,752256.0,25.888,8189.8880000000045,825232.0,201028.0,2814392.0,469776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71284.0,23508.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",503,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.264,8197.152000000004,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.848,8200.000000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",505,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.36,8207.360000000004,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,8210.176000000005,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",507,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.784,8212.960000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.488,8216.448000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",509,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804256.0,128.0,13.952,8230.400000000003,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",510,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.752,8233.152000000004,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.68,8236.832000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.752,8239.584000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.68,8243.264000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",514,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.448,8247.712000000005,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",515,1210564.0,2017280.0,403848.0,0,0.0,2421128.0,2421128.0,0.0,4737.0,0.0,1608256.0,0.0,5.728,8253.440000000004,0.0,0.0,1008640.0,201924.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",516,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,17.856,8271.296000000004,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.656,8273.952000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,8276.704000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.752,8279.456000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,8282.240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.912,8285.152000000006,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",522,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,8287.520000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",523,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,8289.888000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",524,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,8292.704000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",525,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.464,8295.168000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.912,8298.080000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.984,8304.064000000008,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",528,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,8306.912000000008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,8309.664000000008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",530,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,8312.768000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",531,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.52,8316.288000000008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",532,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,8319.072000000007,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
