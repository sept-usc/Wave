Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,6.944,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.568,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,11.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,13.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,15.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.976,18.72,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,21.247999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,23.647999999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,25.695999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.04,28.735999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,31.231999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,33.727999999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,0.0,2.528,36.25599999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,4.704,40.959999999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.168,44.12799999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.816,46.943999999999996,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",20,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.688,49.632,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.496,52.128,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1664.0,2304.0,1280.0,0,0.0,3584.0,3584.0,0.0,8.0,0.0,512.0,512.0,2.976,55.104,0.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.656,57.76,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,3.008,60.768,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.56,63.328,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,65.92,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.776,69.696,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,3.008,72.704,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,75.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,78.336,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,80.96,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,8.064,89.024,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.04,96.06400000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.528,102.59200000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,105.79200000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.168,108.96000000000002,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,112.48000000000002,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.264,115.74400000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,118.33600000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,121.44000000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,124.48000000000002,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,127.90400000000002,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,130.94400000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,133.632,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.096,153.728,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.072,160.8,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,163.424,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,165.984,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,169.66400000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,172.096,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,174.68800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,177.76000000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,180.35200000000003,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",54,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705728.0,12288.0,13.888,194.24000000000004,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303304.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.976,197.21600000000004,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",56,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702528.0,12288.0,14.496,211.71200000000005,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303204.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.656,214.36800000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.008,229.37600000000006,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.816,232.19200000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,234.75200000000007,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,238.40000000000006,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,240.92800000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,243.52000000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.944,246.46400000000006,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,249.08800000000005,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.52,256.60800000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,263.48800000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,270.46400000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,273.5040000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,276.5440000000001,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,279.9680000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,283.07200000000006,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,285.63200000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,288.70400000000006,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,291.71200000000005,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,295.10400000000004,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,298.24000000000007,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,300.80000000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.16,320.9600000000001,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.784,327.7440000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,330.3040000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,332.8960000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,336.5760000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,339.0080000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,341.6000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,344.60800000000006,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,347.20000000000005,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",88,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9704576.0,12288.0,13.952,361.15200000000004,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303268.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,364.064,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",90,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699328.0,12288.0,14.88,378.944,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303104.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,381.536,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.264,396.8,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,399.36,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,401.92,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,405.504,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,408.0,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,410.72,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,413.728,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,416.35200000000003,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.04,423.39200000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.816,430.208,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.688,436.896,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,440.064,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,443.136,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.584,446.72,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,449.76000000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,452.32000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,455.36000000000007,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,458.4000000000001,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,461.8880000000001,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,464.9280000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,467.5200000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.096,487.6160000000001,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.04,494.6560000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,497.2480000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,499.8080000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,503.4240000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,505.8880000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,508.4480000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,511.4240000000001,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.656,514.08,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",122,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701248.0,12288.0,14.464,528.5440000000001,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303164.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,531.4560000000001,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",124,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702784.0,12288.0,14.304,545.7600000000001,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303212.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,548.32,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.816,563.1360000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,565.7280000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,568.32,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,572.0,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,574.432,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,577.024,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,580.032,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,582.624,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,589.6320000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.848,596.48,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.04,603.52,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,606.56,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,609.5999999999999,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,613.0239999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,616.0959999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,618.6879999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.008,621.6959999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,2.944,624.6399999999999,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,628.0959999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,631.1999999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,633.824,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.128,653.952,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,660.96,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,663.552,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,666.144,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,669.824,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,672.2239999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,674.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,677.76,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,680.3199999999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",156,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700608.0,12288.0,13.92,694.2399999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303144.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.944,697.1839999999999,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",158,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701760.0,12288.0,14.08,711.2639999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303180.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.688,713.9519999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.008,728.9599999999999,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,731.5199999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,734.0799999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,737.7279999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,740.2239999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,742.8159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,745.8879999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,748.4799999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.816,755.2959999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.552,762.8479999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.136,769.9839999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,773.0239999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,776.0959999999998,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,779.5199999999998,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,782.5599999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,785.1839999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,788.2239999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,791.2959999999997,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,794.8159999999997,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,797.8559999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,800.4479999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.192,820.6399999999996,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.816,827.4559999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,830.0479999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.72,832.7679999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.584,836.3519999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,838.7839999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,841.3439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.136,844.4799999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,847.1039999999996,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",190,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702400.0,12288.0,13.856,860.9599999999996,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303200.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,863.8719999999996,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",192,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9698944.0,12288.0,14.56,878.4319999999996,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303092.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,881.0239999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469760.0,6144.0,15.584,896.6079999999995,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327180.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,899.1679999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,901.7279999999994,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,905.3759999999994,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,907.8079999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,910.3999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.136,913.5359999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.688,916.2239999999994,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.648,923.8719999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.816,930.6879999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,937.5679999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,940.6079999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,943.7439999999993,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,947.1359999999994,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,950.1759999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,952.7359999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,955.8719999999993,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.232,959.1039999999992,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,962.4959999999993,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,965.6639999999993,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,968.2559999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.32,988.5759999999993,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.848,995.4239999999993,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,998.0159999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,1000.6079999999993,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,1004.2239999999993,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1006.6559999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1009.2159999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.88,1012.0959999999992,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1014.6559999999992,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",224,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703168.0,12288.0,13.792,1028.4479999999992,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303224.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,1031.3599999999992,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",226,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9699968.0,12288.0,13.92,1045.2799999999993,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303124.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1047.8719999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.008,1062.8799999999994,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1065.4399999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,1067.9999999999993,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,1071.6799999999994,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1074.1119999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1076.7039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,1079.6799999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1082.2719999999997,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.392,1089.6639999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.944,1096.6079999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.072,1103.6799999999996,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,1106.8799999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,1109.9199999999996,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1113.3759999999995,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1116.4479999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1119.0079999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,1122.1759999999992,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,1125.2159999999992,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,1128.6079999999993,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1131.6479999999992,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.752,1134.3999999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.032,1154.431999999999,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.592,1161.0239999999992,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1163.5839999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.656,1166.239999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,1169.855999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,1172.3519999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1175.0079999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,1177.9839999999992,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1180.5759999999993,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",258,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702656.0,12288.0,14.112,1194.6879999999994,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303208.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.88,1197.5679999999995,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",260,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700352.0,12288.0,14.304,1211.8719999999996,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303136.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1214.4319999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.136,1229.5679999999995,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,1232.2559999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1234.7839999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.904,1238.6879999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1241.1199999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1243.7119999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.104,1246.8159999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1249.3759999999997,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.752,1256.1279999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.784,1262.9119999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.72,1269.6319999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1272.7039999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,1275.7759999999996,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,1279.2639999999997,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1282.3039999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1284.8959999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,1288.0639999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,1291.1039999999996,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,1294.4959999999996,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1297.5679999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.688,1300.2559999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,12288.0,1127808.0,0.0,0,0.0,1127808.0,1127808.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,20.128,1320.3839999999996,954624.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,1327.3919999999996,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1329.9839999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,1332.5439999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,1336.1919999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1338.5919999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1341.1839999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.168,1344.3519999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1346.9439999999997,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",292,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701376.0,12288.0,14.848,1361.7919999999997,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.944,1364.7359999999996,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",294,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700736.0,12288.0,14.4,1379.1359999999997,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303148.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1381.7279999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6112.0,15.36,1397.0879999999997,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,191.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,1399.7119999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1402.2399999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.808,1406.0479999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1408.5119999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1411.0719999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,1414.0799999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.72,1416.7999999999997,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",304,25152000.0,49472000.0,1088000.0,0,0.0,50560000.0,50560000.0,88000.0,1544000.0,0.05392156862745098,99334016.0,179712.0,113.12,1529.9199999999996,256000.0,0.0,24608000.0,544000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3104188.0,5616.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1531.9679999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",306,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.528,1534.4959999999996,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,1536.9599999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.752,1539.7119999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1541.8239999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",310,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.968,1545.7919999999997,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",311,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.608,1550.3999999999996,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",312,16192.0,0.0,32384.0,0,0.0,32384.0,32384.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.968,1554.3679999999997,0.0,0.0,0.0,16192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",313,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.8,1559.1679999999997,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,16130.0,0.0,32260.0,0,0.0,32260.0,32260.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.0,1563.1679999999997,0.0,0.0,0.0,16130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,28672.0,0.0,57344.0,0,0.0,57344.0,57344.0,2112.0,8642.0,0.19639204017109912,527360.0,0.0,4.672,1567.8399999999997,0.0,0.0,0.0,28672.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,4.064,1571.9039999999998,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,32.0,4.704,1576.6079999999997,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",318,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.04,1579.6479999999997,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,1581.6639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",320,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.288,1585.9519999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1587.9999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",322,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.256,1592.2559999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",323,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,6642.0,2104.0,0.7594328836039332,131808.0,1824.0,6.016,1598.272,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4119.0,57.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",324,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,6.016,1604.288,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",325,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.096,1608.384,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4063.0,250.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",326,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,1611.2640000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",327,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.528,1613.7920000000001,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",328,387235.0,0.0,774470.0,0,0.0,774470.0,774470.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.968,1617.7600000000002,0.0,0.0,0.0,387235.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,1620.4800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",330,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4264.0,0.7094972067039106,407552.0,306752.0,14.912,1635.3920000000003,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12736.0,9586.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4264.0,0.4449362145274668,407552.0,390144.0,13.056,1648.4480000000003,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12736.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4224.0,0.5318111283529151,405504.0,390144.0,14.176,1662.6240000000003,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12672.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4232.0,0.5313399778516058,405504.0,328064.0,14.656,1677.2800000000002,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12672.0,10252.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",334,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,254720.0,128000.0,18.624,1695.9040000000002,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7960.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",335,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.08,1697.9840000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",336,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2053.0,0.6793189628241174,134208.0,129024.0,3.808,1701.7920000000001,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4194.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",337,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.656,1704.448,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",338,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.272,1706.72,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",339,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12576.0,8.992,1715.712,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9000.0,393.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",340,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.944,1718.656,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",341,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,262400.0,128000.0,19.008,1737.664,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8200.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",342,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.792,1747.456,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,1749.888,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",344,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.664,1759.552,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,1761.952,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",346,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,1764.544,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,1767.8400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",348,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.76,1777.6000000000001,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,1780.0000000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.528,1782.5280000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,1785.7600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",352,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.816,1788.5760000000002,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",353,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.744,1792.3200000000002,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",354,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,13.056,1805.3760000000002,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1807.8080000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,1810.2720000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,1812.6720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,1815.1040000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",359,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,2.656,1817.7600000000002,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",360,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,1819.7760000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.08,1821.8560000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",362,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,1824.4480000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",363,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,1826.4960000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",364,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.368,1828.8640000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",365,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,1831.3920000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,1833.8560000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",367,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.04,1836.8960000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.168,1840.064,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",369,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,1842.4640000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",370,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,1844.8960000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",371,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,3.0,0.0,64.0,32.0,3.328,1848.2240000000002,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1850.2720000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",373,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,1853.1840000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1855.7440000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,1858.1440000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",376,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.464,1860.6080000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",377,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,3264.0,3072.0,3.104,1863.7120000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,1866.4640000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",379,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.584,1870.0480000000002,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",380,515.0,0.0,1030.0,0,0.0,1030.0,1030.0,0.0,2.0,0.0,32.0,32.0,2.784,1872.8320000000003,0.0,0.0,0.0,515.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",381,0.0,128.0,0.0,0,0.0,128.0,128.0,8.0,6.0,0.5714285714285714,320.0,256.0,2.56,1875.3920000000003,0.0,128.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,2.528,1877.9200000000003,0.0,0.0,0.0,288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,1664.0,2308.0,1280.0,0,0.0,3588.0,3588.0,0.0,8.0,0.0,512.0,512.0,2.88,1880.8000000000004,4.0,256.0,1024.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,1883.2640000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,1536.0,2304.0,1024.0,0,0.0,3328.0,3328.0,0.0,8.0,0.0,512.0,512.0,2.88,1886.1440000000005,0.0,256.0,1024.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,8.0,0.0,512.0,512.0,2.464,1888.6080000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,1891.2000000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",388,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.712,1894.9120000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",389,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1897.2800000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1899.8400000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,1902.8160000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1905.4080000000006,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",393,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.56,1911.9680000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.392,1919.3600000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",395,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,1926.3680000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",396,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1929.4080000000006,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,1932.4800000000005,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1935.9360000000004,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1938.9760000000003,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1941.5680000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,1944.6080000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,1947.6480000000004,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",403,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1951.1040000000003,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,1954.1760000000002,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",405,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,1956.7680000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.688,1959.4560000000004,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,1962.0160000000003,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",408,11904.0,1127186.0,0.0,0,0.0,1127186.0,1127186.0,6255.0,12.0,0.9980852082336046,15360.0,3072.0,20.256,1982.2720000000004,954804.0,148574.0,11904.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",409,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.624,1988.8960000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,1991.4560000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,1993.9840000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",412,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,1997.6640000000004,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2000.0640000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2002.6240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,2005.6960000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2008.2880000000005,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",417,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9704448.0,12288.0,13.824,2022.1120000000005,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303264.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,2025.0240000000006,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",419,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702272.0,12288.0,14.112,2039.1360000000006,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303196.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2041.6960000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10470400.0,6112.0,15.424,2057.120000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327200.0,191.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2059.7440000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.656,2062.4000000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",424,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,2066.0480000000007,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2068.4160000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2070.9440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",427,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.136,2074.0800000000004,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2076.6720000000005,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",429,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.944,2083.6160000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.944,2090.5600000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.784,2097.3440000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2100.4800000000005,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,2103.4880000000003,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2106.976,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2110.016,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2112.576,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2115.712,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,2118.784,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,2122.176,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2125.312,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2127.872,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2130.432,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2132.9919999999997,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",444,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.288,2153.2799999999997,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",445,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,2160.256,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2162.8799999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2165.5039999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",448,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,2169.1199999999994,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",449,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2171.5199999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2174.0799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,2177.0559999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",452,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2179.6159999999995,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",453,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702016.0,12288.0,13.792,2193.4079999999994,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303188.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.944,2196.3519999999994,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",455,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9709312.0,12288.0,14.304,2210.6559999999995,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303416.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2213.2799999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10470400.0,6112.0,15.104,2228.383999999999,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327200.0,191.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2230.975999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.72,2233.695999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",460,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2237.375999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",461,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2239.775999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2242.367999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",463,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,2245.343999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.784,2248.1279999999992,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.72,2254.847999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.04,2261.887999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",467,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.264,2269.151999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2272.2239999999993,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,2275.2959999999994,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",470,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2278.7519999999995,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2281.8239999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",472,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2284.4159999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2287.584,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,2290.656,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,2294.048,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2297.12,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2299.712,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,2302.304,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2304.864,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",480,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.288,2325.152,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",481,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.2,2332.352,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2334.9759999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.624,2337.5999999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",484,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2341.2799999999993,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",485,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2343.711999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2346.271999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.04,2349.311999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.688,2351.999999999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",489,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9704064.0,12288.0,14.336,2366.335999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303252.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,2369.2479999999987,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",491,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9710848.0,12288.0,14.496,2383.743999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303464.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2386.3679999999986,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.36,2401.7279999999987,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2404.3519999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2406.9439999999986,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,4.0,2410.9439999999986,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2413.3439999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2415.935999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,2419.007999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2421.6319999999987,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",501,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.592,2428.223999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",502,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.784,2435.007999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",503,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.976,2441.983999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2445.119999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.104,2448.223999999999,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2451.7119999999986,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.232,2454.9439999999986,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2457.5999999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2460.7359999999985,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,2463.8079999999986,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",511,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2467.2959999999985,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2470.3359999999984,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",513,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2472.8959999999984,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2475.4559999999983,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.688,2478.1439999999984,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",516,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.192,2498.3359999999984,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",517,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,2505.2159999999985,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2507.8079999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",519,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.752,2510.5599999999986,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",520,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,2514.2079999999987,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",521,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2516.607999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2519.199999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.04,2522.239999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2524.799999999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",525,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9697920.0,12288.0,14.656,2539.4559999999988,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303060.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.976,2542.431999999999,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",527,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9706240.0,12288.0,13.984,2556.415999999999,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303320.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2559.007999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,14.624,2573.6319999999987,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",530,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2576.223999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,2578.7839999999987,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",532,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,2582.431999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",533,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2584.831999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2587.391999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,2590.367999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",536,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2592.959999999999,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.624,2599.583999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",538,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.264,2606.847999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",539,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,2613.727999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2616.767999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,2619.8399999999992,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.424,2623.263999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.04,2626.303999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",544,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.72,2629.023999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2632.159999999999,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,2635.1679999999988,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2638.623999999999,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,2641.7279999999987,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2644.3519999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.528,2646.8799999999983,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2649.4399999999982,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",552,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.352,2669.791999999998,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",553,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.2,2676.991999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2679.583999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,2682.175999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.648,2685.8239999999983,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2688.287999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2690.847999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.04,2693.887999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2696.511999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",561,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705600.0,12288.0,14.24,2710.7519999999977,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303300.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,3.04,2713.7919999999976,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",563,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703040.0,12288.0,13.92,2727.7119999999977,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303220.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",564,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2730.3679999999977,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",565,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.648,2746.015999999998,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",566,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2748.607999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.752,2751.359999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",568,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.712,2755.071999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",569,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2757.439999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2759.9679999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.072,2763.0399999999977,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",572,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2765.631999999998,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",573,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.784,2772.415999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",574,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.296,2779.7119999999977,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",575,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.36,2787.071999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2790.239999999998,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,2793.247999999998,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.584,2796.8319999999976,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,2800.0319999999974,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,2802.6879999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2805.8559999999975,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.136,2808.9919999999975,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",583,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,2812.3839999999973,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.168,2815.5519999999974,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",585,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2818.1439999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,2820.7999999999975,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2823.3599999999974,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",588,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.192,2843.5519999999974,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",589,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.688,2850.2399999999975,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2852.8319999999976,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,2855.3919999999976,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",592,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2859.0719999999974,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",593,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2861.4719999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2864.0959999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,2867.0719999999974,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.56,2869.6319999999973,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",597,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700096.0,12288.0,13.952,2883.5839999999976,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303128.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.88,2886.4639999999977,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",599,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9700352.0,12288.0,14.304,2900.7679999999978,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303136.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",600,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2903.4239999999977,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",601,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.328,2918.7519999999977,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2921.3759999999975,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.656,2924.0319999999974,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",604,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,2927.7119999999973,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",605,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2930.175999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2932.8639999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,2935.871999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",608,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.72,2938.591999999997,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",609,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.88,2945.471999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.944,2952.415999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.008,2959.423999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2962.495999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.04,2965.535999999997,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2968.991999999997,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,2972.127999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,2974.719999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.072,2977.791999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.328,2981.119999999997,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.616,2984.735999999997,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,2987.839999999997,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.624,2990.4639999999968,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.56,2993.0239999999967,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.528,2995.5519999999965,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,12288.0,1128194.0,0.0,0,0.0,1128194.0,1128194.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.288,3015.8399999999965,955008.0,148610.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",625,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.912,3022.7519999999963,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3025.3439999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.528,3027.871999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",628,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.616,3031.487999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",629,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3033.8879999999963,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3036.511999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.976,3039.487999999996,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3042.111999999996,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",633,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9707776.0,12288.0,13.824,3055.935999999996,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303368.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",634,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.912,3058.847999999996,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",635,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9703424.0,12288.0,14.24,3073.0879999999956,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303232.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",636,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3075.6799999999957,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",637,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6144.0,15.328,3091.0079999999957,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3093.599999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,3096.191999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.808,3099.999999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3102.4319999999957,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3104.9919999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.04,3108.0319999999956,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",644,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.624,3110.6559999999954,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.624,3117.279999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,7.104,3124.383999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.656,3131.039999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.2,3134.239999999995,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.008,3137.2479999999946,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",650,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.392,3140.6399999999944,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.136,3143.7759999999944,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",652,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3146.4319999999943,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,3149.535999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,640.0,384.0,1280.0,0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.072,3152.6079999999943,384.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,173568.0,0.0,347136.0,0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.52,3156.1279999999942,0.0,0.0,0.0,173568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.104,3159.231999999994,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.72,3161.951999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",658,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,3164.607999999994,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.592,3167.199999999994,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",660,12288.0,1128192.0,0.0,0,0.0,1128192.0,1128192.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,20.32,3187.519999999994,955008.0,148608.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",661,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2506752.0,1536.0,6.816,3194.335999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,78336.0,48.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.592,3196.927999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.688,3199.615999999994,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3203.295999999994,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3205.695999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3208.255999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,3211.2639999999938,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",668,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3213.9199999999937,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",669,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9702528.0,12288.0,14.048,3227.9679999999935,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303204.0,384.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,33792.0,64512.0,6144.0,0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,3.104,3231.0719999999933,3072.0,0.0,30720.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",671,2457600.0,5157888.0,196608.0,0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9707264.0,12288.0,13.824,3244.8959999999934,144384.0,294912.0,2359296.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,303352.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",672,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3247.4879999999935,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",673,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10469376.0,6112.0,15.488,3262.9759999999933,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,327168.0,191.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",674,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.784,3265.7599999999934,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.592,3268.3519999999935,0.0,768.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",676,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.68,3272.0319999999933,1888.0,1.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",677,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3274.4959999999933,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",678,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3277.055999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,1536.0,768.0,3072.0,0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.008,3280.063999999993,0.0,768.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",680,0.0,768.0,0.0,0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.816,3282.879999999993,0.0,768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 5, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",681,25152000.0,49472000.0,1088000.0,0,0.0,50560000.0,50560000.0,88000.0,1544000.0,0.05392156862745098,99298976.0,177472.0,113.056,3395.935999999993,256000.0,0.0,24608000.0,544000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3103093.0,5546.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3397.9839999999926,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.56,3400.5439999999926,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3403.1039999999925,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",685,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,128000.0,128000.0,2.72,3405.8239999999923,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",686,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3407.871999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,3411.775999999992,0.0,0.0,0.0,48128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.736,3416.511999999992,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,16192.0,0.0,32384.0,0,0.0,32384.0,32384.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.904,3420.415999999992,0.0,0.0,0.0,16192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,33792.0,0.0,67584.0,0,0.0,67584.0,67584.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,4.736,3425.151999999992,0.0,0.0,0.0,33792.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,16135.0,0.0,32270.0,0,0.0,32270.0,32270.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.872,3429.0239999999917,0.0,0.0,0.0,16135.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,4.928,3433.9519999999916,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",693,16129.0,0.0,32258.0,0,0.0,32258.0,32258.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,3.872,3437.8239999999914,0.0,0.0,0.0,16129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",694,27648.0,0.0,55296.0,0,0.0,55296.0,55296.0,2112.0,8610.0,0.1969781757134863,527360.0,32.0,4.928,3442.7519999999913,0.0,0.0,0.0,27648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",695,352.0,0.0,704.0,0,0.0,704.0,704.0,0.0,3.0,0.0,1056.0,128.0,3.04,3445.7919999999913,0.0,0.0,0.0,352.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,3447.9039999999914,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.352,3452.255999999991,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,3454.303999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",699,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,11.0,0.9829984544049459,128.0,0.0,4.32,3458.623999999991,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",700,40292.0,0.0,80584.0,0,0.0,80584.0,80584.0,9430.0,2108.0,0.8172993586410123,131808.0,1856.0,6.208,3464.8319999999912,0.0,0.0,0.0,40292.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4119.0,58.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",701,64.0,0.0,128.0,0,0.0,128.0,128.0,458.0,8.0,0.9828326180257511,640.0,0.0,5.952,3470.7839999999915,0.0,0.0,0.0,64.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,8000.0,4.096,3474.8799999999915,0.0,0.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4063.0,250.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",703,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,3477.7599999999916,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",704,128768.0,0.0,257536.0,0,0.0,257536.0,257536.0,0.0,1000.0,0.0,0.0,256000.0,2.624,3480.3839999999914,0.0,0.0,0.0,128768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",705,387236.0,0.0,774472.0,0,0.0,774472.0,774472.0,64512.0,1000.0,0.9847356209549396,128000.0,0.0,3.904,3484.2879999999914,0.0,0.0,0.0,387236.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,3486.911999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,29568.0,0.0,59136.0,0,0.0,59136.0,59136.0,10414.0,4256.0,0.7098841172460805,407680.0,304928.0,14.88,3501.7919999999913,0.0,0.0,0.0,29568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12740.0,9529.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3418.0,4236.0,0.446563888163052,407552.0,390144.0,13.088,3514.8799999999915,0.0,0.0,0.0,14400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12736.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",709,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4218.0,0.5321650399290151,405504.0,390144.0,14.304,3529.1839999999916,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12672.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",710,15744.0,0.0,31488.0,0,0.0,31488.0,31488.0,4798.0,4262.0,0.5295805739514349,405504.0,324256.0,14.208,3543.3919999999916,0.0,0.0,0.0,15744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12672.0,10133.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",711,524494.0,1061280.0,152988.0,0,0.0,1214268.0,1214268.0,132.0,1312.0,0.09141274238227147,253824.0,128000.0,18.144,3561.5359999999914,133280.0,32000.0,448000.0,76494.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7932.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",712,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,2.048,3563.583999999991,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",713,2177.0,85371.0,4354.0,0,0.0,89725.0,89725.0,4349.0,2062.0,0.6783653096240836,135872.0,129024.0,4.096,3567.679999999991,85371.0,0.0,0.0,2177.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4246.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,512.0,0.0,128000.0,31808.0,2.624,3570.303999999991,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",715,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3572.3519999999908,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,68096.0,0.0,136192.0,0,0.0,136192.0,136192.0,0.0,3000.0,0.0,288000.0,12736.0,8.96,3581.311999999991,0.0,0.0,0.0,68096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,9000.0,398.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,768.0,0.0,160000.0,0.0,2.88,3584.191999999991,0.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",718,524497.0,1061280.0,152994.0,0,0.0,1214274.0,1214274.0,132.0,1312.0,0.09141274238227147,258688.0,128000.0,18.624,3602.8159999999907,133280.0,32000.0,448000.0,76497.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8084.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",719,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.6,3612.4159999999906,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",720,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,3614.8799999999906,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",721,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.632,3624.5119999999906,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,3626.9439999999904,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",723,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,3629.5039999999904,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.36,3632.8639999999905,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",725,1536.0,36576.0,3072.0,0,0.0,39648.0,39648.0,62.0,251.0,0.19808306709265175,128000.0,32.0,9.696,3642.5599999999904,36576.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",726,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,3644.9599999999905,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,3647.4559999999906,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,3650.6239999999907,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",729,448000.0,640000.0,320000.0,0,0.0,960000.0,960000.0,0.0,1000.0,0.0,0.0,128000.0,2.784,3653.407999999991,0.0,64000.0,288000.0,160000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",730,196945.0,327680.0,66210.0,0,0.0,393890.0,393890.0,0.0,768.0,0.0,256000.0,0.0,3.744,3657.151999999991,0.0,0.0,163840.0,33105.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",731,18048.0,0.0,36096.0,0,0.0,36096.0,36096.0,124.0,251.0,0.33066666666666666,128000.0,32.0,12.768,3669.919999999991,0.0,0.0,0.0,18048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,3672.319999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",733,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.368,3674.687999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,3677.087999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,3679.551999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,5.0,0.0,64.0,64.0,2.464,3682.015999999991,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",737,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.984,3683.999999999991,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",738,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.048,3686.0479999999907,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",739,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,3688.5759999999905,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",740,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.208,3690.7839999999906,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.464,3693.2479999999905,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,3695.9039999999904,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,3698.3039999999905,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",744,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.072,3701.3759999999907,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",745,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,3704.6079999999906,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",746,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,3707.0079999999907,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
