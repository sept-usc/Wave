Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.864,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.24,7.104,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.656,9.76,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.464,12.224,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.52,15.744,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.36,19.104,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,21.535999999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,23.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,25.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,27.776000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,30.784000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,33.376000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,35.84,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.976,38.816,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,41.248000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.496,43.74400000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.56,46.30400000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,17408.0,65536.0,4.384,50.68800000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,544.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,17408.0,65536.0,3.776,54.46400000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,57.152000000000015,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,59.552000000000014,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.392,62.94400000000002,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.104,74.04800000000002,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206915072.0,196608.0,235.872,309.92,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466096.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.456,313.37600000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,316.44800000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,319.456,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,24.768,344.22400000000005,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.728,429.95200000000006,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.752,432.70400000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.04,443.7440000000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,275105664.0,262144.0,305.824,749.5680000000001,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8597052.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,752.416,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,755.2320000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,758.0160000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,761.056,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,763.744,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,364324.0,908872.0,16384.0,0,0.0,925256.0,925256.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,766.5600000000001,65536.0,131072.0,356132.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.912,769.4720000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.136,772.6080000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",43,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,321.344,1093.952,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1096.608,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",45,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,1107.52,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",46,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206979968.0,196608.0,230.88,1338.4,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6468124.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,2.976,1341.3760000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.2,1344.5760000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,1347.5840000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",50,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.776,1371.3600000000004,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",51,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.568,1456.9280000000003,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,1459.5520000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",53,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.976,1470.5280000000005,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",54,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274145536.0,262144.0,305.12,1775.6480000000006,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8567048.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",55,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,1778.3360000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",56,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,1781.0560000000007,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,1783.8080000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.168,1786.9760000000006,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,1789.7920000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,364632.0,909488.0,16384.0,0,0.0,925872.0,925872.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,1792.5760000000007,65536.0,131072.0,356440.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",61,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,1795.2640000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,2.976,1798.240000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",63,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.632,2123.8720000000008,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.848,2126.7200000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",65,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,2137.6640000000007,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",66,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206936576.0,196608.0,230.752,2368.4160000000006,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466768.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.168,2371.5840000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.04,2374.6240000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,2377.6320000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",70,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.872,2401.5040000000004,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.312,2486.8160000000003,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,2489.44,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.976,2500.416,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274917248.0,262144.0,304.48,2804.896,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8591164.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",75,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.04,2807.936,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",76,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,2810.7200000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,2813.5040000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,2816.5760000000005,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,2819.3280000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",80,364676.0,909576.0,16384.0,0,0.0,925960.0,925960.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,2822.6560000000004,65536.0,131072.0,356484.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",81,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,2825.472,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",82,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.2,2828.672,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",83,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.344,3154.016,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,3156.64,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",85,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.976,3167.616,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",86,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206961024.0,196608.0,231.872,3399.488,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6467532.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.136,3402.624,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.264,3405.888,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,3408.8959999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",90,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.936,3432.832,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,86.176,3519.008,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",92,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.72,3521.7279999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",93,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,3532.6399999999994,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274248320.0,262144.0,306.24,3838.879999999999,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8570260.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",95,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,3841.5679999999993,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",96,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.008,3844.575999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",97,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,3847.263999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.296,3850.559999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",99,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.88,3853.439999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,364112.0,908448.0,16384.0,0,0.0,924832.0,924832.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,3856.959999999999,65536.0,131072.0,355920.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",101,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,3859.7439999999992,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",102,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,3862.783999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.088,4187.871999999999,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,4190.527999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",105,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.816,4201.343999999999,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206949632.0,196608.0,230.56,4431.9039999999995,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6467176.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.04,4434.9439999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,4438.016,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,4441.023999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",110,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.84,4464.864,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",111,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.824,4550.687999999999,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,4553.343999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.008,4564.351999999999,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",114,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,278670720.0,262144.0,307.904,4872.255999999999,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8708460.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",115,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,4874.9439999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",116,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,4877.759999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",117,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,4880.607999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",118,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,2.976,4883.583999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,4886.303999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,364884.0,909992.0,16384.0,0,0.0,926376.0,926376.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,4889.151999999999,65536.0,131072.0,356692.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",121,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,4891.9039999999995,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",122,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,4894.9439999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,328.448,5223.392,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,5226.048,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",125,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,5236.96,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206942720.0,196608.0,230.336,5467.296,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466960.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.136,5470.432000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.04,5473.472000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,5476.4800000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",130,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.936,5500.416,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,86.4,5586.816,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",132,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,5589.472,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",133,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.752,5600.224,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",134,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274233984.0,262144.0,305.92,5906.144,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8569812.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",135,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,5908.832,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",136,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.04,5911.872,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,5914.56,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",138,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.328,5917.888000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",139,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,5920.576000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",140,364968.0,910160.0,16384.0,0,0.0,926544.0,926544.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,5923.424000000001,65536.0,131072.0,356776.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",141,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.04,5926.464000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",142,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.136,5929.600000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",143,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,324.128,6253.728000000001,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,6256.384000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,6267.296000000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206968320.0,196608.0,229.984,6497.280000000002,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6467760.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,6500.352000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,2.976,6503.328000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,6506.336000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",150,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.936,6530.272000000001,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",151,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.984,6616.256000000001,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",152,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,6618.912000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",153,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,6629.824000000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",154,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,277229568.0,262144.0,301.248,6931.072000000001,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8663424.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",155,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,6933.792000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",156,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,6936.5120000000015,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",157,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,6939.232000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,6942.272000000002,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",159,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,6945.056000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",160,364576.0,909376.0,16384.0,0,0.0,925760.0,925760.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,6947.872000000001,65536.0,131072.0,356384.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",161,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,6950.560000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",162,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,6953.600000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",163,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,326.176,7279.776000000002,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,7282.432000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",165,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.072,7293.504000000002,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",166,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206961152.0,196608.0,231.392,7524.896000000002,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6467536.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,7527.904000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.136,7531.040000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",169,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,7534.112000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",170,524288.0,18464768.0,0.0,0,0.0,18464768.0,18464768.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,23.968,7558.080000000002,14221312.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,86.656,7644.736000000002,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,7647.392000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",173,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,7658.336000000002,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274851584.0,262144.0,305.696,7964.032000000002,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8589112.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",175,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,7966.752000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",176,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.976,7969.728000000002,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",177,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,7972.448000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.104,7975.552000000002,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",179,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,7978.272000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,364424.0,909072.0,16384.0,0,0.0,925456.0,925456.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,7981.024000000003,65536.0,131072.0,356232.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.04,7984.064000000003,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,7987.104000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,328.288,8315.392000000003,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.912,8318.304000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",185,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,8329.248000000003,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,837884816.0,1804441664.0,28948256.0,0,0.0,1833389920.0,1833389920.0,10880956.0,9750436.0,0.5273980543823703,1200781696.0,1185632.0,912.544,9241.792000000003,54679616.0,102940672.0,823410688.0,14474128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37524428.0,37051.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,9243.840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",188,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,9246.336000000003,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",189,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,9248.768000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",190,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.648,9252.416000000003,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,9254.560000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",192,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.096,9258.656000000003,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",193,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.464,9265.120000000003,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",194,122572.0,0.0,245144.0,0,0.0,245144.0,245144.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.128,9269.248000000003,0.0,0.0,0.0,122572.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",195,179200.0,0.0,358400.0,0,0.0,358400.0,358400.0,13200.0,82808.0,0.13748854262144822,5029376.0,0.0,6.112,9275.360000000002,0.0,0.0,0.0,179200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",196,101400.0,0.0,202800.0,0,0.0,202800.0,202800.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.32,9279.680000000002,0.0,0.0,0.0,101400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",197,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,13200.0,83608.0,0.13635236757292785,5029376.0,0.0,6.304,9285.984000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",198,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.384,9290.368000000002,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",199,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,13200.0,83208.0,0.13691809808314662,5029376.0,128.0,6.112,9296.480000000001,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",200,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.2,9299.680000000002,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",201,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,9301.696000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",202,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.416,9306.112000000001,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,9308.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",204,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.416,9312.544,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",205,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,60024.0,13020.0,0.8217512732051914,829920.0,8832.0,6.24,9318.784,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,276.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",206,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.208,9324.992,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.64,9329.632,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",208,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.0,9333.632,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",209,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.776,9337.408,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",210,388056.0,0.0,776112.0,0,0.0,776112.0,776112.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.608,9342.016,0.0,0.0,0.0,388056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,9344.608,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",212,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28626.0,0.6967070689947449,2737728.0,1860192.0,16.448,9361.056,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85554.0,58131.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",213,62276.0,0.0,124552.0,0,0.0,124552.0,124552.0,14202.0,28475.0,0.33277878013918505,2724544.0,2451392.0,13.696,9374.752,0.0,0.0,0.0,62276.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85142.0,76606.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",214,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28247.0,0.3500609742067601,2715072.0,1871648.0,14.688,9389.44,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84846.0,58489.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",215,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,13810.0,28316.0,0.3278260456725063,2715456.0,2451392.0,14.976,9404.416000000001,0.0,0.0,0.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84858.0,76606.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",216,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,4.96,9409.376,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.624,9412.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",218,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15362.0,0.49150971500446855,1870624.0,1285632.0,8.832,9420.832,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58457.0,40176.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",219,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429888.0,2412352.0,6.272,9427.104000000001,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75934.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",220,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2277760.0,751040.0,25.408,9452.512,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71180.0,23470.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",221,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804512.0,579136.0,78.816,9531.328000000001,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25141.0,18098.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.296,9534.624000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.176,9536.800000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,77632.0,9.184,9545.984,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2426.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",225,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.968,9549.952000000001,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",226,3284172.0,6655044.0,939560.0,0,0.0,7594604.0,7594604.0,528.0,6704.0,0.07300884955752213,2277120.0,751488.0,25.472,9575.424,825232.0,201028.0,2814392.0,469780.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71160.0,23484.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",227,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.656,9582.080000000002,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.496,9584.576000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",229,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.784,9591.36,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,9593.792000000001,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",231,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,9596.448000000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,9599.680000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",233,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,13.056,9612.736000000003,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",234,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.464,9615.200000000003,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",235,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.328,9618.528000000002,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,9621.024000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,9624.256000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",238,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.192,9628.448,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",239,1210568.0,2017280.0,403856.0,0,0.0,2421136.0,2421136.0,0.0,4737.0,0.0,1608256.0,0.0,5.248,9633.696,0.0,0.0,1008640.0,201928.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",240,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,17.696,9651.392,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.368,9653.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,9656.192000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,9658.688,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,9661.12,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,9663.616,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",246,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,9665.664,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",247,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,9667.744,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",248,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,9670.24,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",249,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,9672.288,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.688,9674.976,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",251,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.792,9680.768,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",252,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.592,9683.36,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,9685.792000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",254,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,9688.864000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",255,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.264,9692.128,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",256,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.368,9694.496000000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",257,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,9696.928000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",258,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.264,9700.192000000001,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",259,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.976,9703.168000000001,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,9705.600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",261,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.4,9708.000000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",262,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.496,9710.496000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.528,9713.024000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",264,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,66560.0,65536.0,6.208,9719.232000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2080.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",265,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,17408.0,65536.0,3.776,9723.008000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",266,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,9725.664000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",267,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.496,9728.160000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",268,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.328,9731.488000000001,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",269,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.168,9742.656,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",270,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206916224.0,196608.0,230.656,9973.312000000002,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466132.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",271,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.68,9976.992000000002,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",272,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.712,9980.704000000002,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,9983.712000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",274,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,23.776,10007.488000000001,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.248,10092.736,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",276,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,10095.392000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.008,10106.400000000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,275293312.0,262144.0,304.384,10410.784000000001,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8602916.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",279,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,10413.536000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",280,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,10416.352000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",281,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,10419.168000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,10422.240000000003,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,10424.992000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",284,364257.0,908738.0,16384.0,0,0.0,925122.0,925122.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,10427.808000000005,65536.0,131072.0,356065.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",285,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,10430.528000000004,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",286,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.104,10433.632000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,321.12,10754.752000000004,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",288,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,10757.376000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",289,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.752,10768.128000000004,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",290,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206932480.0,196608.0,230.688,10998.816000000004,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466640.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",291,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.744,11002.560000000005,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",292,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.68,11006.240000000005,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.008,11009.248000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",294,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,23.808,11033.056000000006,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,86.272,11119.328000000007,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",296,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.752,11122.080000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",297,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,11133.024000000007,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,276137216.0,262144.0,306.24,11439.264000000006,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8629288.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,11442.016000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",300,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,11444.832000000008,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",301,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,11447.584000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.104,11450.688000000007,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",303,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,11453.376000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",304,364384.0,908992.0,16384.0,0,0.0,925376.0,925376.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,11456.192000000008,65536.0,131072.0,356192.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,11459.040000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",306,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,11462.112000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",307,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,323.392,11785.504000000008,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",308,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,11788.128000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",309,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.88,11799.008000000007,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",310,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206914560.0,196608.0,230.88,12029.888000000006,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466080.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.648,12033.536000000006,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",312,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.68,12037.216000000006,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.04,12040.256000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",314,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,24.096,12064.352000000006,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",315,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.696,12150.048000000006,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,12152.704000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",317,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,12163.648000000007,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",318,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274639232.0,262144.0,304.864,12468.512000000006,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8582476.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",319,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,12471.296000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",320,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,12474.080000000005,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",321,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,12476.768000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",322,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.136,12479.904000000006,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",323,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,12482.624000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",324,364136.0,908496.0,16384.0,0,0.0,924880.0,924880.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,12485.440000000006,65536.0,131072.0,355944.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",325,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,12488.128000000006,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",326,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,12491.200000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",327,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.088,12816.288000000006,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.752,12819.040000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",329,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,12829.952000000007,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",330,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206925312.0,196608.0,230.432,13060.384000000007,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466416.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.648,13064.032000000007,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.904,13067.936000000007,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.136,13071.072000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",334,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,23.936,13095.008000000007,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.664,13180.672000000008,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",336,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.72,13183.392000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",337,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.976,13194.368000000008,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",338,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,275189504.0,262144.0,306.944,13501.312000000007,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8599672.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",339,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,13504.000000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",340,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,13506.688000000007,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,13509.472000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.168,13512.640000000007,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",343,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,13515.392000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,364034.0,908292.0,16384.0,0,0.0,924676.0,924676.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,13518.208000000008,65536.0,131072.0,355842.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.912,13521.120000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",346,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.008,13524.128000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",347,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,324.96,13849.088000000007,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,13851.744000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.04,13862.784000000009,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206939392.0,196608.0,231.68,14094.464000000009,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466856.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.616,14098.080000000009,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.648,14101.728000000008,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.104,14104.832000000008,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",354,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,23.776,14128.608000000007,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",355,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.408,14214.016000000007,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",356,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,14216.672000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",357,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.912,14227.584000000008,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",358,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274329344.0,262144.0,307.008,14534.592000000008,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8572792.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",359,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,14537.280000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",360,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,14540.032000000008,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,14542.752000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",362,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,14545.824000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,14548.512000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,364514.0,909252.0,16384.0,0,0.0,925636.0,925636.0,0.0,1024.0,0.0,262144.0,262144.0,3.008,14551.520000000008,65536.0,131072.0,356322.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",365,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,14554.240000000007,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",366,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.072,14557.312000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.376,14882.688000000007,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,14885.344000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.008,14896.352000000008,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",370,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206919168.0,196608.0,231.232,15127.584000000008,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466224.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",371,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.744,15131.328000000009,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",372,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.648,15134.976000000008,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,15138.048000000008,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",374,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,24.096,15162.144000000008,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",375,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,85.344,15247.488000000007,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",376,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,15250.144000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",377,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.976,15261.120000000008,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",378,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274133888.0,262144.0,309.472,15570.592000000008,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8566684.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",379,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,15573.440000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",380,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,15576.224000000007,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",381,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,15578.944000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.2,15582.144000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,15584.832000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,364756.0,909736.0,16384.0,0,0.0,926120.0,926120.0,0.0,1024.0,0.0,262144.0,262144.0,2.848,15587.680000000008,65536.0,131072.0,356564.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",385,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,15590.432000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",386,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,15593.472000000009,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",387,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,323.552,15917.024000000009,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,15919.68000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",389,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.104,15930.784000000009,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",390,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206914048.0,196608.0,231.168,16161.952000000008,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466064.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.616,16165.568000000008,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.68,16169.248000000009,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",393,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.136,16172.38400000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",394,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,24.128,16196.51200000001,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",395,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,86.144,16282.65600000001,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.592,16285.24800000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",397,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,16296.19200000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",398,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,274167296.0,262144.0,307.36,16603.55200000001,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8567728.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",399,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,16606.30400000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",400,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,16609.08800000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,16611.80800000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.104,16614.91200000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",403,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.72,16617.632000000012,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,364164.0,908552.0,16384.0,0,0.0,924936.0,924936.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,16620.416000000012,65536.0,131072.0,355972.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",405,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.784,16623.20000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",406,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,16626.240000000013,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.376,16951.616000000013,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,16954.27200000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",409,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.88,16965.152000000013,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",410,201768960.0,406683648.0,884736.0,0,0.0,407568384.0,407568384.0,1724160.0,1673472.0,0.5074593128390597,206939776.0,196608.0,229.792,17194.944000000014,884736.0,3145728.0,201326592.0,442368.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6466868.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.68,17198.624000000014,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,237568.0,0.0,475136.0,0,0.0,475136.0,475136.0,0.0,2048.0,0.0,131072.0,131072.0,3.648,17202.272000000015,0.0,0.0,0.0,237568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1024.0,0.0,65536.0,65536.0,3.072,17205.344000000016,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",414,524288.0,18481152.0,0.0,0,0.0,18481152.0,18481152.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,23.808,17229.152000000016,14237696.0,3194880.0,524288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,67272704.0,135856128.0,327680.0,0,0.0,136183808.0,136183808.0,592384.0,558080.0,0.5149087672452158,71319552.0,65536.0,89.216,17318.368000000017,589824.0,1048576.0,67108864.0,163840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2228736.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,17321.024000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,11.008,17332.032000000017,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,269025280.0,542244864.0,1179648.0,0,0.0,543424512.0,543424512.0,2298880.0,2231296.0,0.5074593128390597,276023040.0,262144.0,305.824,17637.856000000018,1179648.0,4194304.0,268435456.0,589824.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8625720.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",419,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,17640.544000000016,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",420,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.752,17643.296000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",421,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,17645.984000000015,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.008,17648.992000000017,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,17651.680000000015,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,364274.0,908772.0,16384.0,0,0.0,925156.0,925156.0,0.0,1024.0,0.0,262144.0,262144.0,2.816,17654.496000000014,65536.0,131072.0,356082.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,2.688,17657.184000000012,0.0,0.0,65536.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.04,17660.224000000013,0.0,65536.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16384.0,8192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,268992512.0,543227904.0,1114112.0,0,0.0,544342016.0,544342016.0,2361856.0,2229248.0,0.5144418423106948,285229056.0,65536.0,325.76,17985.98400000001,2162688.0,4194304.0,268435456.0,557056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8913408.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",428,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,17988.64000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",429,93764.0,306420.0,3072.0,0,0.0,309492.0,309492.0,68.0,1416.0,0.04582210242587601,196608.0,65792.0,10.944,17999.58400000001,92720.0,29244.0,92228.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,837884816.0,1804441664.0,28948256.0,0,0.0,1833389920.0,1833389920.0,10880956.0,9750436.0,0.5273980543823703,1197202304.0,1177248.0,912.128,18911.71200000001,54679616.0,102940672.0,823410688.0,14474128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,37412572.0,36789.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",431,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,18913.72800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.464,18916.19200000001,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",433,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,18918.62400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.392,18922.01600000001,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,18924.03200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",436,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.128,18928.16000000001,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",437,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.08,18934.240000000013,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",438,122337.0,0.0,244674.0,0,0.0,244674.0,244674.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.064,18938.30400000001,0.0,0.0,0.0,122337.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",439,185600.0,0.0,371200.0,0,0.0,371200.0,371200.0,13200.0,83008.0,0.13720272742391484,5029376.0,0.0,6.4,18944.704000000012,0.0,0.0,0.0,185600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",440,101405.0,0.0,202810.0,0,0.0,202810.0,202810.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.32,18949.024000000012,0.0,0.0,0.0,101405.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",441,187200.0,0.0,374400.0,0,0.0,374400.0,374400.0,13200.0,83058.0,0.1371314592033909,5029376.0,0.0,6.272,18955.296000000013,0.0,0.0,0.0,187200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",442,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.224,18959.52000000001,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",443,187200.0,0.0,374400.0,0,0.0,374400.0,374400.0,13200.0,83058.0,0.1371314592033909,5029376.0,128.0,6.336,18965.85600000001,0.0,0.0,0.0,187200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",444,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.072,18968.92800000001,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",445,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,18971.008000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",446,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.416,18975.424000000014,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,18977.440000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",448,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.384,18981.82400000001,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",449,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,56621.0,13016.0,0.813087869954191,829920.0,8768.0,6.272,18988.096000000012,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,274.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",450,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.24,18994.336000000014,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.096,18998.432000000015,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",452,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.84,19002.272000000015,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",453,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.776,19006.048000000017,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",454,388053.0,0.0,776106.0,0,0.0,776106.0,776106.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.832,19010.880000000016,0.0,0.0,0.0,388053.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",455,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,19013.472000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",456,186692.0,0.0,373384.0,0,0.0,373384.0,373384.0,64746.0,28932.0,0.6911548068916928,2748224.0,1888224.0,16.128,19029.600000000017,0.0,0.0,0.0,186692.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85882.0,59007.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",457,65732.0,0.0,131464.0,0,0.0,131464.0,131464.0,15606.0,28243.0,0.35590321330018926,2710208.0,1683424.0,14.4,19044.00000000002,0.0,0.0,0.0,65732.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84694.0,52607.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",458,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28094.0,0.35129768172162185,2720448.0,1873280.0,14.528,19058.528000000017,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85014.0,58540.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",459,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,13810.0,28319.0,0.3278027012271832,2714688.0,2451648.0,15.104,19073.632000000016,0.0,0.0,0.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84834.0,76614.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",460,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,4.8,19078.432000000015,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.656,19081.088000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",462,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15248.0,0.49337143236867465,1869984.0,1281664.0,8.864,19089.952000000016,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58437.0,40052.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",463,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429472.0,2412352.0,6.112,19096.064000000017,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75921.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",464,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2281472.0,752192.0,25.344,19121.408000000018,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71296.0,23506.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",465,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804416.0,579552.0,78.56,19199.96800000002,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25138.0,18111.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",466,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.424,19203.392000000018,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.112,19205.50400000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,77952.0,9.056,19214.56000000002,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2436.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",469,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.968,19218.52800000002,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",470,3284170.0,6655044.0,939556.0,0,0.0,7594600.0,7594600.0,528.0,6704.0,0.07300884955752213,2282624.0,750976.0,25.44,19243.96800000002,825232.0,201028.0,2814392.0,469778.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71332.0,23468.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",471,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.592,19250.56000000002,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,19252.99200000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",473,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.56,19259.55200000002,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",474,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,19261.984000000022,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",475,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,19264.51200000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,19267.80800000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",477,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,13.088,19280.89600000002,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",478,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.464,19283.36000000002,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",479,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,19286.656000000017,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,19289.05600000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",481,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,19292.25600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",482,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.192,19296.44800000002,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",483,1210566.0,2017280.0,403852.0,0,0.0,2421132.0,2421132.0,0.0,4737.0,0.0,1608256.0,0.0,5.312,19301.76000000002,0.0,0.0,1008640.0,201926.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",484,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804320.0,128.0,17.76,19319.52000000002,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25135.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",485,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,19321.95200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,19324.41600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,19326.91200000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,19329.440000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.4,19331.84000000002,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",490,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,19333.888000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",491,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.112,19336.00000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",492,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,19338.496000000017,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",493,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.144,19340.640000000018,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.528,19343.168000000016,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.824,19348.992000000017,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",496,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,19351.488000000016,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",497,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.4,19353.888000000017,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",498,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,19356.960000000017,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",499,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.168,19360.12800000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",500,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.368,19362.496000000017,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
