Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.664,1.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.664,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.536,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,12.032,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.84,15.872,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.296,19.168,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.848,22.016,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,24.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,26.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.272,28.351999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.88,31.231999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,33.727999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,36.12799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.912,39.03999999999999,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,41.50399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,43.93599999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.56,46.495999999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,4352.0,16384.0,4.288,50.78399999999999,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,136.0,512.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,4352.0,16384.0,4.128,54.91199999999999,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,136.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,57.535999999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,59.93599999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.424,63.35999999999999,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,68.416,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,22.912,91.328,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.456,94.784,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.008,97.792,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,100.83200000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,11.552,112.38400000000001,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),31,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.416,120.80000000000001,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",32,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.232,124.03200000000001,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.008,127.04,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.152,132.192,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.968,156.16,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,158.784,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.752,161.536,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,164.096,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,166.752,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,169.312,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,96248.0,237552.0,4096.0,0,0.0,241648.0,241648.0,0.0,256.0,0.0,65536.0,65536.0,2.816,172.12800000000001,16384.0,32768.0,94200.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,174.72000000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.624,177.34400000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",44,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.92,247.264,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,249.888,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,254.976,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.408,276.384,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.264,279.648,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,282.68800000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.008,285.696,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.336,296.03200000000004,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),52,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.864,304.896,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",53,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.104,308.0,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",54,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,310.624,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",55,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,315.71200000000005,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.872,339.58400000000006,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.656,342.24000000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",58,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,344.8640000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,347.4560000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,350.1120000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.784,352.8960000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,96264.0,237584.0,4096.0,0,0.0,241680.0,241680.0,0.0,256.0,0.0,65536.0,65536.0,2.848,355.7440000000001,16384.0,32768.0,94216.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,358.33600000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.624,360.9600000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",65,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.016,430.9760000000001,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,433.5680000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.216,438.7840000000001,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.76,460.5440000000001,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,463.5840000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,466.62400000000014,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.136,469.76000000000016,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.24,480.00000000000017,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),73,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.608,488.6080000000002,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",74,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.136,491.7440000000002,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,494.3360000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",76,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.312,499.6480000000002,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",77,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.552,523.2000000000002,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",78,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.784,525.9840000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",79,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,528.5760000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,531.1360000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.624,533.7600000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,536.3520000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,96016.0,237088.0,4096.0,0,0.0,241184.0,241184.0,0.0,256.0,0.0,65536.0,65536.0,2.752,539.104,16384.0,32768.0,93968.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,541.696,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",85,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.624,544.32,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",86,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.472,613.792,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,616.384,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,621.44,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.696,643.1360000000001,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,646.176,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,649.216,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.296,652.5120000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.24,662.7520000000001,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),94,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.48,671.2320000000001,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,674.3040000000001,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,676.8960000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,681.9520000000001,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.744,705.6960000000001,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",99,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,708.3200000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",100,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,710.9120000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",101,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,713.5360000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,716.2240000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,718.7840000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",104,96216.0,237488.0,4096.0,0,0.0,241584.0,241584.0,0.0,256.0,0.0,65536.0,65536.0,2.72,721.5040000000001,16384.0,32768.0,94168.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",105,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,724.0960000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",106,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,726.8160000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.824,796.6400000000001,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,799.2,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,804.2560000000001,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",110,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.696,825.9520000000001,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,829.0240000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.136,832.1600000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.168,835.3280000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.304,845.6320000000001,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),115,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.992,854.624,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.104,857.7280000000001,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",117,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,860.32,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",118,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,865.3760000000001,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",119,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.616,888.9920000000001,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",120,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,891.6160000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",121,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,894.2080000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",122,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.816,897.0240000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",123,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,899.7120000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.784,902.4960000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,96332.0,237720.0,4096.0,0,0.0,241816.0,241816.0,0.0,256.0,0.0,65536.0,65536.0,2.688,905.1840000000001,16384.0,32768.0,94284.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",126,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.656,907.84,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",127,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.592,910.432,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.984,980.416,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,983.008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.12,988.128,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.664,1009.792,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.104,1012.8960000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.136,1016.032,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,1019.072,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.432,1029.504,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),136,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.288,1037.792,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",137,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,1040.8639999999998,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",138,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1043.456,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",139,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.024,1048.4799999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.616,1072.0959999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",141,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,1074.6559999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",142,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.56,1077.2159999999997,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",143,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.656,1079.8719999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1082.5279999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",145,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,1085.0879999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,96132.0,237320.0,4096.0,0,0.0,241416.0,241416.0,0.0,256.0,0.0,65536.0,65536.0,2.624,1087.7119999999995,16384.0,32768.0,94084.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",147,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,1090.3359999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",148,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.848,1093.1839999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.56,1163.7439999999995,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1166.3679999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,1171.4559999999994,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,20.832,1192.2879999999996,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,1195.3279999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,1198.3679999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,1201.4399999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.336,1211.7759999999994,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),157,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,9.216,1220.9919999999993,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.2,1224.1919999999993,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",159,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,1226.8799999999994,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",160,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.12,1231.9999999999993,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.808,1255.8079999999993,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,1258.4319999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",163,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.656,1261.0879999999993,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",164,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.912,1263.9999999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.816,1266.8159999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",166,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,1269.4399999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,96384.0,237824.0,4096.0,0,0.0,241920.0,241920.0,0.0,256.0,0.0,65536.0,65536.0,2.784,1272.2239999999995,16384.0,32768.0,94336.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,1274.8159999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",169,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,1277.4719999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.432,1347.9039999999995,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,1350.5919999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,1355.6479999999997,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.888,1377.5359999999996,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,1380.6079999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,1383.6799999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,1386.7519999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,131072.0,4616192.0,0.0,0,0.0,4616192.0,4616192.0,34048.0,64.0,0.99812382739212,49152.0,16384.0,10.304,1397.0559999999994,3555328.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),178,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.736,1405.7919999999995,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",179,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.232,1409.0239999999994,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,1411.6159999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",181,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.152,1416.7679999999996,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",182,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.712,1440.4799999999996,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.656,1443.1359999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",184,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.656,1445.7919999999995,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,1448.3519999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",186,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.72,1451.0719999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",187,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,1453.6639999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,96280.0,237616.0,4096.0,0,0.0,241712.0,241712.0,0.0,256.0,0.0,65536.0,65536.0,2.656,1456.3199999999995,16384.0,32768.0,94232.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",189,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.56,1458.8799999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.784,1461.6639999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.048,1531.7119999999995,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,1534.3359999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,1539.4239999999995,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,210677456.0,453522752.0,9649568.0,0,0.0,463172320.0,463172320.0,3040636.0,2512996.0,0.5475040478015107,285283968.0,1175040.0,231.776,1771.1999999999996,16082240.0,25735168.0,205852672.0,4824784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8915124.0,36720.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,1773.2799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,1775.7759999999996,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1778.2079999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.36,1781.5679999999995,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,1783.6799999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.128,1787.8079999999995,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.464,1794.2719999999995,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,102680.0,0.0,205360.0,0,0.0,205360.0,205360.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.576,1798.8479999999995,0.0,0.0,0.0,102680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,13200.0,83608.0,0.13635236757292785,5029376.0,0.0,7.136,1805.9839999999995,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,101400.0,0.0,202800.0,0,0.0,202800.0,202800.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.064,1810.0479999999995,0.0,0.0,0.0,101400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,166400.0,0.0,332800.0,0,0.0,332800.0,332800.0,13200.0,82408.0,0.13806376035478202,5029376.0,0.0,6.528,1816.5759999999996,0.0,0.0,0.0,166400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.224,1820.7999999999995,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,166400.0,0.0,332800.0,0,0.0,332800.0,332800.0,13200.0,82408.0,0.13806376035478202,5029376.0,128.0,6.4,1827.1999999999996,0.0,0.0,0.0,166400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.072,1830.2719999999995,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,1832.3199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.384,1836.7039999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1838.7839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.608,1843.3919999999994,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,46412.0,13004.0,0.7811363942372425,829920.0,8480.0,6.208,1849.5999999999995,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,265.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.272,1855.8719999999994,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.256,1860.1279999999995,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.808,1863.9359999999995,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.744,1867.6799999999994,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,387860.0,0.0,775720.0,0,0.0,775720.0,775720.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.704,1872.3839999999993,0.0,0.0,0.0,387860.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.656,1875.0399999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28799.0,0.6954323846991761,2728896.0,1884736.0,16.864,1891.9039999999993,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85278.0,58898.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,62276.0,0.0,124552.0,0,0.0,124552.0,124552.0,14202.0,28443.0,0.3330284910306015,2725312.0,2451520.0,13.856,1905.7599999999993,0.0,0.0,0.0,62276.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85166.0,76610.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28365.0,0.3491131049358636,2718784.0,2452032.0,14.688,1920.4479999999994,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84962.0,76626.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28422.0,0.3486570721422679,2718144.0,1870400.0,14.624,1935.0719999999994,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84942.0,58450.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,4.928,1939.9999999999995,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,1942.5599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15043.0,0.4967549846112672,1868448.0,1283360.0,8.864,1951.4239999999995,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58389.0,40105.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2428928.0,2412352.0,6.176,1957.5999999999995,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75904.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2279680.0,750976.0,25.408,1983.0079999999994,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71240.0,23468.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804416.0,581024.0,78.496,2061.5039999999995,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25138.0,18157.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.36,2064.8639999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,2067.0079999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,78272.0,8.992,2075.9999999999995,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2446.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.032,2080.0319999999997,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,3284168.0,6655044.0,939552.0,0,0.0,7594596.0,7594596.0,528.0,6704.0,0.07300884955752213,2280192.0,751424.0,25.344,2105.3759999999997,825232.0,201028.0,2814392.0,469776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71256.0,23482.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.88,2112.256,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,2114.72,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.752,2121.4719999999998,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2123.9039999999995,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.688,2126.5919999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.296,2129.8879999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804256.0,128.0,12.96,2142.8479999999995,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.464,2145.3119999999994,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.456,2148.7679999999996,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,2151.2639999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2154.528,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.096,2158.624,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,1210564.0,2017280.0,403848.0,0,0.0,2421128.0,2421128.0,0.0,4737.0,0.0,1608256.0,0.0,5.312,2163.9359999999997,0.0,0.0,1008640.0,201924.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,17.728,2181.6639999999998,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,2184.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2186.5919999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,2189.1199999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,2191.6159999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.56,2194.1759999999995,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2196.2239999999993,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2198.271999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.688,2200.959999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2203.007999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.816,2205.8239999999987,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.632,2211.4559999999988,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,2213.9839999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,2216.4159999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,2219.4879999999985,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.2,2222.6879999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2225.0879999999984,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2227.519999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.328,2230.847999999998,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.976,2233.8239999999983,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,2236.255999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.464,2238.719999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.432,2241.1519999999978,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.432,2243.5839999999976,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,16640.0,16384.0,4.704,2248.2879999999977,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,520.0,512.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,384.0,0.0,4352.0,16384.0,3.712,2251.9999999999977,0.0,0.0,0.0,5120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,136.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,2254.6559999999977,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.464,2257.1199999999976,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.328,2260.4479999999976,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.152,2265.5999999999976,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.664,2287.263999999998,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.616,2290.879999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.776,2294.6559999999977,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.072,2297.727999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.272,2307.9999999999977,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),283,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.576,2316.5759999999977,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",284,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,2319.647999999998,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2322.239999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",286,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,2327.295999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.616,2350.911999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2353.535999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",289,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2356.1599999999976,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",290,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2358.7519999999977,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,2361.4079999999976,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2364.0319999999974,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,96346.0,237748.0,4096.0,0,0.0,241844.0,241844.0,0.0,256.0,0.0,65536.0,65536.0,2.656,2366.6879999999974,16384.0,32768.0,94298.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",294,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.752,2369.4399999999973,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,2372.0959999999973,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.592,2442.6879999999974,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,2445.3759999999975,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,2450.4639999999977,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",299,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.568,2472.031999999998,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.776,2475.8079999999977,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.648,2479.455999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,2482.495999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.4,2492.895999999998,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),304,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.768,2501.663999999998,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.232,2504.895999999998,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.72,2507.6159999999977,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,2512.703999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.904,2536.607999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2539.199999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",310,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.656,2541.855999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",311,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2544.447999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",312,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,2547.135999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2549.7279999999982,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,96223.0,237502.0,4096.0,0,0.0,241598.0,241598.0,0.0,256.0,0.0,65536.0,65536.0,2.688,2552.4159999999983,16384.0,32768.0,94175.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",315,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2555.039999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",316,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.72,2557.759999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",317,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.344,2627.103999999998,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2629.695999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.152,2634.847999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",320,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.6,2656.447999999998,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.712,2660.159999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.648,2663.807999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,2666.847999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.24,2677.087999999998,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),325,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.576,2685.663999999998,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",326,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.104,2688.7679999999978,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",327,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2691.359999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",328,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,2696.447999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",329,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.808,2720.255999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",330,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2722.879999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",331,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.656,2725.535999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",332,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2728.127999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,2730.815999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",334,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2733.407999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,96128.0,237312.0,4096.0,0,0.0,241408.0,241408.0,0.0,256.0,0.0,65536.0,65536.0,2.688,2736.095999999998,16384.0,32768.0,94080.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",336,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2738.6879999999983,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.624,2741.311999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",338,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.28,2810.5919999999983,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2813.1839999999984,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.28,2818.4639999999986,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",341,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.856,2840.319999999999,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.68,2843.9999999999986,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.712,2847.7119999999986,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,2850.7519999999986,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.464,2861.2159999999985,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),346,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.8,2870.0159999999987,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",347,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,2873.087999999999,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2875.679999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.184,2880.863999999999,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.68,2904.543999999999,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,2907.1679999999988,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",352,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2909.759999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2912.351999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,2915.007999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",355,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.72,2917.7279999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,96204.0,237464.0,4096.0,0,0.0,241560.0,241560.0,0.0,256.0,0.0,65536.0,65536.0,2.656,2920.3839999999987,16384.0,32768.0,94156.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,2922.9759999999987,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.688,2925.663999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",359,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.312,2994.9759999999987,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,2997.567999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,3002.623999999999,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.536,3024.159999999999,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.68,3027.839999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.712,3031.5519999999988,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,3034.5919999999987,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.304,3044.895999999999,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),367,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.8,3053.695999999999,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",368,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,3056.767999999999,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",369,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3059.423999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",370,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.024,3064.447999999999,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",371,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.648,3088.095999999999,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3090.687999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",373,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.72,3093.407999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3095.999999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3098.655999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3101.247999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,96236.0,237528.0,4096.0,0,0.0,241624.0,241624.0,0.0,256.0,0.0,65536.0,65536.0,2.944,3104.191999999999,16384.0,32768.0,94188.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",378,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3106.783999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.752,3109.535999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",380,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,69.216,3178.751999999999,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.688,3181.439999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.12,3186.559999999999,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.312,3207.871999999999,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.712,3211.583999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.616,3215.199999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.04,3218.239999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.336,3228.5759999999987,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),388,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.448,3237.0239999999985,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",389,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,3240.0959999999986,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.752,3242.8479999999986,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",391,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,3247.9039999999986,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.584,3271.4879999999985,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3274.0799999999986,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",394,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3276.6719999999987,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3279.2639999999988,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,3281.951999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.624,3284.5759999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,96287.0,237630.0,4096.0,0,0.0,241726.0,241726.0,0.0,256.0,0.0,65536.0,65536.0,2.784,3287.3599999999988,16384.0,32768.0,94239.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.56,3289.9199999999987,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",400,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3292.5759999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.112,3362.6879999999987,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.56,3365.2479999999987,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.024,3370.2719999999986,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.536,3391.8079999999986,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.712,3395.5199999999986,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.68,3399.1999999999985,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,3.008,3402.2079999999983,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.336,3412.543999999998,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),409,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.8,3421.3439999999982,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",410,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.04,3424.383999999998,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3426.9759999999983,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",412,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.024,3431.999999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",413,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.68,3455.679999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.848,3458.527999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",415,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.784,3461.311999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",416,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,3463.871999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.752,3466.623999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.688,3469.311999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,96186.0,237428.0,4096.0,0,0.0,241524.0,241524.0,0.0,256.0,0.0,65536.0,65536.0,2.688,3471.999999999998,16384.0,32768.0,94138.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",420,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,3474.623999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",421,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.752,3477.375999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",422,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.688,3548.063999999998,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.624,3550.687999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.024,3555.7119999999977,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,12632064.0,25509888.0,98304.0,0,0.0,25608192.0,25608192.0,112512.0,105216.0,0.5167548500881834,13381632.0,49152.0,21.248,3576.9599999999978,147456.0,196608.0,12582912.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,418176.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.648,3580.607999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,3.648,3584.255999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,256.0,0.0,16384.0,16384.0,2.976,3587.231999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,131072.0,4620288.0,0.0,0,0.0,4620288.0,4620288.0,34048.0,64.0,0.99812382739212,81920.0,16384.0,10.432,3597.663999999998,3559424.0,798720.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2560.0,512.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),430,33570816.0,67371008.0,32768.0,0,0.0,67403776.0,67403776.0,115456.0,1024.0,0.9912087912087912,4325376.0,131072.0,8.352,3606.015999999998,0.0,262144.0,33554432.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,135168.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",431,24576.0,40960.0,49152.0,0,0.0,90112.0,90112.0,0.0,1920.0,0.0,135168.0,16384.0,3.072,3609.087999999998,36864.0,4096.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4224.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.592,3611.679999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",433,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.056,3616.735999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",434,16842752.0,34013184.0,131072.0,0,0.0,34144256.0,34144256.0,150016.0,140288.0,0.5167548500881834,17842176.0,65536.0,23.456,3640.191999999998,196608.0,262144.0,16777216.0,65536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557568.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3642.7839999999983,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",436,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.624,3645.407999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3647.999999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,2.688,3650.6879999999983,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,2.56,3653.2479999999982,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,96307.0,237670.0,4096.0,0,0.0,241766.0,241766.0,0.0,256.0,0.0,65536.0,65536.0,2.656,3655.903999999998,16384.0,32768.0,94259.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",441,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,256.0,0.0,65536.0,65536.0,2.592,3658.4959999999983,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",442,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,2.656,3661.151999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,16818176.0,33964032.0,81920.0,0,0.0,34045952.0,34045952.0,148096.0,139520.0,0.5149087672452158,17829888.0,16384.0,70.336,3731.487999999998,147456.0,262144.0,16777216.0,40960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,557184.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,2.656,3734.143999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,512.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,32324.0,109812.0,3072.0,0,0.0,112884.0,112884.0,68.0,360.0,0.1588785046728972,49152.0,16640.0,5.088,3739.231999999998,31280.0,16956.0,30788.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,520.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,210677456.0,453522752.0,9649568.0,0,0.0,463172320.0,463172320.0,3040636.0,2512996.0,0.5475040478015107,284267008.0,1178912.0,231.36,3970.5919999999983,16082240.0,25735168.0,205852672.0,4824784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8883344.0,36841.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,3972.6079999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.528,3975.135999999998,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,3977.567999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.328,3980.895999999998,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,3983.007999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.128,3987.135999999998,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.72,3993.855999999998,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,102564.0,0.0,205128.0,0,0.0,205128.0,205128.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.256,3998.111999999998,0.0,0.0,0.0,102564.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,208000.0,0.0,416000.0,0,0.0,416000.0,416000.0,13200.0,83708.0,0.13621166467164733,5029376.0,0.0,6.464,4004.5759999999977,0.0,0.0,0.0,208000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,101394.0,0.0,202788.0,0,0.0,202788.0,202788.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.128,4008.703999999998,0.0,0.0,0.0,101394.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,187200.0,0.0,374400.0,0,0.0,374400.0,374400.0,13200.0,83058.0,0.1371314592033909,5029376.0,0.0,6.464,4015.167999999998,0.0,0.0,0.0,187200.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.448,4019.6159999999977,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,13200.0,83208.0,0.13691809808314662,5029376.0,128.0,6.368,4025.9839999999976,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.136,4029.1199999999976,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4031.1679999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.384,4035.5519999999974,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4037.599999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.448,4042.047999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,46371.0,13014.0,0.7808537509472089,829920.0,8512.0,6.336,4048.383999999997,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,266.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.208,4054.591999999997,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.288,4058.879999999997,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.904,4062.783999999997,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.68,4066.4639999999968,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,387851.0,0.0,775702.0,0,0.0,775702.0,775702.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.512,4070.975999999997,0.0,0.0,0.0,387851.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.624,4073.5999999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28512.0,0.6975495915985997,2726208.0,1876128.0,16.416,4090.015999999997,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85194.0,58629.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,65732.0,0.0,131464.0,0,0.0,131464.0,131464.0,15606.0,28322.0,0.35526315789473684,2719168.0,1520256.0,14.656,4104.671999999997,0.0,0.0,0.0,65732.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84974.0,47508.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28299.0,0.34964263553420816,2717248.0,2340288.0,14.688,4119.359999999997,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84914.0,73134.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28539.0,0.34772472744726074,2719040.0,2223808.0,14.208,4133.567999999997,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84970.0,69494.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,4.992,4138.559999999997,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,4141.151999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15351.0,0.4916887417218543,1862688.0,1284128.0,8.896,4150.047999999996,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58209.0,40129.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429568.0,2412352.0,6.112,4156.159999999996,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75924.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2276352.0,751296.0,25.312,4181.471999999996,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71136.0,23478.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804352.0,579712.0,78.624,4260.095999999996,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25136.0,18116.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.36,4263.455999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,4265.599999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,75552.0,8.832,4274.431999999996,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2361.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,3.904,4278.335999999997,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,3284168.0,6655044.0,939552.0,0,0.0,7594596.0,7594596.0,528.0,6704.0,0.07300884955752213,2280448.0,751360.0,25.664,4303.999999999996,825232.0,201028.0,2814392.0,469776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71264.0,23480.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.56,4310.559999999997,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,4312.991999999997,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,6.592,4319.583999999996,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.528,4322.111999999996,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.56,4324.671999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,4327.903999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,13.312,4341.215999999997,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.432,4343.6479999999965,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.328,4346.975999999997,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4349.407999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4352.6079999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.096,4356.703999999996,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,1210564.0,2017280.0,403848.0,0,0.0,2421128.0,2421128.0,0.0,4737.0,0.0,1608256.0,0.0,5.216,4361.919999999996,0.0,0.0,1008640.0,201924.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804288.0,128.0,17.632,4379.551999999996,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25134.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.4,4381.951999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4384.3839999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,4386.911999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.464,4389.375999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.528,4391.903999999996,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4393.951999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4395.999999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,4398.527999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4400.5759999999955,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.56,4403.135999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.76,4408.895999999996,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.56,4411.4559999999965,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,4413.887999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,4416.991999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.2,4420.191999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,4422.591999999996,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
