Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,2.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,6.08,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.368,8.448,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.008,11.456,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,14.271999999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.224,18.496,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.584,22.08,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.232,25.311999999999998,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,27.647999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,30.015999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.432,32.44799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.2,35.647999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,38.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.816,41.28,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.264,44.544000000000004,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,47.29600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,50.04800000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.944,52.99200000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,13056.0,49152.0,4.512,57.50400000000001,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,408.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,13056.0,49152.0,4.48,61.98400000000001,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.848,64.83200000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.752,67.584,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,4.032,71.616,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.408,81.024,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),26,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116698112.0,294912.0,135.712,216.736,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646816.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",27,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.44,222.176,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.584,225.76,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.424,229.184,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,232.672,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",31,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,21.088,253.76,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",32,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.216,314.976,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.168,318.144,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.408,327.552,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155221888.0,196608.0,175.392,502.944,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850684.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,506.016,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.04,509.05600000000004,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.912,511.968,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,515.136,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,518.208,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,276288.0,687744.0,12288.0,0,0.0,700032.0,700032.0,0.0,768.0,0.0,196608.0,196608.0,3.264,521.472,49152.0,98304.0,270144.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,524.448,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,527.648,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",44,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,230.4,758.048,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,760.928,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.216,770.144,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),47,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116711360.0,294912.0,132.32,902.4639999999999,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647230.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",48,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.088,907.5519999999999,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,911.0719999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,914.5919999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,918.0799999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",52,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.8,938.8799999999999,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",53,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.376,1000.2559999999999,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",54,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,1003.1359999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",55,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.408,1012.5439999999999,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155243008.0,196608.0,175.264,1187.808,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4851344.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,1190.784,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",58,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.072,1193.856,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.232,1197.088,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,1200.2559999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,1203.232,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,276072.0,687312.0,12288.0,0,0.0,699600.0,699600.0,0.0,768.0,0.0,196608.0,196608.0,3.04,1206.272,49152.0,98304.0,269928.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.944,1209.216,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,1212.3839999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",65,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,228.672,1441.0559999999998,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,1444.0639999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.312,1453.3759999999997,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),68,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116723168.0,294912.0,132.864,1586.2399999999998,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647599.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",69,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.344,1591.5839999999998,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,1595.1039999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,1598.5919999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.648,1602.2399999999998,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",73,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.8,1623.0399999999997,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.512,1683.5519999999997,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,1686.4639999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",76,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.28,1695.7439999999997,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",77,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155231744.0,196608.0,174.496,1870.2399999999998,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850992.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",78,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,1873.216,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",79,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.264,1876.4799999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,1879.456,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,1882.6879999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,1885.7599999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,276180.0,687528.0,12288.0,0,0.0,699816.0,699816.0,0.0,768.0,0.0,196608.0,196608.0,3.136,1888.8959999999997,49152.0,98304.0,270036.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.944,1891.8399999999997,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",85,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,1895.0719999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",86,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,229.248,2124.3199999999997,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,2127.2319999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.504,2136.7359999999994,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),89,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116703744.0,294912.0,133.696,2270.4319999999993,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646992.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",90,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.12,2275.551999999999,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,2279.071999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.712,2282.783999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",93,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.552,2286.3359999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",94,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.672,2307.0079999999994,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",95,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.024,2368.0319999999992,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,2371.1039999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.312,2380.4159999999993,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155209728.0,196608.0,174.624,2555.039999999999,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850304.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",99,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,2558.015999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",100,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,2560.9919999999993,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",101,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,2563.9679999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,2567.167999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,2570.2399999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",104,276352.0,687872.0,12288.0,0,0.0,700160.0,700160.0,0.0,768.0,0.0,196608.0,196608.0,3.168,2573.4079999999994,49152.0,98304.0,270208.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",105,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,2576.3839999999996,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",106,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,2579.6479999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,228.288,2807.9359999999997,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,2810.8479999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.152,2819.9999999999995,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),110,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116728000.0,294912.0,132.064,2952.0639999999994,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647750.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",111,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.184,2957.2479999999996,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,2960.7359999999994,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,2964.2559999999994,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,2967.7759999999994,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",115,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.736,2988.5119999999993,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",116,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.288,3048.7999999999993,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",117,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,3051.8719999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",118,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.344,3061.2159999999994,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",119,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155255680.0,196608.0,174.496,3235.7119999999995,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4851740.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",120,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.136,3238.8479999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",121,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,3241.8559999999993,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",122,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,3244.9279999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",123,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,3248.3199999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.912,3251.231999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,276248.0,687664.0,12288.0,0,0.0,699952.0,699952.0,0.0,768.0,0.0,196608.0,196608.0,3.136,3254.367999999999,49152.0,98304.0,270104.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",126,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.168,3257.535999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",127,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,3260.7039999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,231.648,3492.3519999999994,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.104,3495.455999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.248,3504.7039999999993,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),131,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116713376.0,294912.0,132.8,3637.5039999999995,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647293.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.024,3642.5279999999993,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,3646.015999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,3649.503999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.552,3653.055999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",136,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,21.056,3674.111999999999,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.76,3735.8719999999994,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",138,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,3738.9119999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",139,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.312,3748.2239999999993,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155303936.0,196608.0,173.728,3921.9519999999993,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4853248.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",141,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.008,3924.959999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",142,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,3927.967999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",143,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,3930.943999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.296,3934.239999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",145,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,3937.215999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,276096.0,687360.0,12288.0,0,0.0,699648.0,699648.0,0.0,768.0,0.0,196608.0,196608.0,3.072,3940.287999999999,49152.0,98304.0,269952.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",147,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.944,3943.231999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",148,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,3946.399999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,229.216,4175.615999999999,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,4178.495999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.184,4187.679999999999,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),152,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116703872.0,294912.0,132.352,4320.031999999999,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646996.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.088,4325.119999999999,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.584,4328.703999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,4332.223999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.616,4335.839999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",157,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.64,4356.48,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",158,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,59.936,4416.415999999999,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",159,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,4419.455999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",160,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.536,4428.991999999999,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155246592.0,196608.0,174.72,4603.7119999999995,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4851456.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,4606.687999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",163,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.072,4609.759999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",164,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,4612.799999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.136,4615.936,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",166,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,4618.911999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,276044.0,687256.0,12288.0,0,0.0,699544.0,699544.0,0.0,768.0,0.0,196608.0,196608.0,3.104,4622.016,49152.0,98304.0,269900.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,4624.991999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",169,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,4628.255999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,228.736,4856.991999999999,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,4859.967999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.44,4869.4079999999985,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),173,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116669760.0,294912.0,134.72,5004.127999999999,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3645930.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.088,5009.2159999999985,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,5012.735999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.488,5016.223999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.552,5019.775999999999,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",178,393216.0,13848576.0,0.0,0,0.0,13848576.0,13848576.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,20.704,5040.479999999999,10665984.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.28,5101.759999999998,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,5104.799999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",181,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.184,5113.983999999999,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",182,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155211520.0,196608.0,174.496,5288.479999999999,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850360.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.008,5291.4879999999985,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",184,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.04,5294.527999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.232,5297.759999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",186,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,5301.279999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",187,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,5304.2559999999985,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,276236.0,687640.0,12288.0,0,0.0,699928.0,699928.0,0.0,768.0,0.0,196608.0,196608.0,3.04,5307.2959999999985,49152.0,98304.0,270092.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",189,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,5310.303999999998,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,5313.759999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,229.76,5543.519999999999,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,5546.463999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.312,5555.775999999999,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,628815696.0,1354135360.0,22515360.0,0,0.0,1376650720.0,1376650720.0,8267516.0,7337956.0,0.5297831427335232,896841856.0,1187648.0,689.184,6244.959999999999,41813824.0,77205504.0,617558016.0,11257680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,28026308.0,37114.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.432,6247.391999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,6250.303999999999,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,6252.991999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.936,6256.927999999999,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.432,6259.359999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.416,6263.775999999999,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.624,6270.399999999999,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,116532.0,0.0,233064.0,0,0.0,233064.0,233064.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.544,6274.943999999999,0.0,0.0,0.0,116532.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,185600.0,0.0,371200.0,0,0.0,371200.0,371200.0,13200.0,83008.0,0.13720272742391484,5029376.0,0.0,6.496,6281.439999999999,0.0,0.0,0.0,185600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,101416.0,0.0,202832.0,0,0.0,202832.0,202832.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.736,6286.175999999999,0.0,0.0,0.0,101416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.496,6292.671999999999,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.672,6297.343999999998,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,185600.0,0.0,371200.0,0,0.0,371200.0,371200.0,13200.0,83008.0,0.13720272742391484,5029376.0,128.0,6.784,6304.127999999998,0.0,0.0,0.0,185600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.584,6307.711999999998,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.368,6310.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.64,6314.719999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,6317.055999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.64,6321.695999999999,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,59368.0,13004.0,0.8203172497651026,829920.0,8128.0,6.624,6328.319999999999,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,254.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.784,6335.103999999998,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.608,6339.711999999999,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,6343.903999999999,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,4.064,6347.967999999999,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,388053.0,0.0,776106.0,0,0.0,776106.0,776106.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,4.96,6352.927999999999,0.0,0.0,0.0,388053.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.976,6355.903999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,186692.0,0.0,373384.0,0,0.0,373384.0,373384.0,64746.0,28733.0,0.6926261513281058,2739136.0,1871520.0,16.768,6372.671999999999,0.0,0.0,0.0,186692.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85598.0,58485.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,62276.0,0.0,124552.0,0,0.0,124552.0,124552.0,14202.0,28492.0,0.3326462734810512,2719424.0,2451264.0,13.92,6386.591999999999,0.0,0.0,0.0,62276.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84982.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28302.0,0.3496185311149922,2729536.0,1870912.0,15.04,6401.631999999999,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85298.0,58466.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,13810.0,28379.0,0.3273365095166987,2710848.0,2451520.0,15.136,6416.767999999999,0.0,0.0,0.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84714.0,76610.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,5.344,6422.111999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.008,6425.119999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15303.0,0.4924714778455824,1871008.0,1286816.0,9.344,6434.463999999999,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58469.0,40213.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429920.0,2412352.0,6.304,6440.767999999999,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75935.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2279424.0,751104.0,25.76,6466.527999999999,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71232.0,23472.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804384.0,577664.0,78.688,6545.215999999999,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25137.0,18052.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.68,6548.896,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.656,6551.552,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,77248.0,9.952,6561.504,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2414.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.128,6565.632,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,3284168.0,6655044.0,939552.0,0,0.0,7594596.0,7594596.0,528.0,6704.0,0.07300884955752213,2279808.0,751360.0,25.92,6591.552,825232.0,201028.0,2814392.0,469776.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71244.0,23480.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.392,6598.9439999999995,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,6601.759999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.104,6608.864,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.944,6611.808,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.008,6614.816,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.648,6618.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,13.888,6632.352,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.688,6635.04,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.712,6638.752,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.784,6641.536,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.68,6645.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.544,6649.76,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,1210564.0,2017280.0,403848.0,0,0.0,2421128.0,2421128.0,0.0,4737.0,0.0,1608256.0,0.0,5.6,6655.360000000001,0.0,0.0,1008640.0,201924.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,18.048,6673.408,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.688,6676.0960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,6678.816000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,6681.6320000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,6684.4800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,6687.392000000001,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,6689.760000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,6692.096000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.976,6695.072000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,6697.408000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.848,6700.256000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.176,6706.432000000002,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,6709.280000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,6712.032000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.2,6715.232000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.584,6718.816000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.752,6721.568000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,6724.352000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.712,6728.064000000002,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.264,6731.328000000002,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.752,6734.080000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.752,6736.832000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.816,6739.648000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.04,6742.688000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,49920.0,49152.0,5.184,6747.872000000003,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1560.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,13056.0,49152.0,4.16,6752.032000000003,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,6754.944000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.752,6757.696000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,4.096,6761.792000000003,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.568,6771.360000000003,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),278,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116721440.0,294912.0,131.936,6903.296000000003,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647545.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",279,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.312,6908.608000000003,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.288,6912.8960000000025,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.192,6917.0880000000025,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.552,6920.640000000002,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",283,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.768,6941.408000000002,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",284,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.344,7002.752000000002,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,7005.696000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",286,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.696,7015.392000000003,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155329024.0,196608.0,174.432,7189.824000000002,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4854032.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,7192.800000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",289,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.104,7195.904000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",290,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.232,7199.136000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",291,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.296,7202.4320000000025,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",292,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.912,7205.344000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,276245.0,687658.0,12288.0,0,0.0,699946.0,699946.0,0.0,768.0,0.0,196608.0,196608.0,3.072,7208.416000000003,49152.0,98304.0,270101.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",294,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.944,7211.360000000003,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.296,7214.656000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,232.096,7446.752000000004,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,7449.632000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.376,7459.008000000004,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),299,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116668032.0,294912.0,133.536,7592.544000000004,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3645876.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.184,7597.728000000005,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.288,7602.016000000004,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",302,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.192,7606.208000000004,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,7609.728000000005,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",304,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,21.088,7630.816000000004,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.96,7691.776000000004,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,7694.6560000000045,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.248,7703.904000000004,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155250944.0,196608.0,173.76,7877.664000000004,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4851592.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,7880.928000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",310,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.104,7884.032000000005,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",311,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,7887.072000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",312,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,7890.336000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.912,7893.248000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,275932.0,687032.0,12288.0,0,0.0,699320.0,699320.0,0.0,768.0,0.0,196608.0,196608.0,3.04,7896.288000000005,49152.0,98304.0,269788.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",315,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,7899.264000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",316,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,7902.6560000000045,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",317,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,231.136,8133.792000000005,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,8136.672000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.408,8146.080000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),320,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116690688.0,294912.0,133.536,8279.616000000005,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646584.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",321,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.12,8284.736000000006,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.32,8289.056000000006,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",323,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.512,8293.568000000007,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",324,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.616,8297.184000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",325,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.96,8318.144000000006,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",326,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.544,8378.688000000006,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",327,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,8381.568000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",328,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.28,8390.848000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",329,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155354112.0,196608.0,174.304,8565.152000000006,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4854816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",330,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,8568.192000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",331,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,8571.200000000006,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",332,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,8574.240000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,8577.440000000008,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",334,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,8580.480000000009,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",335,276329.0,687826.0,12288.0,0,0.0,700114.0,700114.0,0.0,768.0,0.0,196608.0,196608.0,3.104,8583.584000000008,49152.0,98304.0,270185.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",336,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.944,8586.528000000008,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",337,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,8590.048000000008,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",338,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,229.248,8819.296000000008,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,8822.208000000008,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.376,8831.584000000008,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),341,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116698464.0,294912.0,135.776,8967.360000000008,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646827.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",342,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.152,8972.512000000008,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.192,8976.704000000007,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",344,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.224,8980.928000000007,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.776,8984.704000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",346,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.864,9005.568000000007,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",347,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.096,9065.664000000006,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,9068.608000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.216,9077.824000000006,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155434368.0,196608.0,173.92,9251.744000000006,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4857324.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",351,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.008,9254.752000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",352,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.296,9258.048000000006,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.008,9261.056000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,9264.320000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",355,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,9267.264000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,276200.0,687568.0,12288.0,0,0.0,699856.0,699856.0,0.0,768.0,0.0,196608.0,196608.0,3.104,9270.368000000004,49152.0,98304.0,270056.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,9273.344000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,9276.608000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",359,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,230.176,9506.784000000003,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,9509.696000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.344,9519.040000000003,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),362,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116708832.0,294912.0,133.504,9652.544000000004,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647151.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",363,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.152,9657.696000000004,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.224,9661.920000000004,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",365,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.384,9666.304000000004,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,9669.824000000004,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",367,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.928,9690.752000000004,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",368,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.448,9751.200000000004,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",369,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.848,9754.048000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",370,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.216,9763.264000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",371,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155229696.0,196608.0,173.632,9936.896000000004,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850928.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,9939.872000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",373,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.008,9942.880000000005,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,9945.824000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,9948.992000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,9952.064000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,276364.0,687896.0,12288.0,0,0.0,700184.0,700184.0,0.0,768.0,0.0,196608.0,196608.0,3.04,9955.104000000005,49152.0,98304.0,270220.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",378,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.04,9958.144000000006,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,9961.472000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",380,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,230.08,10191.552000000005,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,10194.496000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.216,10203.712000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),383,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116723232.0,294912.0,132.192,10335.904000000006,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3647601.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",384,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.088,10340.992000000006,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.16,10345.152000000006,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",386,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.192,10349.344000000005,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",387,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.52,10352.864000000005,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",388,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.8,10373.664000000004,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",389,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,60.128,10433.792000000005,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,10436.736000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",391,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.344,10446.080000000004,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155297920.0,196608.0,174.976,10621.056000000004,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4853060.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,10624.096000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",394,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.04,10627.136000000006,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.136,10630.272000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,10633.536000000006,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",397,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.976,10636.512000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,276058.0,687284.0,12288.0,0,0.0,699572.0,699572.0,0.0,768.0,0.0,196608.0,196608.0,3.072,10639.584000000006,49152.0,98304.0,269914.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.168,10642.752000000006,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",400,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.296,10646.048000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,229.888,10875.936000000007,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,10878.848000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.536,10888.384000000007,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),404,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116703232.0,294912.0,136.864,11025.248000000007,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646976.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",405,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.184,11030.432000000006,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.416,11034.848000000005,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.416,11039.264000000005,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.616,11042.880000000005,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",409,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.768,11063.648000000005,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",410,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,59.936,11123.584000000004,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,11126.496000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",412,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.28,11135.776000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",413,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155227136.0,196608.0,174.656,11310.432000000006,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4850848.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.04,11313.472000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",415,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.2,11316.672000000008,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",416,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,11319.616000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,11322.944000000007,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.072,11326.016000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,276036.0,687240.0,12288.0,0,0.0,699528.0,699528.0,0.0,768.0,0.0,196608.0,196608.0,3.488,11329.504000000006,49152.0,98304.0,269892.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",420,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.976,11332.480000000007,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",421,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,11335.744000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",422,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,230.048,11565.792000000007,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,11568.672000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.28,11577.952000000007,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(T1::Params),425,906006528.0,1812529152.0,73728.0,0,0.0,1812602880.0,1812602880.0,2692800.0,2304.0,0.9991451164778798,116693824.0,294912.0,132.864,11710.816000000006,0.0,589824.0,905969664.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3646682.0,9216.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",426,221184.0,147456.0,442368.0,0,0.0,589824.0,589824.0,0.0,10368.0,0.0,331776.0,147456.0,5.12,11715.936000000007,110592.0,36864.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10368.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.32,11720.256000000007,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",428,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,0.0,1536.0,0.0,98304.0,98304.0,4.288,11724.544000000007,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",429,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,768.0,0.0,49152.0,49152.0,3.584,11728.128000000008,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",430,393216.0,13860864.0,0.0,0,0.0,13860864.0,13860864.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,20.96,11749.088000000007,10678272.0,2396160.0,393216.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,37847040.0,76431360.0,196608.0,0,0.0,76627968.0,76627968.0,333696.0,314112.0,0.5151155898043864,40120320.0,49152.0,61.824,11810.912000000008,344064.0,589824.0,37748736.0,98304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1253760.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.88,11813.792000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",433,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.44,11823.232000000007,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",434,151339008.0,305037312.0,688128.0,0,0.0,305725440.0,305725440.0,1294080.0,1255680.0,0.5075301204819277,155350400.0,196608.0,174.176,11997.408000000007,688128.0,2359296.0,150994944.0,344064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4854700.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,12000.352000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",436,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.104,12003.456000000006,0.0,98304.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,12006.400000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,12009.568000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,2.944,12012.512000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,276004.0,687176.0,12288.0,0,0.0,699464.0,699464.0,0.0,768.0,0.0,196608.0,196608.0,3.008,12015.520000000004,49152.0,98304.0,269860.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",441,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,2.912,12018.432000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",442,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,12021.664000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,151314432.0,305577984.0,638976.0,0,0.0,306216960.0,306216960.0,1329024.0,1254144.0,0.5144938308309797,160444416.0,49152.0,228.64,12250.304000000004,1228800.0,2359296.0,150994944.0,319488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5013888.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,12253.344000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,73284.0,240884.0,3072.0,0,0.0,243956.0,243956.0,68.0,1064.0,0.06007067137809187,147456.0,49408.0,9.28,12262.624000000005,72240.0,25148.0,71748.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,628815696.0,1354135360.0,22515360.0,0,0.0,1376650720.0,1376650720.0,8267516.0,7337956.0,0.5297831427335232,891301376.0,1188384.0,688.288,12950.912000000006,41813824.0,77205504.0,617558016.0,11257680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,27853168.0,37137.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,12953.280000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.944,12956.224000000006,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,12958.944000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,201728.0,0.0,0,0.0,201728.0,201728.0,0.0,3158.0,0.0,804128.0,804128.0,3.904,12962.848000000005,0.0,201728.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.4,12965.248000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,302404.0,0.0,604808.0,0,0.0,604808.0,604808.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.736,12969.984000000006,0.0,0.0,0.0,302404.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,172800.0,0.0,345600.0,0,0.0,345600.0,345600.0,13200.0,82608.0,0.1377755511022044,5029376.0,0.0,6.912,12976.896000000006,0.0,0.0,0.0,172800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,116474.0,0.0,232948.0,0,0.0,232948.0,232948.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.864,12981.760000000006,0.0,0.0,0.0,116474.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,185600.0,0.0,371200.0,0,0.0,371200.0,371200.0,13200.0,83008.0,0.13720272742391484,5029376.0,0.0,6.944,12988.704000000005,0.0,0.0,0.0,185600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,101395.0,0.0,202790.0,0,0.0,202790.0,202790.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.384,12993.088000000005,0.0,0.0,0.0,101395.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,182400.0,0.0,364800.0,0,0.0,364800.0,364800.0,13200.0,82908.0,0.13734548632788113,5029376.0,0.0,7.04,13000.128000000006,0.0,0.0,0.0,182400.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,101380.0,0.0,202760.0,0,0.0,202760.0,202760.0,3200.0,9484.0,0.2522863450015768,811616.0,51200.0,4.448,13004.576000000006,0.0,0.0,0.0,101380.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25363.0,1600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,13200.0,83208.0,0.13691809808314662,5029376.0,128.0,6.848,13011.424000000006,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,157168.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,856.0,0.0,1712.0,0,0.0,1712.0,1712.0,0.0,21.0,0.0,6432.0,800.0,3.488,13014.912000000006,0.0,0.0,0.0,856.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.464,13017.376000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.64,13022.016000000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,13024.320000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,23.0,0.9650986342943855,800.0,0.0,4.64,13028.960000000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,253328.0,0.0,506656.0,0,0.0,506656.0,506656.0,53710.0,13020.0,0.8048853589090365,829920.0,8288.0,6.432,13035.392000000005,0.0,0.0,0.0,253328.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25935.0,259.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.72,13042.112000000005,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,814528.0,50272.0,4.704,13046.816000000004,0.0,0.0,0.0,402056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25454.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,13051.008000000003,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,603784.0,0.0,1207568.0,0,0.0,1207568.0,1207568.0,0.0,6283.0,0.0,0.0,1608224.0,3.968,13054.976000000004,0.0,0.0,0.0,603784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,388042.0,0.0,776084.0,0,0.0,776084.0,776084.0,64512.0,6283.0,0.9112507945476376,804128.0,0.0,5.056,13060.032000000005,0.0,0.0,0.0,388042.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.88,13062.912000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,189312.0,0.0,378624.0,0,0.0,378624.0,378624.0,65758.0,28683.0,0.696286570451393,2723776.0,1923136.0,16.608,13079.520000000004,0.0,0.0,0.0,189312.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,85118.0,60098.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,69188.0,0.0,138376.0,0,0.0,138376.0,138376.0,17010.0,28295.0,0.3754552477651473,2713536.0,1649536.0,14.656,13094.176000000005,0.0,0.0,0.0,69188.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84798.0,51548.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,64896.0,0.0,129792.0,0,0.0,129792.0,129792.0,15214.0,28456.0,0.348385619418365,2710848.0,1869664.0,15.072,13109.248000000005,0.0,0.0,0.0,64896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84714.0,58427.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,13810.0,28341.0,0.32763161016345993,2718272.0,2451264.0,15.392,13124.640000000005,0.0,0.0,0.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,84946.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,6283.0,0.5995793767127653,1608224.0,0.0,5.312,13129.952000000005,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.912,13132.864000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,41123.0,0.0,82246.0,0,0.0,82246.0,82246.0,14849.0,15230.0,0.49366667774859535,1874848.0,1286400.0,9.184,13142.048000000004,0.0,0.0,0.0,41123.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,58589.0,40200.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,603272.0,0.0,1206544.0,0,0.0,1206544.0,1206544.0,0.0,25132.0,0.0,2429216.0,2412352.0,6.656,13148.704000000005,0.0,0.0,0.0,603272.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75913.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,3284156.0,6655044.0,939528.0,0,0.0,7594572.0,7594572.0,528.0,6704.0,0.07300884955752213,2276352.0,751424.0,25.856,13174.560000000005,825232.0,201028.0,2814392.0,469764.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71136.0,23482.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,210944.0,1024200.0,421888.0,0,0.0,1446088.0,1446088.0,112284.0,12568.0,0.8993368147887099,804480.0,584096.0,80.128,13254.688000000006,1024200.0,0.0,0.0,210944.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25140.0,18253.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,3158.0,0.0,804128.0,200800.0,3.872,13258.560000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.688,13261.248000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,603084.0,0.0,1206168.0,0,0.0,1206168.0,1206168.0,0.0,18849.0,0.0,1809280.0,75776.0,9.632,13270.880000000005,0.0,0.0,0.0,603084.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56540.0,2368.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,25216.0,0.0,50432.0,0,0.0,50432.0,50432.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,13275.072000000004,0.0,0.0,0.0,25216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,3284169.0,6655044.0,939554.0,0,0.0,7594598.0,7594598.0,528.0,6704.0,0.07300884955752213,2279808.0,751424.0,25.824,13300.896000000004,825232.0,201028.0,2814392.0,469777.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,71244.0,23482.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.104,13308.000000000004,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.848,13310.848000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,7.072,13317.920000000004,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,13320.736000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.04,13323.776000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.52,13327.296000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,8192.0,220484.0,16384.0,0,0.0,236868.0,236868.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,13.984,13341.280000000006,220484.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.72,13344.000000000005,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.744,13347.744000000006,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.784,13350.528000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.52,13354.048000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,1806336.0,2724488.0,1290240.0,0,0.0,4014728.0,4014728.0,0.0,6283.0,0.0,0.0,804128.0,4.416,13358.464000000005,0.0,402056.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,1210565.0,2017280.0,403850.0,0,0.0,2421130.0,2421130.0,0.0,4737.0,0.0,1608256.0,0.0,5.76,13364.224000000006,0.0,0.0,1008640.0,201925.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,110754.0,0.0,221508.0,0,0.0,221508.0,221508.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,18.176,13382.400000000005,0.0,0.0,0.0,110754.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.72,13385.120000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,13387.936000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.752,13390.688000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,13393.472000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.912,13396.384000000005,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.4,13398.784000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,13401.152000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,13403.968000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,13406.336000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.816,13409.152000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.176,13415.328000000007,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.944,13418.272000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,13421.024000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,13424.096000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.552,13427.648000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.72,13430.368000000006,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
