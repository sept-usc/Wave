Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",517.0,68288512.0,147062784.0,2359296.0,0.0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78491632.0,65596.0,0.081108,19.502432000000002,4456448.0,8388608.0,67108864.0,1179648.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2452863.5,2049.875,18.822285617600063,14.413220847674852,True,False,0,Q
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",518.0,68288512.0,147062784.0,2359296.0,0.0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79173168.0,65588.0,0.080732,19.583164000000004,4456448.0,8388608.0,67108864.0,1179648.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2474161.5,2049.625,18.822285617600063,14.413220847674852,True,False,0,K
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",519.0,68288512.0,147062784.0,2359296.0,0.0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78220144.0,65616.0,0.08150400000000001,19.664668,4456448.0,8388608.0,67108864.0,1179648.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2444379.5,2050.5,18.822285617600063,14.413220847674852,True,False,0,V
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520.0,49152.0,16384.0,98304.0,0.0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00346,19.668128000000003,0.0,16384.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0,11.64997939616457,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521.0,12288.0,8192.0,24576.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00362,19.671748,8192.0,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,10.397238225511654,14.413220847674852,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",522.0,204800.0,0.0,409600.0,0.0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.0042120000000000005,19.67596,0.0,0.0,0.0,204800.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,12.922938794110705,14.413220847674852,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523.0,49152.0,16384.0,98304.0,0.0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.0034679999999999997,19.679428,0.0,16384.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0,11.64997939616457,14.413220847674852,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",524.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.0030239999999999998,19.682451999999998,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,10.397238225511654,14.413220847674852,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525.0,49152.0,16384.0,98304.0,0.0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.0034159999999999998,19.685868,0.0,16384.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0,11.64997939616457,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526.0,12288.0,8192.0,24576.0,0.0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003584,19.689452000000003,8192.0,0.0,0.0,12288.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1024.0,1024.0,10.397238225511654,14.413220847674852,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",527.0,204800.0,0.0,409600.0,0.0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004176,19.693628,0.0,0.0,0.0,204800.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,12.922938794110705,14.413220847674852,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528.0,49152.0,16384.0,98304.0,0.0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.0034920000000000003,19.69712,0.0,16384.0,0.0,49152.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3072.0,2048.0,11.64997939616457,14.413220847674852,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",529.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003072,19.700192,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,10.397238225511654,14.413220847674852,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530.0,24576.0,0.0,49152.0,0.0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003104,19.703296,0.0,0.0,0.0,24576.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,10.802693161352469,14.413220847674852,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531.0,24576.0,0.0,49152.0,0.0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.0031000000000000003,19.706395999999998,0.0,0.0,0.0,24576.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,4096.0,10.802693161352469,14.413220847674852,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",532.0,259360.0,24060796.5,0.0,0.0,0.0,24060796.5,24060796.5,133241.5,256.0,0.9980823597029373,327680.0,65536.0,0.038396,19.744791999999997,20372025.0,3170051.5,259360.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10240.0,2048.0,16.996094414262394,14.413220847674852,True,True,0,Attention
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",533.0,68288512.0,147062784.0,2359296.0,0.0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79568000.0,65768.0,0.080252,19.825044,4456448.0,8388608.0,67108864.0,1179648.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2486500.0,2055.25,18.822285617600063,14.413220847674852,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003056,19.8281,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,10.397238225511654,14.413220847674852,False,False,16384,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002916,19.831015999999998,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,14.413220847674852,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",536.0,2048.0,20868.0,4096.0,0.0,0.0,24964.0,24964.0,40.0,132.0,0.2325581395348837,65536.0,32.0,0.0068319999999999995,19.837848,20864.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0,10.12523012293471,14.413220847674852,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",537.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002764,19.840612,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.6251071482389,14.413220847674852,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,19.843492,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539.0,32768.0,16384.0,65536.0,0.0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.0034079999999999996,19.846900000000005,0.0,16384.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0,11.31351064723008,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540.0,32768.0,16384.0,65536.0,0.0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003384,19.850284000000002,0.0,16384.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,11.31351064723008,14.413220847674852,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",541.0,273154048.0,588251136.0,9437184.0,0.0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,373146640.0,293416.0,0.300236,20.15052,17825792.0,33554432.0,268435456.0,4718592.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,11660832.5,9169.25,20.208579973700616,14.413220847674852,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",542.0,720896.0,1376256.0,131072.0,0.0,0.0,1507328.0,1507328.0,0.0,1024.0,0.0,262144.0,262144.0,0.0034159999999999998,20.153936,65536.0,0.0,655360.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8192.0,8192.0,14.225849768313665,14.413220847674852,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",543.0,273154048.0,588251136.0,9437184.0,0.0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,373148512.0,293660.0,0.300816,20.454752,17825792.0,33554432.0,268435456.0,4718592.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,11660891.0,9176.875,20.208579973700616,14.413220847674852,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",544.0,0.0,65536.0,0.0,0.0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003388,20.45814,0.0,65536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16384.0,8192.0,11.090370147631774,14.413220847674852,False,False,0,other
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",545.0,272760832.0,587464704.0,8650752.0,0.0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,328709408.0,65940.0,0.30546399999999996,20.763604,17039360.0,33554432.0,268435456.0,4325376.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10272169.0,2060.625,20.205944926067023,14.413220847674852,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",546.0,16384.0,32768.0,0.0,0.0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,20.76658,0.0,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,10.397238225511654,14.413220847674852,False,False,16384,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547.0,0.0,16384.0,0.0,0.0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.0029000000000000002,20.76948,0.0,16384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,2048.0,9.704121561132915,14.413220847674852,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",548.0,2048.0,20868.0,4096.0,0.0,0.0,24964.0,24964.0,40.0,132.0,0.2325581395348837,65536.0,32.0,0.006916,20.776396000000002,20864.0,4.0,0.0,2048.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2048.0,1.0,10.12523012293471,14.413220847674852,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",549.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.0027480000000000004,20.779144000000002,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.6251071482389,14.413220847674852,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",550.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002928,20.782072,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551.0,32768.0,16384.0,65536.0,0.0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003432,20.785504000000003,0.0,16384.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2112.0,2048.0,11.31351064723008,14.413220847674852,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552.0,32768.0,16384.0,65536.0,0.0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003408,20.788912000000003,0.0,16384.0,0.0,32768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4096.0,2048.0,11.31351064723008,14.413220847674852,False,False,0,other
