Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum,flops_log,flops_threshold,is_matmul_candidate,is_attention_candidate,elementwise_add_fma_ops,role
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",578.0,617472.0,1207296.0,52224.0,0.0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618896.0,12084.0,7.619999999999999,3247.095999999991,24576.0,0.0,591360.0,26112.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,81840.5,377.625,14.046242047918852,10.949634222602757,True,False,0,Q
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579.0,768.0,2304.0,1536.0,0.0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2600000000000002,3250.3559999999907,1536.0,768.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,48.0,8.253488028345904,10.949634222602757,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",580.0,25344.0,768.0,50688.0,0.0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.876,3253.231999999991,768.0,0.0,0.0,25344.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,10.8485017864294,10.949634222602757,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",581.0,617472.0,1207296.0,52224.0,0.0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618740.0,12052.0,7.688000000000001,3260.919999999991,24576.0,0.0,591360.0,26112.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,81835.625,376.625,14.046242047918852,10.949634222602757,True,False,0,K
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",582.0,768.0,2304.0,1536.0,0.0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2600000000000002,3264.1799999999907,1536.0,768.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,48.0,8.253488028345904,10.949634222602757,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",583.0,25344.0,768.0,50688.0,0.0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.892,3267.0719999999906,768.0,0.0,0.0,25344.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,10.8485017864294,10.949634222602757,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 6, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",584.0,617472.0,1207296.0,52224.0,0.0,0.0,1259520.0,1259520.0,10752.0,37632.0,0.2222222222222222,2618292.0,12052.0,7.683999999999999,3274.7559999999908,24576.0,0.0,591360.0,26112.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,81821.625,376.625,14.046242047918852,10.949634222602757,True,False,0,V
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585.0,768.0,2304.0,1536.0,0.0,0.0,3840.0,3840.0,0.0,2304.0,0.0,6144.0,1536.0,3.2560000000000002,3278.0119999999906,1536.0,768.0,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,48.0,8.253488028345904,10.949634222602757,False,False,0,other
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",586.0,25344.0,768.0,50688.0,0.0,0.0,51456.0,51456.0,0.0,960.0,0.0,6144.0,0.0,2.888,3280.8999999999905,768.0,0.0,0.0,25344.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,0.0,10.8485017864294,10.949634222602757,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.076,3283.9759999999906,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588.0,640.0,384.0,1280.0,0.0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.044,3287.0199999999904,384.0,0.0,0.0,640.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,48.0,7.417580402414544,10.949634222602757,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589.0,173568.0,0.0,347136.0,0.0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.488,3290.5079999999903,0.0,0.0,0.0,173568.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,12.757474793691093,10.949634222602757,True,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.08,3293.58799999999,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.656,3296.24399999999,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.6251071482389,10.949634222602757,False,False,0,add
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.036,3299.2799999999907,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593.0,640.0,384.0,1280.0,0.0,0.0,1664.0,1664.0,0.0,24.0,0.0,1536.0,1536.0,3.044,3302.3239999999905,384.0,0.0,0.0,640.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,48.0,48.0,7.417580402414544,10.949634222602757,False,False,0,other
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",594.0,173568.0,0.0,347136.0,0.0,0.0,347136.0,347136.0,0.0,48.0,0.0,3072.0,3072.0,3.476,3305.79999999999,0.0,0.0,0.0,173568.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,12.757474793691093,10.949634222602757,True,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,4608.0,3072.0,3.052,3308.8519999999903,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,144.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",596.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.668,3311.5199999999904,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.6251071482389,10.949634222602757,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597.0,1280.0,0.0,2560.0,0.0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.656,3314.1759999999904,0.0,0.0,0.0,1280.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,192.0,7.848153086199526,10.949634222602757,False,False,0,add
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",598.0,1280.0,0.0,2560.0,0.0,0.0,2560.0,2560.0,0.0,60.0,0.0,6144.0,6144.0,2.6759999999999997,3316.85199999999,0.0,0.0,0.0,1280.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,192.0,7.848153086199526,10.949634222602757,False,False,0,add
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",599.0,12224.0,1128027.75,0.0,0.0,0.0,1128027.75,1128027.75,6243.0,12.0,0.9980815324608547,15360.0,3072.0,20.172,3337.0239999999903,954974.0,148605.75,12224.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,480.0,96.0,13.935982198303991,10.949634222602757,True,True,0,Attention
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",600.0,640512.0,1205760.0,99840.0,0.0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.2575757575757575,2506752.0,1536.0,6.896,3343.91999999999,24576.0,0.0,590592.0,49920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,78336.0,48.0,14.08217402912306,10.949634222602757,True,False,0,Wo
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",601.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.6479999999999997,3346.56799999999,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.6251071482389,10.949634222602757,False,False,1024,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",602.0,128.0,768.0,256.0,0.0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.56,3349.1279999999897,0.0,768.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,6.932447891572509,10.949634222602757,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",603.0,384.0,1889.0,768.0,0.0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.7199999999999998,3352.84799999999,1888.0,1.0,0.0,384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,1.0,7.885329239273191,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",604.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.428,3355.27599999999,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.6251071482389,10.949634222602757,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",605.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.568,3357.84399999999,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,10.949634222602757,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,3.0,3360.84399999999,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,99.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",607.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.616,3363.4599999999896,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,6.645090969505644,10.949634222602757,False,False,0,other
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",608.0,2457600.0,5157888.0,196608.0,0.0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9705968.0,12288.0,14.100000000000001,3377.5599999999895,144384.0,294912.0,2359296.0,98304.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,303311.5,384.0,15.493447326546507,10.949634222602757,True,False,0,FFN1
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609.0,33792.0,64512.0,6144.0,0.0,0.0,70656.0,70656.0,0.0,48.0,0.0,12288.0,12288.0,2.952,3380.5119999999897,3072.0,0.0,30720.0,3072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,384.0,384.0,11.165592463176269,10.949634222602757,True,False,0,other
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",610.0,2457600.0,5157888.0,196608.0,0.0,0.0,5354496.0,5354496.0,98304.0,84480.0,0.5378151260504201,9701680.0,12288.0,14.232,3394.7439999999897,144384.0,294912.0,2359296.0,98304.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,303177.5,384.0,15.493447326546507,10.949634222602757,True,False,0,FFN2
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",611.0,0.0,3072.0,0.0,0.0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,2.62,3397.3639999999896,0.0,3072.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,768.0,384.0,8.030409562130485,10.949634222602757,False,False,0,other
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",612.0,2409984.0,4744704.0,99840.0,0.0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.0809523809523809,10469376.0,6144.0,15.184000000000001,3412.5479999999898,24576.0,0.0,2360064.0,49920.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,327168.0,192.0,15.393363887648356,10.949634222602757,True,False,0,FFN3
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",613.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,72.0,0.0,6144.0,3072.0,2.6639999999999997,3415.2119999999895,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,7.6251071482389,10.949634222602757,False,False,1024,elementwise_add
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",614.0,128.0,768.0,256.0,0.0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,2.58,3417.7919999999895,0.0,768.0,0.0,128.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,96.0,6.932447891572509,10.949634222602757,False,False,0,other
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",615.0,384.0,1889.0,768.0,0.0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,3.688,3421.479999999989,1888.0,1.0,0.0,384.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,96.0,1.0,7.885329239273191,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",616.0,1024.0,2048.0,0.0,0.0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.452,3423.9319999999893,0.0,0.0,1024.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,7.6251071482389,10.949634222602757,False,False,0,add
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3426.5239999999894,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,10.949634222602757,False,False,0,other
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618.0,1536.0,768.0,3072.0,0.0,0.0,3840.0,3840.0,0.0,72.0,0.0,3168.0,3072.0,2.992,3429.515999999989,0.0,768.0,0.0,1536.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,99.0,96.0,8.253488028345904,10.949634222602757,False,False,0,other
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",619.0,0.0,768.0,0.0,0.0,0.0,768.0,768.0,0.0,72.0,0.0,6144.0,3072.0,2.6319999999999997,3432.147999999989,0.0,768.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,192.0,96.0,6.645090969505644,10.949634222602757,False,False,0,other
