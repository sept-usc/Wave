Using existing model at: models/llama_layer8_embd4096_ffn16384_head32_pos1024
Warning: models/llama_layer8_embd4096_ffn16384_head32_pos1024 may not contain a tokenizer. This could cause issues.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.40it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.43it/s]
Generating with parameters: max_tokens=2
Batch size: 4, Prompt seq len: 1

Generated Outputs:
------------------------------------------------------------
Prompt:    'Hello'
Output:    'Hello Praatten'
------------------------------------------------------------
Prompt:    'Hello'
Output:    'Helloè´¥TA'
------------------------------------------------------------
Prompt:    'Hello'
Output:    'HelloÏ‰ð•œ'
------------------------------------------------------------
Prompt:    'Hello'
Output:    'Hello Japaneseivan'
------------------------------------------------------------
